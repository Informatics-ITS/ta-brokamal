{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "M_t8ufqBMTV6"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import random\n",
        "\n",
        "base_source_tokens = ['source', 'nga', 'nga_ee', 'nga_uu', 'nga_ii', 'nga_ex', 'nga_oo', 'nga_eueu', 'nga_pamaeh',\n",
        "    'nga_hh', 'nga_ng', 'nga_rr',\n",
        "    'nga_ee_hh', 'nga_ee_ng', 'nga_ee_rr',\n",
        "    'nga_uu_hh', 'nga_uu_ng', 'nga_uu_rr',\n",
        "    'nga_ii_hh', 'nga_ii_ng', 'nga_ii_rr',\n",
        "    'nga_ex_hh', 'nga_ex_ng', 'nga_ex_rr',\n",
        "    'nga_oo_hh', 'nga_oo_ng', 'nga_oo_rr',\n",
        "    'nga_eueu_hh', 'nga_eueu_ng', 'nga_eueu_rr',\n",
        "    'a', 'i', 'u', 'e', 'o', 'eu', 'é', 'a_ng', 'a_hh', 'a_rr',\n",
        "          'i_ng', 'i_hh', 'i_rr',\n",
        "          'u_ng', 'u_hh', 'u_rr',\n",
        "          'e_ng', 'e_hh', 'e_rr',\n",
        "          'o_ng', 'o_hh', 'o_rr','hiji', 'dua', 'tilu', 'opat', 'lima', 'genep', 'tujuh', 'dalapan', 'salapan', 'enol', 'ka', 'na', 'pa', 'ma', 'ta', 'da', 'ba', 'ga', 'ja', 'ra', 'la', 'sa', 'ya', 'wa', 'ha', 'za', 'xa', 'fa', 'va', 'ca', 'nya', 'kha', 'sya', 'qa', 'ka_ng', 'ka_rr', 'ka_hh', 'na_ng', 'na_rr', 'na_hh', 'pa_ng', 'pa_rr', 'pa_hh', 'ma_ng', 'ma_rr', 'ma_hh', 'ta_ng', 'ta_rr', 'ta_hh', 'da_ng', 'da_rr', 'da_hh', 'ba_ng', 'ba_rr', 'ba_hh', 'ga_ng', 'ga_rr', 'ga_hh', 'ja_ng', 'ja_rr', 'ja_hh', 'ra_ng', 'ra_rr', 'ra_hh', 'la_ng', 'la_rr', 'la_hh', 'sa_ng', 'sa_rr', 'sa_hh', 'ya_ng', 'ya_rr', 'ya_hh', 'wa_ng', 'wa_rr', 'wa_hh', 'ha_ng', 'ha_rr', 'ha_hh', 'za_ng', 'za_rr', 'za_hh', 'xa_ng', 'xa_rr', 'xa_hh', 'fa_ng', 'fa_rr', 'fa_hh', 'va_ng', 'va_rr', 'va_hh', 'ca_ng', 'ca_rr', 'ca_hh', 'nya_ng', 'nya_rr', 'nya_hh', 'kha_ng', 'kha_rr', 'kha_hh', 'sya_ng', 'sya_rr', 'sya_hh', 'qa_ng', 'qa_rr', 'qa_hh', 'ka_rrr', 'ka_lll', 'ka_yyy', 'na_rrr', 'na_lll', 'na_yyy', 'pa_rrr', 'pa_lll', 'pa_yyy', 'ma_rrr', 'ma_lll', 'ma_yyy', 'ta_rrr', 'ta_lll', 'ta_yyy', 'da_rrr', 'da_lll', 'da_yyy', 'ba_rrr', 'ba_lll', 'ba_yyy', 'ga_rrr', 'ga_lll', 'ga_yyy', 'ja_rrr', 'ja_lll', 'ja_yyy', 'ra_rrr', 'ra_lll', 'ra_yyy', 'la_rrr', 'la_lll', 'la_yyy', 'sa_rrr', 'sa_lll', 'sa_yyy', 'ya_rrr', 'ya_lll', 'ya_yyy', 'wa_rrr', 'wa_lll', 'wa_yyy', 'ha_rrr', 'ha_lll', 'ha_yyy', 'za_rrr', 'za_lll', 'za_yyy', 'xa_rrr', 'xa_lll', 'xa_yyy', 'fa_rrr', 'fa_lll', 'fa_yyy', 'va_rrr', 'va_lll', 'va_yyy', 'ca_rrr', 'ca_lll', 'ca_yyy', 'qa_rrr', 'qa_lll', 'qa_yyy', 'ka_ex', 'ka_ii', 'ka_oo', 'ka_uu', 'ka_ee', 'ka_eueu', 'ka_pamaeh', 'na_ex', 'na_ii', 'na_oo', 'na_uu', 'na_ee', 'na_eueu', 'na_pamaeh', 'pa_ex', 'pa_ii', 'pa_oo', 'pa_uu', 'pa_ee', 'pa_eueu', 'pa_pamaeh', 'ma_ex', 'ma_ii', 'ma_oo', 'ma_uu', 'ma_ee', 'ma_eueu', 'ma_pamaeh', 'ta_ex', 'ta_ii', 'ta_oo', 'ta_uu', 'ta_ee', 'ta_eueu', 'ta_pamaeh', 'da_ex', 'da_ii', 'da_oo', 'da_uu', 'da_ee', 'da_eueu', 'da_pamaeh', 'ba_ex', 'ba_ii', 'ba_oo', 'ba_uu', 'ba_ee', 'ba_eueu', 'ba_pamaeh', 'ga_ex', 'ga_ii', 'ga_oo', 'ga_uu', 'ga_ee', 'ga_eueu', 'ga_pamaeh', 'ja_ex', 'ja_ii', 'ja_oo', 'ja_uu', 'ja_ee', 'ja_eueu', 'ja_pamaeh', 'ra_ex', 'ra_ii', 'ra_oo', 'ra_uu', 'ra_ee', 'ra_eueu', 'ra_pamaeh', 'la_ex', 'la_ii', 'la_oo', 'la_uu', 'la_ee', 'la_eueu', 'la_pamaeh', 'sa_ex', 'sa_ii', 'sa_oo', 'sa_uu', 'sa_ee', 'sa_eueu', 'sa_pamaeh', 'ya_ex', 'ya_ii', 'ya_oo', 'ya_uu', 'ya_ee', 'ya_eueu', 'ya_pamaeh', 'wa_ex', 'wa_ii', 'wa_oo', 'wa_uu', 'wa_ee', 'wa_eueu', 'wa_pamaeh', 'ha_ex', 'ha_ii', 'ha_oo', 'ha_uu', 'ha_ee', 'ha_eueu', 'ha_pamaeh', 'za_ex', 'za_ii', 'za_oo', 'za_uu', 'za_ee', 'za_eueu', 'za_pamaeh', 'xa_ex', 'xa_ii', 'xa_oo', 'xa_uu', 'xa_ee', 'xa_eueu', 'xa_pamaeh', 'fa_ex', 'fa_ii', 'fa_oo', 'fa_uu', 'fa_ee', 'fa_eueu', 'fa_pamaeh', 'va_ex', 'va_ii', 'va_oo', 'va_uu', 'va_ee', 'va_eueu', 'va_pamaeh', 'ca_ex', 'ca_ii', 'ca_oo', 'ca_uu', 'ca_ee', 'ca_eueu', 'ca_pamaeh', 'nya_ex', 'nya_ii', 'nya_oo', 'nya_uu', 'nya_ee', 'nya_eueu', 'nya_pamaeh', 'kha_ex', 'kha_ii', 'kha_oo', 'kha_uu', 'kha_ee', 'kha_eueu', 'kha_pamaeh', 'sya_ex', 'sya_ii', 'sya_oo', 'sya_uu', 'sya_ee', 'sya_eueu', 'sya_pamaeh', 'qa_ex', 'qa_ii', 'qa_oo', 'qa_uu', 'qa_ee', 'qa_eueu', 'qa_pamaeh', 'ka_ex_ng', 'ka_ex_rr', 'ka_ex_hh', 'ka_ii_ng', 'ka_ii_rr', 'ka_ii_hh', 'ka_oo_ng', 'ka_oo_rr', 'ka_oo_hh', 'ka_uu_ng', 'ka_uu_rr', 'ka_uu_hh', 'ka_ee_ng', 'ka_ee_rr', 'ka_ee_hh', 'ka_eueu_ng', 'ka_eueu_rr', 'ka_eueu_hh', 'na_ex_ng', 'na_ex_rr', 'na_ex_hh', 'na_ii_ng', 'na_ii_rr', 'na_ii_hh', 'na_oo_ng', 'na_oo_rr', 'na_oo_hh', 'na_uu_ng', 'na_uu_rr', 'na_uu_hh', 'na_ee_ng', 'na_ee_rr', 'na_ee_hh', 'na_eueu_ng', 'na_eueu_rr', 'na_eueu_hh', 'pa_ex_ng', 'pa_ex_rr', 'pa_ex_hh', 'pa_ii_ng', 'pa_ii_rr', 'pa_ii_hh', 'pa_oo_ng', 'pa_oo_rr', 'pa_oo_hh', 'pa_uu_ng', 'pa_uu_rr', 'pa_uu_hh', 'pa_ee_ng', 'pa_ee_rr', 'pa_ee_hh', 'pa_eueu_ng', 'pa_eueu_rr', 'pa_eueu_hh', 'ma_ex_ng', 'ma_ex_rr', 'ma_ex_hh', 'ma_ii_ng', 'ma_ii_rr', 'ma_ii_hh', 'ma_oo_ng', 'ma_oo_rr', 'ma_oo_hh', 'ma_uu_ng', 'ma_uu_rr', 'ma_uu_hh', 'ma_ee_ng', 'ma_ee_rr', 'ma_ee_hh', 'ma_eueu_ng', 'ma_eueu_rr', 'ma_eueu_hh', 'ta_ex_ng', 'ta_ex_rr', 'ta_ex_hh', 'ta_ii_ng', 'ta_ii_rr', 'ta_ii_hh', 'ta_oo_ng', 'ta_oo_rr', 'ta_oo_hh', 'ta_uu_ng', 'ta_uu_rr', 'ta_uu_hh', 'ta_ee_ng', 'ta_ee_rr', 'ta_ee_hh', 'ta_eueu_ng', 'ta_eueu_rr', 'ta_eueu_hh', 'da_ex_ng', 'da_ex_rr', 'da_ex_hh', 'da_ii_ng', 'da_ii_rr', 'da_ii_hh', 'da_oo_ng', 'da_oo_rr', 'da_oo_hh', 'da_uu_ng', 'da_uu_rr', 'da_uu_hh', 'da_ee_ng', 'da_ee_rr', 'da_ee_hh', 'da_eueu_ng', 'da_eueu_rr', 'da_eueu_hh', 'ba_ex_ng', 'ba_ex_rr', 'ba_ex_hh', 'ba_ii_ng', 'ba_ii_rr', 'ba_ii_hh', 'ba_oo_ng', 'ba_oo_rr', 'ba_oo_hh', 'ba_uu_ng', 'ba_uu_rr', 'ba_uu_hh', 'ba_ee_ng', 'ba_ee_rr', 'ba_ee_hh', 'ba_eueu_ng', 'ba_eueu_rr', 'ba_eueu_hh', 'ga_ex_ng', 'ga_ex_rr', 'ga_ex_hh', 'ga_ii_ng', 'ga_ii_rr', 'ga_ii_hh', 'ga_oo_ng', 'ga_oo_rr', 'ga_oo_hh', 'ga_uu_ng', 'ga_uu_rr', 'ga_uu_hh', 'ga_ee_ng', 'ga_ee_rr', 'ga_ee_hh', 'ga_eueu_ng', 'ga_eueu_rr', 'ga_eueu_hh', 'ja_ex_ng', 'ja_ex_rr', 'ja_ex_hh', 'ja_ii_ng', 'ja_ii_rr', 'ja_ii_hh', 'ja_oo_ng', 'ja_oo_rr', 'ja_oo_hh', 'ja_uu_ng', 'ja_uu_rr', 'ja_uu_hh', 'ja_ee_ng', 'ja_ee_rr', 'ja_ee_hh', 'ja_eueu_ng', 'ja_eueu_rr', 'ja_eueu_hh', 'ra_ex_ng', 'ra_ex_rr', 'ra_ex_hh', 'ra_ii_ng', 'ra_ii_rr', 'ra_ii_hh', 'ra_oo_ng', 'ra_oo_rr', 'ra_oo_hh', 'ra_uu_ng', 'ra_uu_rr', 'ra_uu_hh', 'ra_ee_ng', 'ra_ee_rr', 'ra_ee_hh', 'ra_eueu_ng', 'ra_eueu_rr', 'ra_eueu_hh', 'la_ex_ng', 'la_ex_rr', 'la_ex_hh', 'la_ii_ng', 'la_ii_rr', 'la_ii_hh', 'la_oo_ng', 'la_oo_rr', 'la_oo_hh', 'la_uu_ng', 'la_uu_rr', 'la_uu_hh', 'la_ee_ng', 'la_ee_rr', 'la_ee_hh', 'la_eueu_ng', 'la_eueu_rr', 'la_eueu_hh', 'sa_ex_ng', 'sa_ex_rr', 'sa_ex_hh', 'sa_ii_ng', 'sa_ii_rr', 'sa_ii_hh', 'sa_oo_ng', 'sa_oo_rr', 'sa_oo_hh', 'sa_uu_ng', 'sa_uu_rr', 'sa_uu_hh', 'sa_ee_ng', 'sa_ee_rr', 'sa_ee_hh', 'sa_eueu_ng', 'sa_eueu_rr', 'sa_eueu_hh', 'ya_ex_ng', 'ya_ex_rr', 'ya_ex_hh', 'ya_ii_ng', 'ya_ii_rr', 'ya_ii_hh', 'ya_oo_ng', 'ya_oo_rr', 'ya_oo_hh', 'ya_uu_ng', 'ya_uu_rr', 'ya_uu_hh', 'ya_ee_ng', 'ya_ee_rr', 'ya_ee_hh', 'ya_eueu_ng', 'ya_eueu_rr', 'ya_eueu_hh', 'wa_ex_ng', 'wa_ex_rr', 'wa_ex_hh', 'wa_ii_ng', 'wa_ii_rr', 'wa_ii_hh', 'wa_oo_ng', 'wa_oo_rr', 'wa_oo_hh', 'wa_uu_ng', 'wa_uu_rr', 'wa_uu_hh', 'wa_ee_ng', 'wa_ee_rr', 'wa_ee_hh', 'wa_eueu_ng', 'wa_eueu_rr', 'wa_eueu_hh', 'ha_ex_ng', 'ha_ex_rr', 'ha_ex_hh', 'ha_ii_ng', 'ha_ii_rr', 'ha_ii_hh', 'ha_oo_ng', 'ha_oo_rr', 'ha_oo_hh', 'ha_uu_ng', 'ha_uu_rr', 'ha_uu_hh', 'ha_ee_ng', 'ha_ee_rr', 'ha_ee_hh', 'ha_eueu_ng', 'ha_eueu_rr', 'ha_eueu_hh', 'za_ex_ng', 'za_ex_rr', 'za_ex_hh', 'za_ii_ng', 'za_ii_rr', 'za_ii_hh', 'za_oo_ng', 'za_oo_rr', 'za_oo_hh', 'za_uu_ng', 'za_uu_rr', 'za_uu_hh', 'za_ee_ng', 'za_ee_rr', 'za_ee_hh', 'za_eueu_ng', 'za_eueu_rr', 'za_eueu_hh', 'xa_ex_ng', 'xa_ex_rr', 'xa_ex_hh', 'xa_ii_ng', 'xa_ii_rr', 'xa_ii_hh', 'fa_ex_ng', 'fa_ex_rr', 'fa_ex_hh', 'fa_ii_ng', 'fa_ii_rr', 'fa_ii_hh', 'fa_oo_ng', 'fa_oo_rr', 'fa_oo_hh', 'fa_uu_ng', 'fa_uu_rr', 'fa_uu_hh', 'fa_ee_ng', 'fa_ee_rr', 'fa_ee_hh', 'fa_eueu_ng', 'fa_eueu_rr', 'fa_eueu_hh', 'va_ex_ng', 'va_ex_rr', 'va_ex_hh', 'va_ii_ng', 'va_ii_rr', 'va_ii_hh', 'va_oo_ng', 'va_oo_rr', 'va_oo_hh', 'va_uu_ng', 'va_uu_rr', 'va_uu_hh', 'va_ee_ng', 'va_ee_rr', 'va_ee_hh', 'va_eueu_ng', 'va_eueu_rr', 'va_eueu_hh', 'ca_ex_ng', 'ca_ex_rr', 'ca_ex_hh', 'ca_ii_ng', 'ca_ii_rr', 'ca_ii_hh', 'ca_oo_ng', 'ca_oo_rr', 'ca_oo_hh', 'ca_uu_ng', 'ca_uu_rr', 'ca_uu_hh', 'ca_ee_ng', 'ca_ee_rr', 'ca_ee_hh', 'ca_eueu_ng', 'ca_eueu_rr', 'ca_eueu_hh', 'nya_ex_ng', 'nya_ex_rr', 'nya_ex_hh', 'nya_ii_ng', 'nya_ii_rr', 'nya_ii_hh', 'nya_oo_ng', 'nya_oo_rr', 'nya_oo_hh', 'nya_uu_ng', 'nya_uu_rr', 'nya_uu_hh', 'nya_ee_ng', 'nya_ee_rr', 'nya_ee_hh', 'nya_eueu_ng', 'nya_eueu_rr', 'nya_eueu_hh', 'kha_ex_ng', 'kha_ex_rr', 'kha_ex_hh', 'kha_ee_ng', 'kha_ee_rr', 'kha_ee_hh', 'kha_eueu_ng', 'kha_eueu_rr', 'kha_eueu_hh', 'sya_ex_ng', 'sya_ex_rr', 'sya_ex_hh', 'sya_ii_ng', 'sya_ii_rr', 'sya_ii_hh', 'sya_oo_ng', 'sya_oo_rr', 'sya_oo_hh', 'sya_uu_ng', 'sya_uu_rr', 'sya_uu_hh', 'sya_ee_ng', 'sya_ee_rr', 'sya_ee_hh', 'sya_eueu_ng', 'sya_eueu_rr', 'sya_eueu_hh', 'qa_ex_ng', 'qa_ex_rr', 'qa_ex_hh', 'qa_ii_ng', 'qa_ii_rr', 'qa_ii_hh', 'qa_oo_ng', 'qa_oo_rr', 'qa_oo_hh', 'qa_uu_ng', 'qa_uu_rr', 'qa_uu_hh', 'qa_ee_ng', 'qa_ee_rr', 'qa_ee_hh', 'qa_eueu_ng', 'qa_eueu_rr', 'qa_eueu_hh', 'ka_ex_rrr', 'ka_ex_lll', 'ka_ex_yyy', 'ka_ii_rrr', 'ka_ii_lll', 'ka_ii_yyy', 'ka_oo_rrr', 'ka_oo_lll', 'ka_oo_yyy', 'ka_uu_rrr', 'ka_uu_lll', 'ka_uu_yyy', 'ka_ee_rrr', 'ka_ee_lll', 'ka_ee_yyy', 'ka_eueu_rrr', 'ka_eueu_lll', 'ka_eueu_yyy', 'na_ex_rrr', 'na_ex_lll', 'na_ex_yyy', 'na_ii_rrr', 'na_ii_lll', 'na_ii_yyy', 'na_oo_rrr', 'na_oo_lll', 'na_oo_yyy', 'na_uu_rrr', 'na_uu_lll', 'na_uu_yyy', 'na_ee_rrr', 'na_ee_lll', 'na_ee_yyy', 'na_eueu_rrr', 'na_eueu_lll', 'na_eueu_yyy', 'pa_ex_rrr', 'pa_ex_lll', 'pa_ex_yyy', 'pa_ii_rrr', 'pa_ii_lll', 'pa_ii_yyy', 'pa_oo_rrr', 'pa_oo_lll', 'pa_oo_yyy', 'pa_uu_rrr', 'pa_uu_lll', 'pa_uu_yyy', 'pa_ee_rrr', 'pa_ee_lll', 'pa_ee_yyy', 'pa_eueu_rrr', 'pa_eueu_lll', 'pa_eueu_yyy', 'ma_ex_rrr', 'ma_ex_lll', 'ma_ex_yyy', 'ma_ii_rrr', 'ma_ii_lll', 'ma_ii_yyy', 'ma_oo_rrr', 'ma_oo_lll', 'ma_oo_yyy', 'ma_uu_rrr', 'ma_uu_lll', 'ma_uu_yyy', 'ma_ee_rrr', 'ma_ee_lll', 'ma_ee_yyy', 'ma_eueu_rrr', 'ma_eueu_lll', 'ma_eueu_yyy', 'ta_ex_rrr', 'ta_ex_lll', 'ta_ex_yyy', 'ta_ii_rrr', 'ta_ii_lll', 'ta_ii_yyy', 'ta_oo_rrr', 'ta_oo_lll', 'ta_oo_yyy', 'ta_uu_rrr', 'ta_uu_lll', 'ta_uu_yyy', 'ta_ee_rrr', 'ta_ee_lll', 'ta_ee_yyy', 'ta_eueu_rrr', 'ta_eueu_lll', 'ta_eueu_yyy', 'da_ex_rrr', 'da_ex_lll', 'da_ex_yyy', 'da_ii_rrr', 'da_ii_lll', 'da_ii_yyy', 'da_oo_rrr', 'da_oo_lll', 'da_oo_yyy', 'da_uu_rrr', 'da_uu_lll', 'da_uu_yyy', 'da_ee_rrr', 'da_ee_lll', 'da_ee_yyy', 'da_eueu_rrr', 'da_eueu_lll', 'da_eueu_yyy', 'ba_ex_rrr', 'ba_ex_lll', 'ba_ex_yyy', 'ba_ii_rrr', 'ba_ii_lll', 'ba_ii_yyy', 'ba_oo_rrr', 'ba_oo_lll', 'ba_oo_yyy', 'ba_uu_rrr', 'ba_uu_lll', 'ba_uu_yyy', 'ba_ee_rrr', 'ba_ee_lll', 'ba_ee_yyy', 'ba_eueu_rrr', 'ba_eueu_lll', 'ba_eueu_yyy', 'ga_ex_rrr', 'ga_ex_lll', 'ga_ex_yyy', 'ga_ii_rrr', 'ga_ii_lll', 'ga_ii_yyy', 'ga_oo_rrr', 'ga_oo_lll', 'ga_oo_yyy', 'ga_uu_rrr', 'ga_uu_lll', 'ga_uu_yyy', 'ga_ee_rrr', 'ga_ee_lll', 'ga_ee_yyy', 'ga_eueu_rrr', 'ga_eueu_lll', 'ga_eueu_yyy', 'ja_ex_rrr', 'ja_ex_lll', 'ja_ex_yyy', 'ja_ii_rrr', 'ja_ii_lll', 'ja_ii_yyy', 'ja_oo_rrr', 'ja_oo_lll', 'ja_oo_yyy', 'ja_uu_rrr', 'ja_uu_lll', 'ja_uu_yyy', 'ja_ee_rrr', 'ja_ee_lll', 'ja_ee_yyy', 'ra_ii_rrr', 'ra_ii_lll', 'ra_ii_yyy', 'ra_oo_rrr', 'ra_oo_lll', 'ra_oo_yyy', 'ra_uu_rrr', 'ra_uu_lll', 'ra_uu_yyy', 'ra_ee_rrr', 'ra_ee_lll', 'ra_ee_yyy', 'ra_eueu_rrr', 'ra_eueu_lll', 'ra_eueu_yyy', 'la_ex_rrr', 'la_ex_lll', 'la_ex_yyy', 'la_ii_rrr', 'la_ii_lll', 'la_ii_yyy', 'la_oo_rrr', 'la_oo_lll', 'la_oo_yyy', 'la_uu_rrr', 'la_uu_lll', 'la_uu_yyy', 'la_ee_rrr', 'la_ee_lll', 'la_ee_yyy', 'sa_ex_rrr', 'sa_ex_lll', 'sa_ex_yyy', 'sa_ii_rrr', 'sa_ii_lll', 'sa_ii_yyy', 'sa_oo_rrr', 'sa_oo_lll', 'sa_oo_yyy', 'sa_uu_rrr', 'sa_uu_lll', 'sa_uu_yyy', 'sa_ee_rrr', 'sa_ee_lll', 'sa_ee_yyy', 'sa_eueu_rrr', 'sa_eueu_lll', 'sa_eueu_yyy', 'ya_ex_rrr', 'ya_ex_lll', 'ya_ex_yyy', 'ya_ii_rrr', 'ya_ii_lll', 'ya_ii_yyy', 'ya_oo_rrr', 'ya_oo_lll', 'ya_oo_yyy', 'ya_uu_rrr', 'ya_uu_lll', 'ya_uu_yyy', 'ya_ee_rrr', 'ya_ee_lll', 'ya_ee_yyy', 'ya_eueu_rrr', 'ya_eueu_lll', 'ya_eueu_yyy', 'wa_ex_rrr', 'wa_ex_lll', 'wa_ex_yyy', 'wa_ii_rrr', 'wa_ii_lll', 'wa_ii_yyy', 'wa_oo_rrr', 'wa_oo_lll', 'wa_oo_yyy', 'wa_uu_rrr', 'wa_uu_lll', 'wa_uu_yyy', 'wa_ee_rrr', 'wa_ee_lll', 'wa_ee_yyy', 'wa_eueu_rrr', 'wa_eueu_lll', 'wa_eueu_yyy', 'ha_ex_rrr', 'ha_ex_lll', 'ha_ex_yyy', 'ha_ii_rrr', 'ha_ii_lll', 'ha_ii_yyy', 'ha_oo_rrr', 'ha_oo_lll', 'ha_oo_yyy', 'ha_uu_rrr', 'ha_uu_lll', 'ha_uu_yyy', 'ha_ee_rrr', 'ha_ee_lll', 'ha_ee_yyy', 'ha_eueu_rrr', 'ha_eueu_lll', 'ha_eueu_yyy', 'fa_ex_rrr', 'fa_ex_lll', 'fa_ex_yyy', 'fa_ii_rrr', 'fa_ii_lll', 'fa_ii_yyy', 'fa_oo_rrr', 'fa_oo_lll', 'fa_oo_yyy', 'fa_uu_rrr', 'fa_uu_lll', 'fa_ee_rrr', 'fa_ee_lll', 'ca_ii_rrr', 'ca_ii_lll', 'ca_ii_yyy', 'ca_oo_rrr', 'ca_oo_lll', 'ca_oo_yyy', 'ca_uu_rrr', 'ca_uu_lll', 'ca_uu_yyy']\n",
        "base_target_tokens = [\n",
        "    'target',\n",
        "    'nga', 'nge', 'ngu', 'ngi', 'ngé', 'ngo', 'ngeu', 'ng',\n",
        "    'ngah', 'ngang', 'ngar',\n",
        "    'ngeh', 'ngeng', 'nger',\n",
        "    'nguh', 'ngung', 'ngur',\n",
        "    'ngih', 'nging', 'ngir',\n",
        "    'ngéh', 'ngéng', 'ngér',\n",
        "    'ngoh', 'ngong', 'ngor',\n",
        "    'ngeuh', 'ngeung', 'ngeur',\n",
        "    'a', 'i', 'u', 'e', 'o', 'eu', 'é', 'ang', 'ah', 'ar',\n",
        "    'ing', 'ih', 'ir',\n",
        "          'ung', 'uh', 'ur',\n",
        "          'eng', 'eh', 'er',\n",
        "          'ong', 'oh', 'or', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', 'ka', 'na', 'pa', 'ma', 'ta', 'da', 'ba', 'ga', 'ja', 'ra', 'la', 'sa', 'ya', 'wa', 'ha', 'za', 'xa', 'fa', 'va', 'ca', 'nya', 'kha', 'sya', 'qa', 'kang', 'kar', 'kah', 'nang', 'nar', 'nah', 'pang', 'par', 'pah', 'mang', 'mar', 'mah', 'tang', 'tar', 'tah', 'dang', 'dar', 'dah', 'bang', 'bar', 'bah', 'gang', 'gar', 'gah', 'jang', 'jar', 'jah', 'rang', 'rar', 'rah', 'lang', 'lar', 'lah', 'sang', 'sar', 'sah', 'yang', 'yar', 'yah', 'wang', 'war', 'wah', 'hang', 'har', 'hah', 'zang', 'zar', 'zah', 'xang', 'xar', 'xah', 'fang', 'far', 'fah', 'vang', 'var', 'vah', 'cang', 'car', 'cah', 'nyang', 'nyar', 'nyah', 'khang', 'khar', 'khah', 'syang', 'syar', 'syah', 'qang', 'qar', 'qah', 'kra', 'kla', 'kya', 'nra', 'nla', 'nya', 'pra', 'pla', 'pya', 'mra', 'mla', 'mya', 'tra', 'tla', 'tya', 'dra', 'dla', 'dya', 'bra', 'bla', 'bya', 'gra', 'gla', 'gya', 'jra', 'jla', 'jya', 'rra', 'rla', 'rya', 'lra', 'lla', 'lya', 'sra', 'sla', 'sya', 'yra', 'yla', 'yya', 'wra', 'wla', 'wya', 'hra', 'hla', 'hya', 'zra', 'zla', 'zya', 'xra', 'xla', 'xya', 'fra', 'fla', 'fya', 'vra', 'vla', 'vya', 'cra', 'cla', 'cya', 'qra', 'qla', 'qya', 'ké', 'ki', 'ko', 'ku', 'ke', 'keu', 'k', 'né', 'ni', 'no', 'nu', 'ne', 'neu', 'n', 'pé', 'pi', 'po', 'pu', 'pe', 'peu', 'p', 'mé', 'mi', 'mo', 'mu', 'me', 'meu', 'm', 'té', 'ti', 'to', 'tu', 'te', 'teu', 't', 'dé', 'di', 'do', 'du', 'de', 'deu', 'd', 'bé', 'bi', 'bo', 'bu', 'be', 'beu', 'b', 'gé', 'gi', 'go', 'gu', 'ge', 'geu', 'g', 'jé', 'ji', 'jo', 'ju', 'je', 'jeu', 'j', 'ré', 'ri', 'ro', 'ru', 're', 'reu', 'r', 'lé', 'li', 'lo', 'lu', 'le', 'leu', 'l', 'sé', 'si', 'so', 'su', 'se', 'seu', 's', 'yé', 'yi', 'yo', 'yu', 'ye', 'yeu', 'y', 'wé', 'wi', 'wo', 'wu', 'we', 'weu', 'w', 'hé', 'hi', 'ho', 'hu', 'he', 'heu', 'h', 'zé', 'zi', 'zo', 'zu', 'ze', 'zeu', 'z', 'xé', 'xi', 'xo', 'xu', 'xe', 'xeu', 'x', 'fé', 'fi', 'fo', 'fu', 'fe', 'feu', 'f', 'vé', 'vi', 'vo', 'vu', 've', 'veu', 'v', 'cé', 'ci', 'co', 'cu', 'ce', 'ceu', 'c', 'nyé', 'nyi', 'nyo', 'nyu', 'nye', 'nyeu', 'ny', 'khé', 'khi', 'kho', 'khu', 'khe', 'kheu', 'kh', 'syé', 'syi', 'syo', 'syu', 'sye', 'syeu', 'sy', 'qé', 'qi', 'qo', 'qu', 'qe', 'qeu', 'q', 'kéng', 'kér', 'kéh', 'king', 'kir', 'kih', 'kong', 'kor', 'koh', 'kung', 'kur', 'kuh', 'keng', 'ker', 'keh', 'keung', 'keur', 'keuh', 'néng', 'nér', 'néh', 'ning', 'nir', 'nih', 'nong', 'nor', 'noh', 'nung', 'nur', 'nuh', 'neng', 'ner', 'neh', 'neung', 'neur', 'neuh', 'péng', 'pér', 'péh', 'ping', 'pir', 'pih', 'pong', 'por', 'poh', 'pung', 'pur', 'puh', 'peng', 'per', 'peh', 'peung', 'peur', 'peuh', 'méng', 'mér', 'méh', 'ming', 'mir', 'mih', 'mong', 'mor', 'moh', 'mung', 'mur', 'muh', 'meng', 'mer', 'meh', 'meung', 'meur', 'meuh', 'téng', 'tér', 'téh', 'ting', 'tir', 'tih', 'tong', 'tor', 'toh', 'tung', 'tur', 'tuh', 'teng', 'ter', 'teh', 'teung', 'teur', 'teuh', 'déng', 'dér', 'déh', 'ding', 'dir', 'dih', 'dong', 'dor', 'doh', 'dung', 'dur', 'duh', 'deng', 'der', 'deh', 'deung', 'deur', 'deuh', 'béng', 'bér', 'béh', 'bing', 'bir', 'bih', 'bong', 'bor', 'boh', 'bung', 'bur', 'buh', 'beng', 'ber', 'beh', 'beung', 'beur', 'beuh', 'géng', 'gér', 'géh', 'ging', 'gir', 'gih', 'gong', 'gor', 'goh', 'gung', 'gur', 'guh', 'geng', 'ger', 'geh', 'geung', 'geur', 'geuh', 'jéng', 'jér', 'jéh', 'jing', 'jir', 'jih', 'jong', 'jor', 'joh', 'jung', 'jur', 'juh', 'jeng', 'jer', 'jeh', 'jeung', 'jeur', 'jeuh', 'réng', 'rér', 'réh', 'ring', 'rir', 'rih', 'rong', 'ror', 'roh', 'rung', 'rur', 'ruh', 'reng', 'rer', 'reh', 'reung', 'reur', 'reuh', 'léng', 'lér', 'léh', 'ling', 'lir', 'lih', 'long', 'lor', 'loh', 'lung', 'lur', 'luh', 'leng', 'ler', 'leh', 'leung', 'leur', 'leuh', 'séng', 'sér', 'séh', 'sing', 'sir', 'sih', 'song', 'sor', 'soh', 'sung', 'sur', 'suh', 'seng', 'ser', 'seh', 'seung', 'seur', 'seuh', 'yéng', 'yér', 'yéh', 'ying', 'yir', 'yih', 'yong', 'yor', 'yoh', 'yung', 'yur', 'yuh', 'yeng', 'yer', 'yeh', 'yeung', 'yeur', 'yeuh', 'wéng', 'wér', 'wéh', 'wing', 'wir', 'wih', 'wong', 'wor', 'woh', 'wung', 'wur', 'wuh', 'weng', 'wer', 'weh', 'weung', 'weur', 'weuh', 'héng', 'hér', 'héh', 'hing', 'hir', 'hih', 'hong', 'hor', 'hoh', 'hung', 'hur', 'huh', 'heng', 'her', 'heh', 'heung', 'heur', 'heuh', 'zéng', 'zér', 'zéh', 'zing', 'zir', 'zih', 'zong', 'zor', 'zoh', 'zung', 'zur', 'zuh', 'zeng', 'zer', 'zeh', 'zeung', 'zeur', 'zeuh', 'xéng', 'xér', 'xéh', 'xing', 'xir', 'xih', 'féng', 'fér', 'féh', 'fing', 'fir', 'fih', 'fong', 'for', 'foh', 'fung', 'fur', 'fuh', 'feng', 'fer', 'feh', 'feung', 'feur', 'feuh', 'véng', 'vér', 'véh', 'ving', 'vir', 'vih', 'vong', 'vor', 'voh', 'vung', 'vur', 'vuh', 'veng', 'ver', 'veh', 'veung', 'veur', 'veuh', 'céng', 'cér', 'céh', 'cing', 'cir', 'cih', 'cong', 'cor', 'coh', 'cung', 'cur', 'cuh', 'ceng', 'cer', 'ceh', 'ceung', 'ceur', 'ceuh', 'nyéng', 'nyér', 'nyéh', 'nying', 'nyir', 'nyih', 'nyong', 'nyor', 'nyoh', 'nyung', 'nyur', 'nyuh', 'nyeng', 'nyer', 'nyeh', 'nyeung', 'nyeur', 'nyeuh', 'khéng', 'khér', 'khéh', 'kheng', 'kher', 'kheh', 'kheung', 'kheur', 'kheuh', 'syéng', 'syér', 'syéh', 'sying', 'syir', 'syih', 'syong', 'syor', 'syoh', 'syung', 'syur', 'syuh', 'syeng', 'syer', 'syeh', 'syeung', 'syeur', 'syeuh', 'qéng', 'qér', 'qéh', 'qing', 'qir', 'qih', 'qong', 'qor', 'qoh', 'qung', 'qur', 'quh', 'qeng', 'qer', 'qeh', 'qeung', 'qeur', 'qeuh', 'kré', 'klé', 'kyé', 'kri', 'kli', 'kyi', 'kro', 'klo', 'kyo', 'kru', 'klu', 'kyu', 'kre', 'kle', 'kye', 'kreu', 'kleu', 'kyeu', 'nré', 'nlé', 'nyé', 'nri', 'nli', 'nyi', 'nro', 'nlo', 'nyo', 'nru', 'nlu', 'nyu', 'nre', 'nle', 'nye', 'nreu', 'nleu', 'nyeu', 'pré', 'plé', 'pyé', 'pri', 'pli', 'pyi', 'pro', 'plo', 'pyo', 'pru', 'plu', 'pyu', 'pre', 'ple', 'pye', 'preu', 'pleu', 'pyeu', 'mré', 'mlé', 'myé', 'mri', 'mli', 'myi', 'mro', 'mlo', 'myo', 'mru', 'mlu', 'myu', 'mre', 'mle', 'mye', 'mreu', 'mleu', 'myeu', 'tré', 'tlé', 'tyé', 'tri', 'tli', 'tyi', 'tro', 'tlo', 'tyo', 'tru', 'tlu', 'tyu', 'tre', 'tle', 'tye', 'treu', 'tleu', 'tyeu', 'dré', 'dlé', 'dyé', 'dri', 'dli', 'dyi', 'dro', 'dlo', 'dyo', 'dru', 'dlu', 'dyu', 'dre', 'dle', 'dye', 'dreu', 'dleu', 'dyeu', 'bré', 'blé', 'byé', 'bri', 'bli', 'byi', 'bro', 'blo', 'byo', 'bru', 'blu', 'byu', 'bre', 'ble', 'bye', 'breu', 'bleu', 'byeu', 'gré', 'glé', 'gyé', 'gri', 'gli', 'gyi', 'gro', 'glo', 'gyo', 'gru', 'glu', 'gyu', 'gre', 'gle', 'gye', 'greu', 'gleu', 'gyeu', 'jré', 'jlé', 'jyé', 'jri', 'jli', 'jyi', 'jro', 'jlo', 'jyo', 'jru', 'jlu', 'jyu', 'jre', 'jle', 'jye', 'rri', 'rli', 'ryi', 'rro', 'rlo', 'ryo', 'rru', 'rlu', 'ryu', 'rre', 'rle', 'rye', 'rreu', 'rleu', 'ryeu', 'lré', 'llé', 'lyé', 'lri', 'lli', 'lyi', 'lro', 'llo', 'lyo', 'lru', 'llu', 'lyu', 'lre', 'lle', 'lye', 'sré', 'slé', 'syé', 'sri', 'sli', 'syi', 'sro', 'slo', 'syo', 'sru', 'slu', 'syu', 'sre', 'sle', 'sye', 'sreu', 'sleu', 'syeu', 'yré', 'ylé', 'yyé', 'yri', 'yli', 'yyi', 'yro', 'ylo', 'yyo', 'yru', 'ylu', 'yyu', 'yre', 'yle', 'yye', 'yreu', 'yleu', 'yyeu', 'wré', 'wlé', 'wyé', 'wri', 'wli', 'wyi', 'wro', 'wlo', 'wyo', 'wru', 'wlu', 'wyu', 'wre', 'wle', 'wye', 'wreu', 'wleu', 'wyeu', 'hré', 'hlé', 'hyé', 'hri', 'hli', 'hyi', 'hro', 'hlo', 'hyo', 'hru', 'hlu', 'hyu', 'hre', 'hle', 'hye', 'hreu', 'hleu', 'hyeu', 'fré', 'flé', 'fyé', 'fri', 'fli', 'fyi', 'fro', 'flo', 'fyo', 'fru', 'flu', 'fre', 'fle', 'cri', 'cli', 'cyi', 'cro', 'clo', 'cyo', 'cru', 'clu', 'cyu']\n",
        "\n",
        "# dataset generation\n",
        "filename = \"dataset.csv\"\n",
        "with open(filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"source\", \"target\"])\n",
        "\n",
        "    total_rrows = 0\n",
        "    target_rrows = 3000\n",
        "\n",
        "    # First ensure every token is used at least once\n",
        "    for src_token in base_source_tokens:\n",
        "        tgt_token = base_target_tokens[base_source_tokens.index(src_token)]\n",
        "        writer.writerow([src_token.lower(), tgt_token.lower()])\n",
        "        total_rrows += 1\n",
        "\n",
        "    # Then fill remaining rows with random combinations\n",
        "    while total_rrows < target_rrows:\n",
        "        length = random.randint(1, 25)\n",
        "        src_tokens = random.sample(base_source_tokens, k=length)\n",
        "        tgt_tokens = [\n",
        "            base_target_tokens[base_source_tokens.index(w)] if w in base_source_tokens else w\n",
        "            for w in src_tokens\n",
        "        ]\n",
        "        writer.writerow([\" \".join(src_tokens).lower(), \" \".join(tgt_tokens).lower()])\n",
        "        total_rrows += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEbCxyReMbzO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Data Preparation\n",
        "df = pd.read_csv(\"dataset.csv\")\n",
        "\n",
        "# Split into train and test sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "def build_vocab(tokens):\n",
        "    vocab = {tok: i+4 for i, tok in enumerate(tokens)}\n",
        "    vocab[\"<pad>\"] = 0\n",
        "    vocab[\"<sos>\"] = 1\n",
        "    vocab[\"<eos>\"] = 2\n",
        "    vocab[\"<unk>\"] = 3\n",
        "    return vocab\n",
        "\n",
        "source_tokens = [t.lower() for t in df['source'].str.split().explode().unique()]\n",
        "target_tokens = [t.lower() for t in df['target'].str.split().explode().unique()]\n",
        "SRC_VOCAB = build_vocab(source_tokens)\n",
        "TGT_VOCAB = build_vocab(target_tokens)\n",
        "SRC_IVOCAB = {i: t for t, i in SRC_VOCAB.items()}\n",
        "TGT_IVOCAB = {i: t for t, i in TGT_VOCAB.items()}\n",
        "\n",
        "def encode(tokens, vocab):\n",
        "    return [vocab.get(tok, vocab[\"<unk>\"]) for tok in tokens]\n",
        "\n",
        "class Seq2SeqDataset(Dataset):\n",
        "    def __init__(self, df, src_vocab, tgt_vocab):\n",
        "        self.pairs = []\n",
        "        for _, row in df.iterrows():\n",
        "            src = encode(row['source'].split(), src_vocab)\n",
        "            tgt = [tgt_vocab[\"<sos>\"]] + encode(row['target'].split(), tgt_vocab) + [tgt_vocab[\"<eos>\"]]\n",
        "            self.pairs.append((src, tgt))\n",
        "    def __len__(self): return len(self.pairs)\n",
        "    def __getitem__(self, idx): return self.pairs[idx]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    srcs, tgts = zip(*batch)\n",
        "    src_lens = [len(s) for s in srcs]\n",
        "    tgt_lens = [len(t) for t in tgts]\n",
        "    src_pad = torch.zeros(len(srcs), max(src_lens), dtype=torch.long)\n",
        "    tgt_pad = torch.zeros(len(tgts), max(tgt_lens), dtype=torch.long)\n",
        "    for i, (s, t) in enumerate(zip(srcs, tgts)):\n",
        "        src_pad[i, :len(s)] = torch.tensor(s)\n",
        "        tgt_pad[i, :len(t)] = torch.tensor(t)\n",
        "    return src_pad, tgt_pad, src_lens, tgt_lens\n",
        "\n",
        "# Use train_df and test_df to create datasets and loaders\n",
        "train_dataset = Seq2SeqDataset(train_df, SRC_VOCAB, TGT_VOCAB)\n",
        "test_dataset = Seq2SeqDataset(test_df, SRC_VOCAB, TGT_VOCAB)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RG8UsIS0NBJk"
      },
      "outputs": [],
      "source": [
        "# 2. Model Definition\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim, n_layers=1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=SRC_VOCAB[\"<pad>\"])\n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers, bidirectional=True, batch_first=True)\n",
        "    def forward(self, src, src_lens):\n",
        "        emb = self.embedding(src)\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(emb, src_lens, batch_first=True, enforce_sorted=False)\n",
        "        outputs, (h, c) = self.lstm(packed)\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
        "        return outputs, (h, c)\n",
        "\n",
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(enc_hid_dim * 2 + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Parameter(torch.rand(dec_hid_dim))\n",
        "    def forward(self, hidden, encoder_outputs, mask):\n",
        "        src_len = encoder_outputs.size(1)\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "        energy = energy @ self.v\n",
        "        energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        return F.softmax(energy, dim=1)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, enc_hid_dim, dec_hid_dim, attention, n_layers=1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=TGT_VOCAB[\"<pad>\"])\n",
        "        self.lstm = nn.LSTM(emb_dim + enc_hid_dim*2, dec_hid_dim, n_layers, batch_first=True)\n",
        "        self.fc_out = nn.Linear(dec_hid_dim + enc_hid_dim*2 + emb_dim, vocab_size)\n",
        "        self.attention = attention\n",
        "    def forward(self, input, hidden, cell, encoder_outputs, mask):\n",
        "        input = input.unsqueeze(1)\n",
        "        emb = self.embedding(input)\n",
        "        attn_weights = self.attention(hidden[-1], encoder_outputs, mask)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)\n",
        "        lstm_input = torch.cat((emb, attn_applied), dim=2)\n",
        "        output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n",
        "        output = output.squeeze(1)\n",
        "        attn_applied = attn_applied.squeeze(1)\n",
        "        emb = emb.squeeze(1)\n",
        "        pred = self.fc_out(torch.cat((output, attn_applied, emb), dim=1))\n",
        "        return pred, hidden, cell, attn_weights\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.device = device\n",
        "        self.fc_hidden = nn.Linear(encoder.lstm.hidden_size * 2, decoder.lstm.hidden_size)\n",
        "        self.fc_cell = nn.Linear(encoder.lstm.hidden_size * 2, decoder.lstm.hidden_size)\n",
        "    def create_mask(self, src):\n",
        "        return (src != self.src_pad_idx)\n",
        "    def forward(self, src, src_lens, tgt, teacher_forcing_ratio=0.5):\n",
        "        batch_size, tgt_len = tgt.shape\n",
        "        outputs = torch.zeros(batch_size, tgt_len, self.decoder.embedding.num_embeddings).to(self.device)\n",
        "        encoder_outputs, (h, c) = self.encoder(src, src_lens)\n",
        "        h_cat = torch.cat((h[-2,:,:], h[-1,:,:]), dim=1)\n",
        "        c_cat = torch.cat((c[-2,:,:], c[-1,:,:]), dim=1)\n",
        "        h_dec = torch.tanh(self.fc_hidden(h_cat)).unsqueeze(0)\n",
        "        c_dec = torch.tanh(self.fc_cell(c_cat)).unsqueeze(0)\n",
        "        input = tgt[:,0]\n",
        "        mask = self.create_mask(src)\n",
        "        for t in range(1, tgt_len):\n",
        "            output, h_dec, c_dec, _ = self.decoder(input, h_dec, c_dec, encoder_outputs, mask)\n",
        "            outputs[:,t] = output\n",
        "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "            input = tgt[:,t] if teacher_force else top1\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5st3YbQM4NC",
        "outputId": "2b116408-7f35-4afd-96ef-8056a7464a2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 6.5407\n",
            "Epoch 2, Loss: 5.8551\n",
            "Epoch 3, Loss: 5.1080\n",
            "Epoch 4, Loss: 4.2139\n",
            "Epoch 5, Loss: 3.1662\n",
            "Epoch 6, Loss: 2.2130\n",
            "Epoch 7, Loss: 1.5835\n",
            "Epoch 8, Loss: 1.1436\n",
            "Epoch 9, Loss: 0.8184\n",
            "Epoch 10, Loss: 0.6991\n",
            "Epoch 11, Loss: 0.4653\n",
            "Epoch 12, Loss: 0.3527\n",
            "Epoch 13, Loss: 0.3260\n",
            "Epoch 14, Loss: 0.2254\n",
            "Epoch 15, Loss: 0.2324\n",
            "Epoch 16, Loss: 0.2207\n",
            "Epoch 17, Loss: 0.1911\n",
            "Epoch 18, Loss: 0.1521\n",
            "Epoch 19, Loss: 0.1161\n",
            "Epoch 20, Loss: 0.0860\n",
            "Epoch 21, Loss: 0.1263\n",
            "Epoch 22, Loss: 0.0948\n",
            "Epoch 23, Loss: 0.0627\n",
            "Epoch 24, Loss: 0.0575\n",
            "Epoch 25, Loss: 0.0635\n",
            "Epoch 26, Loss: 0.0713\n",
            "Epoch 27, Loss: 0.0821\n",
            "Epoch 28, Loss: 0.0952\n",
            "Epoch 29, Loss: 0.0872\n",
            "Epoch 30, Loss: 0.0582\n",
            "Epoch 31, Loss: 0.0323\n",
            "Epoch 32, Loss: 0.0396\n",
            "Epoch 33, Loss: 0.0222\n",
            "Epoch 34, Loss: 0.0159\n",
            "Epoch 35, Loss: 0.0135\n",
            "Epoch 36, Loss: 0.0069\n",
            "Epoch 37, Loss: 0.0043\n",
            "Epoch 38, Loss: 0.0052\n",
            "Epoch 39, Loss: 0.0036\n",
            "Epoch 40, Loss: 0.0025\n",
            "Epoch 41, Loss: 0.0033\n",
            "Epoch 42, Loss: 0.0040\n",
            "Epoch 43, Loss: 0.0062\n",
            "Epoch 44, Loss: 0.0091\n",
            "Epoch 45, Loss: 0.0232\n",
            "Epoch 46, Loss: 0.0495\n",
            "Epoch 47, Loss: 0.1540\n",
            "Epoch 48, Loss: 0.4041\n",
            "Epoch 49, Loss: 0.2731\n",
            "Epoch 50, Loss: 0.1470\n",
            "Epoch 51, Loss: 0.0923\n",
            "Epoch 52, Loss: 0.0749\n",
            "Epoch 53, Loss: 0.0381\n",
            "Epoch 54, Loss: 0.0105\n",
            "Epoch 55, Loss: 0.0063\n",
            "Epoch 56, Loss: 0.0048\n",
            "Epoch 57, Loss: 0.0023\n",
            "Epoch 58, Loss: 0.0019\n",
            "Epoch 59, Loss: 0.0016\n",
            "Epoch 60, Loss: 0.0014\n",
            "Epoch 61, Loss: 0.0013\n",
            "Epoch 62, Loss: 0.0011\n",
            "Epoch 63, Loss: 0.0010\n",
            "Epoch 64, Loss: 0.0009\n",
            "Epoch 65, Loss: 0.0009\n",
            "Epoch 66, Loss: 0.0008\n",
            "Epoch 67, Loss: 0.0007\n",
            "Epoch 68, Loss: 0.0007\n",
            "Epoch 69, Loss: 0.0006\n",
            "Epoch 70, Loss: 0.0006\n",
            "Epoch 71, Loss: 0.0006\n",
            "Epoch 72, Loss: 0.0005\n",
            "Epoch 73, Loss: 0.0005\n",
            "Epoch 74, Loss: 0.0005\n",
            "Epoch 75, Loss: 0.0004\n",
            "Epoch 76, Loss: 0.0004\n",
            "Epoch 77, Loss: 0.0004\n",
            "Epoch 78, Loss: 0.0004\n",
            "Epoch 79, Loss: 0.0004\n",
            "Epoch 80, Loss: 0.0003\n",
            "Epoch 81, Loss: 0.0003\n",
            "Epoch 82, Loss: 0.0003\n",
            "Epoch 83, Loss: 0.0003\n",
            "Epoch 84, Loss: 0.0003\n",
            "Epoch 85, Loss: 0.0003\n",
            "Epoch 86, Loss: 0.0003\n",
            "Epoch 87, Loss: 0.0002\n",
            "Epoch 88, Loss: 0.0002\n",
            "Epoch 89, Loss: 0.0002\n",
            "Epoch 90, Loss: 0.0002\n",
            "Epoch 91, Loss: 0.0002\n",
            "Epoch 92, Loss: 0.0002\n",
            "Epoch 93, Loss: 0.0002\n",
            "Epoch 94, Loss: 0.0002\n",
            "Epoch 95, Loss: 0.0002\n",
            "Epoch 96, Loss: 0.0002\n",
            "Epoch 97, Loss: 0.0002\n",
            "Epoch 98, Loss: 0.0002\n",
            "Epoch 99, Loss: 0.0001\n",
            "Epoch 100, Loss: 0.0001\n"
          ]
        }
      ],
      "source": [
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "INPUT_DIM = len(SRC_VOCAB)\n",
        "OUTPUT_DIM = len(TGT_VOCAB)\n",
        "ENC_EMB_DIM = 128\n",
        "DEC_EMB_DIM = 128\n",
        "HID_DIM = 256\n",
        "\n",
        "attn = BahdanauAttention(HID_DIM, HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, HID_DIM, attn)\n",
        "model = Seq2Seq(enc, dec, SRC_VOCAB[\"<pad>\"], device).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TGT_VOCAB[\"<pad>\"])\n",
        "\n",
        "def levenshtein(ref, hyp):\n",
        "    m, n = len(ref), len(hyp)\n",
        "    dp = np.zeros((m + 1, n + 1), dtype=int)\n",
        "    for i in range(m + 1):\n",
        "        dp[i][0] = i\n",
        "    for j in range(n + 1):\n",
        "        dp[0][j] = j\n",
        "    for i in range(1, m + 1):\n",
        "        for j in range(1, n + 1):\n",
        "            if ref[i - 1] == hyp[j - 1]:\n",
        "                dp[i][j] = dp[i - 1][j - 1]\n",
        "            else:\n",
        "                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n",
        "    return dp[m][n]\n",
        "\n",
        "# Metric evaluation functions\n",
        "\n",
        "def compute_cer(ref, hyp):\n",
        "    ref = ref.replace(' ', '')\n",
        "    hyp = hyp.replace(' ', '')\n",
        "    if len(ref) == 0:\n",
        "        return 0.0 if len(hyp) == 0 else 1.0\n",
        "    return levenshtein(ref, hyp) / len(ref)\n",
        "\n",
        "def compute_wer(ref, hyp):\n",
        "    ref_words = ref.splyit()\n",
        "    hyp_words = hyp.split()\n",
        "    if len(ref_words) == 0:\n",
        "        return 0.0 if len(hyp_words) == 0 else 1.0\n",
        "    return levenshtein(ref_words, hyp_words) / len(ref_words)\n",
        "\n",
        "# Use train_loader for training\n",
        "best_loss = float('inf')\n",
        "best_model_state = None\n",
        "\n",
        "for epoch in range(150):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    batch_losses = []\n",
        "    for src, tgt, src_lens, tgt_lens in train_loader:\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, src_lens, tgt)\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[:,1:].reshape(-1, output_dim)\n",
        "        tgt = tgt[:,1:].reshape(-1)\n",
        "        loss = criterion(output, tgt)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        batch_losses.append(loss.item())\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n",
        "    # Save the model if it has the lowest loss so far\n",
        "if 1e-6 < avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        best_model_state = model.state_dict()\n",
        "\n",
        "# After training, load the best model\n",
        "if best_model_state is not None:\n",
        "    model.load_state_dict(best_model_state)\n",
        "    print(f\"Loaded best model with loss: {best_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa39-mmNP3qN",
        "outputId": "323e3236-0d3d-4a01-d896-6ae0c347e543"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ke na pa\n"
          ]
        }
      ],
      "source": [
        "def translate(model, src_sentence, max_len=30):\n",
        "    model.eval()\n",
        "    src_tokens = encode(src_sentence.lower().split(), SRC_VOCAB)\n",
        "    src_tensor = torch.tensor(src_tokens).unsqueeze(0).to(device)\n",
        "    src_lens = [len(src_tokens)]\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, (h, c) = model.encoder(src_tensor, src_lens)\n",
        "        h_cat = torch.cat((h[-2,:,:], h[-1,:,:]), dim=1)\n",
        "        c_cat = torch.cat((c[-2,:,:], c[-1,:,:]), dim=1)\n",
        "        h_dec = torch.tanh(model.fc_hidden(h_cat)).unsqueeze(0)\n",
        "        c_dec = torch.tanh(model.fc_cell(c_cat)).unsqueeze(0)\n",
        "        input = torch.tensor([TGT_VOCAB[\"<sos>\"]]).to(device)\n",
        "        mask = model.create_mask(src_tensor)\n",
        "        result = []\n",
        "        for _ in range(max_len):\n",
        "            output, h_dec, c_dec, _ = model.decoder(input, h_dec, c_dec, encoder_outputs, mask)\n",
        "            top1 = output.argmax(1)\n",
        "            if top1.item() == TGT_VOCAB[\"<eos>\"]:\n",
        "                break\n",
        "            result.append(TGT_IVOCAB[top1.item()])\n",
        "            input = top1\n",
        "    return \" \".join(result)\n",
        "\n",
        "# Example usage:\n",
        "print(translate(model, \"ka_ee na pa\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8ha5wx-dF0L",
        "outputId": "57cbda6a-de41-430c-aec7-953513e3f8c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 1:\n",
            "  Source:    ya_ii ra_uu_ll wa_ng xa_ii_r nya_uu fa_oo_h\n",
            "  Target:    yi rlu wang xir nyu foh\n",
            "  Predicted: yi rlu wang xir nyu foh\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 2:\n",
            "  Source:    la_ii_r nya_uu_r la_ii_rr ta_eueu_r sya_eueu_h va_oo_ng wa_ll ba_ex nya_eueu_h nya_ex_r ya_ng\n",
            "  Target:    lir nyur lri teur syeuh vong wla bé nyeuh nyér yang\n",
            "  Predicted: lir nyur lri teur syeuh vong wla bé nyeuh nyér yang\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 3:\n",
            "  Source:    za_eueu_r ja_pamaeh na_ex_yy qa_oo_h ta_ee_yy\n",
            "  Target:    zeur j nyé qoh tye\n",
            "  Predicted: zeur j nyé qoh tye\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 4:\n",
            "  Source:    la_ee\n",
            "  Target:    le\n",
            "  Predicted: le\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 5:\n",
            "  Source:    ra_h pa_ee_rr ba_ee_ng na_ex_r dalapan ga_ee_rr kha_ee_r da_uu_yy da_yy za_uu ya_h sa_ii na_oo_ng ha_ex_ng qa_eueu ca_ii_h ga_eueu ya_rr ya_ex_rr\n",
            "  Target:    rah pre beng nér 8 gre kher dyu dya zu yah si nong héng qeu cih geu yra yré\n",
            "  Predicted: rah pre beng nér 8 gre kher dyu dya zu yah si nong qeu dru geu yra yré\n",
            "  CER: 12.28%, WER: 10.53%\n",
            "\n",
            "Example 6:\n",
            "  Source:    va_ii_ng la_ng la_uu qa_eueu_ng ba_ex_ng ba_ii_ll la_oo_ng ba_eueu_rr fa_ee_h da_uu_ll pa_ee_h fa_rr enol\n",
            "  Target:    ving lang lu qeung béng bli long breu feh dlu peh fra 0\n",
            "  Predicted: ving lang lu qeung béng bli long breu feh dlu peh fra 0\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 7:\n",
            "  Source:    za_uu_r da_ee_r ca_eueu na_oo_yy sa_ex va_oo ya_ng va_ex ca_ii_rr wa_ex_rr nya_oo_ng ga_oo_rr la_oo_r\n",
            "  Target:    zur der ceu nyo sé vo yang vé cri wré nyong gro lor\n",
            "  Predicted: zur der ceu nyo sé vo yang vé cri wré nyong gro lor\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 8:\n",
            "  Source:    na_rr nya_oo sa_oo da_eueu_yy ca_eueu_r kha_ee_h ya_ee_rr ga_ee_yy la_ii_rr ba_ii_ng ga_eueu_h ja_eueu ba_ex_r ra_rr da_uu_h ka_yy pa_ee_r na_ii_h\n",
            "  Target:    nra nyo so dyeu ceur kheh yre gye lri bing geuh jeu bér rra duh kya per nih\n",
            "  Predicted: nra nyo so dyeu ceur kheh yre gye lri bing geuh jeu bér rra duh kya per nuh\n",
            "  CER: 1.72%, WER: 5.56%\n",
            "\n",
            "Example 9:\n",
            "  Source:    ma_uu_ng\n",
            "  Target:    mung\n",
            "  Predicted: mung\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 10:\n",
            "  Source:    ha_ex_yy la_ii_h ca_ee ma_uu_h pa_uu_ng ja_rr ca_ee_r ba_ex_ll sya_ex da_oo ca_oo_h ba_ll ta_ex\n",
            "  Target:    hyé lih ce muh pung jra cer blé syé do coh bla té\n",
            "  Predicted: hyé lih ce muh pung jra cer blé syé do coh coh bla té\n",
            "  CER: 8.11%, WER: 7.69%\n",
            "\n",
            "Example 11:\n",
            "  Source:    ga da_ee_ll\n",
            "  Target:    ga dle\n",
            "  Predicted: ga dle\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 12:\n",
            "  Source:    ma_r\n",
            "  Target:    mar\n",
            "  Predicted: mar\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 13:\n",
            "  Source:    fa_ii_h\n",
            "  Target:    fih\n",
            "  Predicted: fih\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 14:\n",
            "  Source:    ka_rr na_oo ba_oo_h ta_eueu_h ma_uu_r ma_ex_r ra_ee_rr ta_uu ma_ex_yy ta_ex_r ga_rr ca_ii_yy wa_oo_yy\n",
            "  Target:    kra no boh teuh mur mér rre tu myé tér gra cyi wyo\n",
            "  Predicted: kra no boh teuh mur mér rre tu myé tér gra cyi wyo\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 15:\n",
            "  Source:    ka_ii_ng na_eueu da_ee_ll ba_ee za_uu_ng va_ng la_oo_r pa_ii_ll fa_ex_ll ya_uu_yy ta_ii_yy ma_h nya_oo_r kha_ex_ng fa_ii_rr va_ee_h da_r\n",
            "  Target:    king neu dle be zung vang lor pli flé yyu tyi mah nyor khéng fri veh dar\n",
            "  Predicted: king neu dle be zung vang lor pli flé yyu tyi mah nyor khéng fri veh dar\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 16:\n",
            "  Source:    ja_ex_rr\n",
            "  Target:    jré\n",
            "  Predicted: jré\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 17:\n",
            "  Source:    ka_ee_h ra_ex_ng fa_uu kha_ee_h ca_h ra_yy ma_eueu_ll ta_oo_yy wa_r\n",
            "  Target:    keh réng fu kheh cah rya mleu tyo war\n",
            "  Predicted: keh réng fu kheh cah rya mleu tyo war\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 18:\n",
            "  Source:    ga_ex_r\n",
            "  Target:    gér\n",
            "  Predicted: gér\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 19:\n",
            "  Source:    da_ee_rr\n",
            "  Target:    dre\n",
            "  Predicted: dre\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 20:\n",
            "  Source:    ya_ii fa_uu_r dua ha_ii_rr sya_uu_ng tujuh pa_rr wa_uu_r ta_ex_ll qa_eueu_r fa_ee_r sa_yy va_ii_ng ga_ex_rr\n",
            "  Target:    yi fur 2 hri syung 7 pra wur tlé qeur fer sya ving gré\n",
            "  Predicted: yi fur 2 hri syung 7 pra wur tlé qeur fer sya ving gré\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 21:\n",
            "  Source:    ka_h\n",
            "  Target:    kah\n",
            "  Predicted: kah\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 22:\n",
            "  Source:    xa_ex\n",
            "  Target:    xé\n",
            "  Predicted: xé\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 23:\n",
            "  Source:    ja_ee_rr\n",
            "  Target:    jre\n",
            "  Predicted: jre\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 24:\n",
            "  Source:    ra_ng ba_ex_ng ha_eueu nya_eueu_r ya_eueu_ng ba_ii_yy pa_oo_r qa_rr nya_h na_eueu_r wa_ii_h ga_ex_h ba_ee_h nya_ee_h ta_uu_r ta_r nya_ex da_ee_r qa_ex_ng\n",
            "  Target:    rang béng heu nyeur yeung byi por qra nyah neur wih géh beh nyeh tur tar nyé der qéng\n",
            "  Predicted: rang béng heu nyeur yeung byi por qra nyah neur wih géh beh nyeh tur tar nyé der qéng\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 25:\n",
            "  Source:    wa_ii_yy na_uu_rr ra_ee_yy fa_ex_ng ga_rr ja_ex_r ya_ll da_ex\n",
            "  Target:    wyi nru rye féng gra jér yla dé\n",
            "  Predicted: wyi nru rye féng gra jér yla dé\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 26:\n",
            "  Source:    qa_ex_r ha_ee_h ra_ii_ng qa_r ja_rr xa_eueu na_oo_ll ca_ii_rr sa_eueu_ng da_oo_rr ba_ii_yy ja_ee_ll ha_oo_h na_ex_rr fa_oo_r pa_h ba_ee_r wa_eueu_ng\n",
            "  Target:    qér heh ring qar jra xeu nlo cri seung dro byi jle hoh nré for pah ber weung\n",
            "  Predicted: qér heh ring qar jra xeu nlo cri seung dro byi jle hoh nré for pah ber weung\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 27:\n",
            "  Source:    pa_eueu_ll ra_ee_h ka_oo_h da_eueu_yy nya_ii_r ja_ii_yy ba_eueu_yy la_eueu_r da_eueu_r ya_yy sya_uu_r qa_ii_ng sa_ee_yy ha_uu na_oo_ng wa_oo ra_ee_r ja_ee_r sa_eueu_ng ja_eueu\n",
            "  Target:    pleu reh koh dyeu nyir jyi byeu leur deur yya syur qing sye hu nong wo rer jer seung jeu\n",
            "  Predicted: pleu reh koh dyeu nyir jyi byeu leur deur yya syur qing sye hu nong wo rer jer seung jeu\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 28:\n",
            "  Source:    sa_ex sa_ex_rr va_eueu_h\n",
            "  Target:    sé sré veuh\n",
            "  Predicted: sé sré veuh\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 29:\n",
            "  Source:    fa_ex\n",
            "  Target:    fé\n",
            "  Predicted: fé\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 30:\n",
            "  Source:    va_rr za_oo_h ja_ex\n",
            "  Target:    vra zoh jé\n",
            "  Predicted: vra zoh jé\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 31:\n",
            "  Source:    ha_oo_rr\n",
            "  Target:    hro\n",
            "  Predicted: hro\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 32:\n",
            "  Source:    sa_ee_rr ka_eueu_yy kha_oo ga_ex pa_ee_ll fa_ii_ll nya_ex_r ha_ee pa_ll ta_ii ba_ll ja_ee la_oo_ng ha_ex_yy ca_rr ta_eueu_ll la_uu_rr\n",
            "  Target:    sre kyeu kho gé ple fli nyér he pla ti bla je long hyé cra tleu lru\n",
            "  Predicted: sre kyeu kho gé ple fli nyér he pla ti bla je long hyé cra tleu lru\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 33:\n",
            "  Source:    qa_oo_h\n",
            "  Target:    qoh\n",
            "  Predicted: qoh\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 34:\n",
            "  Source:    la_ng sa_ii_rr pa_uu fa_ii sa_ii_h fa_oo_rr dua xa_ex_h ga_ex ya_ii ra_uu_h la_r\n",
            "  Target:    lang sri pu fi sih fro 2 xéh gé yi ruh lar\n",
            "  Predicted: lang sri pu fi sih fro 2 xéh gé yi ruh lar\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 35:\n",
            "  Source:    xa_oo\n",
            "  Target:    xo\n",
            "  Predicted: xo\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 36:\n",
            "  Source:    na_oo_ll\n",
            "  Target:    nlo\n",
            "  Predicted: nlo\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 37:\n",
            "  Source:    ga_ii kha_ex_r ba_rr na_ii_yy ka_oo_rr ha_oo ka_oo_yy ya_ii_ll wa_oo_ll fa_h pa_ee_rr za_ii_ng\n",
            "  Target:    gi khér bra nyi kro ho kyo yli wlo fah pre zing\n",
            "  Predicted: gi khér bra nyi kro ho kyo yli wlo fah fah pre zing\n",
            "  CER: 8.33%, WER: 8.33%\n",
            "\n",
            "Example 38:\n",
            "  Source:    nya_eueu\n",
            "  Target:    nyeu\n",
            "  Predicted: nyeu\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 39:\n",
            "  Source:    fa_oo\n",
            "  Target:    fo\n",
            "  Predicted: fo\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 40:\n",
            "  Source:    ha_ex_rr za_uu pa_ee_h na_ee fa_ex wa_eueu_r da_rr la_ii_h ja_ex_ll ca_uu_ng da_ii_ll pa_ii_yy ga_uu_r na_ii_rr qa xa ja_oo_r\n",
            "  Target:    hré zu peh ne fé weur dra lih jlé cung dli pyi gur nri qa xa jor\n",
            "  Predicted: hré zu peh ne fé weur dra lih jlé cung dli pyi gur nri qa qa yeur jor\n",
            "  CER: 10.42%, WER: 11.76%\n",
            "\n",
            "Example 41:\n",
            "  Source:    pa_uu\n",
            "  Target:    pu\n",
            "  Predicted: pu\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 42:\n",
            "  Source:    ga_ng\n",
            "  Target:    gang\n",
            "  Predicted: gang\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 43:\n",
            "  Source:    pa_ee_ng\n",
            "  Target:    peng\n",
            "  Predicted: peng\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 44:\n",
            "  Source:    sya_oo_r\n",
            "  Target:    syor\n",
            "  Predicted: syor\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 45:\n",
            "  Source:    ka_ii_ng ga_h sya_ii_r ma_eueu_yy va_ee_h ca_oo_ng pa_eueu_ll ra_eueu_r ja_r nya_ii_h wa_ee_rr ha_rr va_ee_ng la_eueu_h\n",
            "  Target:    king gah syir myeu veh cong pleu reur jar nyih wre hra veng leuh\n",
            "  Predicted: king gah syir myeu veh cong pleu reur jar nyih wre hra veng leuh\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 46:\n",
            "  Source:    ya_ex_ll sa_ex ha_ee_r pa_ii_ng ga_uu_ll ka_eueu ja_h sa_ee_ll sa_uu_h ca_r da_ii_r u wa_ex_r da_eueu_ng da_oo_ng wa_uu ha_ee_ll sa_ii ya_h ka_ii_r\n",
            "  Target:    ylé sé her ping glu keu jah sle suh car dir u wér deung dong wu hle si yah kir\n",
            "  Predicted: ylé sé her ping glu keu jah sle suh car u wér wér deung kir hle si yah yah\n",
            "  CER: 22.03%, WER: 25.00%\n",
            "\n",
            "Example 47:\n",
            "  Source:    na_ll sa_ee na_yy genep da_ee_yy wa_oo_yy\n",
            "  Target:    nla se nya 6 dye wyo\n",
            "  Predicted: nla se nya 6 dye wyo\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 48:\n",
            "  Source:    tujuh\n",
            "  Target:    7\n",
            "  Predicted: 7\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 49:\n",
            "  Source:    fa_ee_rr ga_eueu_ng sya_oo_r ra wa_ii_ll ta_eueu_rr sya_eueu_r na_uu_ll na_uu_h ra_ex\n",
            "  Target:    fre geung syor ra wli treu syeur nlu nuh ré\n",
            "  Predicted: fre geung syor ra wli treu syeur nlu nuh ré\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 50:\n",
            "  Source:    ha_ii_r ma_ee_h ba_uu_ng ya_uu_ng ha_eueu_ll tujuh xa_yy xa_ee ha_oo_ng\n",
            "  Target:    hir meh bung yung hleu 7 xya xe hong\n",
            "  Predicted: hir meh bung yung hleu 7 xya xe hong\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 51:\n",
            "  Source:    ya_eueu_h sa_ex_h ha_eueu_r ga_eueu_rr ga_ex_rr wa_uu_yy ca_oo_yy ma_oo_r sya_ee_ng ba_ii_yy sya_r va_h ja_ex_rr\n",
            "  Target:    yeuh séh heur greu gré wyu cyo mor syeng byi syar vah jré\n",
            "  Predicted: yeuh séh heur greu gré wyu cyo mor syeng byi syar vah jré\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 52:\n",
            "  Source:    sa_oo ha_ii_rr ya_rr kha_eueu na_uu_yy ya_uu la_ii_h ka_uu ja_ee_r va_eueu_h na_oo kha_ii ya_ex_ll ka_eueu_h ma_ex_h va_eueu_ng\n",
            "  Target:    so hri yra kheu nyu yu lih ku jer veuh no khi ylé keuh méh veung\n",
            "  Predicted: so hri yra kheu nyu yu lih ku jer veuh no khi khi keuh keuh méh veung\n",
            "  CER: 14.29%, WER: 12.50%\n",
            "\n",
            "Example 53:\n",
            "  Source:    ma_eueu\n",
            "  Target:    meu\n",
            "  Predicted: meu\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 54:\n",
            "  Source:    da_eueu_h ja_ii_h ya_ex\n",
            "  Target:    deuh jih yé\n",
            "  Predicted: deuh jih yé\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 55:\n",
            "  Source:    ya_yy\n",
            "  Target:    yya\n",
            "  Predicted: yya\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 56:\n",
            "  Source:    la_oo_ll ca_ex ca_oo_h ma_ng ca_oo_ll ba_uu_rr ba_oo_ll ba_ii_r ga_ex_rr da_ll sa_oo_ng na_uu_ll ta_oo_ng na_uu_h\n",
            "  Target:    llo cé coh mang clo bru blo bir gré dla song nlu tong nuh\n",
            "  Predicted: llo cé coh mang clo bru blo bir gré dla dla song nlu tong nuh\n",
            "  CER: 6.82%, WER: 7.14%\n",
            "\n",
            "Example 57:\n",
            "  Source:    na_ii_yy wa_ee ga_ee_yy da_uu_rr ja_ex_ll wa_uu_r ga_oo_ng ga_uu qa_pamaeh pa_eueu_ng fa_ee wa_oo_h da da_ex_yy va_uu_h za_oo_r\n",
            "  Target:    nyi we gye dru jlé wur gong gu q peung fe woh da dyé vuh zor\n",
            "  Predicted: nyi we gye dru jlé wur gong gu q peung fe woh da dyé vuh zor\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 58:\n",
            "  Source:    ka_eueu_ll\n",
            "  Target:    kleu\n",
            "  Predicted: kleu\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 59:\n",
            "  Source:    ra_ii_ng fa_uu_ll pa_uu_h na_ex_yy sa_yy la_ex_ng kha_r nya_h za_ee ta_ee_rr\n",
            "  Target:    ring flu puh nyé sya léng khar nyah ze tre\n",
            "  Predicted: ring flu puh nyé sya léng khar nyah ze tre\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 60:\n",
            "  Source:    ha_ex_yy\n",
            "  Target:    hyé\n",
            "  Predicted: hyé\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 61:\n",
            "  Source:    kha_eueu_r\n",
            "  Target:    kheur\n",
            "  Predicted: kheur\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 62:\n",
            "  Source:    ha_eueu_ng\n",
            "  Target:    heung\n",
            "  Predicted: heung\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 63:\n",
            "  Source:    ta_ee_yy\n",
            "  Target:    tye\n",
            "  Predicted: tye\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 64:\n",
            "  Source:    ya_eueu\n",
            "  Target:    yeu\n",
            "  Predicted: yeu\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 65:\n",
            "  Source:    ma_ng\n",
            "  Target:    mang\n",
            "  Predicted: mang\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 66:\n",
            "  Source:    na_ll kha_ex sa ga_ii_ll\n",
            "  Target:    nla khé sa gli\n",
            "  Predicted: nla khé sa gli\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 67:\n",
            "  Source:    za_uu_r ba_uu_ll qa_ee_ng za_uu la_ii_r pa_eueu_ng nya_eueu_h nya_eueu_ng nya_oo_ng\n",
            "  Target:    zur blu qeng zu lir peung nyeuh nyeung nyong\n",
            "  Predicted: zur blu qeng zu lir peung nyeuh nyeung nyong\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 68:\n",
            "  Source:    la_ex sya_oo ta_r ha_ex kha_oo ha_ee_ll ka_ll pa_oo ta_uu_yy ya_eueu_rr da_ee_rr da_oo_yy\n",
            "  Target:    lé syo tar hé kho hle kla po tyu yreu dre dyo\n",
            "  Predicted: lé syo tar hé kho hle kla po tyu yreu dre dyo\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 69:\n",
            "  Source:    fa_eueu\n",
            "  Target:    feu\n",
            "  Predicted: feu\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 70:\n",
            "  Source:    ra_ee_h\n",
            "  Target:    reh\n",
            "  Predicted: reh\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 71:\n",
            "  Source:    ta_uu ba_ex_yy\n",
            "  Target:    tu byé\n",
            "  Predicted: tu byé\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 72:\n",
            "  Source:    ra_ee_rr pa_ee_yy qa_ii la_ee pa_ex_ll ja_ex nya_oo_ng fa_eueu pa_eueu_rr ha sya_ii sya_ee_ng ka_uu_yy ya_r\n",
            "  Target:    rre pye qi le plé jé nyong feu preu ha syi syeng kyu yar\n",
            "  Predicted: rre pye qi le plé jé nyong feu preu ha syi syeng kyu yar\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 73:\n",
            "  Source:    sa_ii_ng ha_oo_rr ga_ee_r fa_yy na_oo_yy nya_eueu sa_ee_r pa_ii_ll pa_oo_h da_ex_ng qa_ee_ng ja_ex xa_ex_r\n",
            "  Target:    sing hro ger fya nyo nyeu ser pli poh déng qeng jé xér\n",
            "  Predicted: sing hro ger fya nyo nyeu ser pli poh déng qeng jé xér\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 74:\n",
            "  Source:    pa_eueu_yy va_oo kha_ex ca_eueu_h ka_eueu ca_uu_h\n",
            "  Target:    pyeu vo khé ceuh keu cuh\n",
            "  Predicted: pyeu vo khé ceuh keu cuh\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 75:\n",
            "  Source:    nya_ng\n",
            "  Target:    nyang\n",
            "  Predicted: nyang\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 76:\n",
            "  Source:    nya_ex_h\n",
            "  Target:    nyéh\n",
            "  Predicted: nyéh\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 77:\n",
            "  Source:    ha_ex_r na_eueu_rr na ja_uu_h wa_ii ma_ee_r qa_ee_h sya_oo_h na_ex sa_uu_yy pa_ee ya_uu_rr ka_oo_h ga_uu_ll ga pa_ii\n",
            "  Target:    hér nreu na juh wi mer qeh syoh né syu pe yru koh glu ga pi\n",
            "  Predicted: hér nreu na juh wi mer qeh syoh né syu pe yru koh glu ga pi\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 78:\n",
            "  Source:    enol ra_uu_ng ka na_rr ya_oo_r ja_ng kha_ee_h\n",
            "  Target:    0 rung ka nra yor jang kheh\n",
            "  Predicted: 0 rung ka nra yor jang kheh\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 79:\n",
            "  Source:    ha_ii_ng ga_ex_h pa_eueu xa_ll ha_yy ja_uu_h ta_uu_ng ca_ee_r ha_oo_rr na_ex_ll ma_rr sa_ex_ll ja_eueu_h ha_eueu_ll va_uu_h fa_oo_ng\n",
            "  Target:    hing géh peu xla hya juh tung cer hro nlé mra slé jeuh hleu vuh fong\n",
            "  Predicted: hing géh peu xla hya juh tung cer hro nlé mra slé jeuh hleu vuh fong\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 80:\n",
            "  Source:    sa_oo_h ra_uu wa_ii_rr ha_ex_ll va_ee_ng wa_ii_h ha_ex za_eueu na_uu_ng wa_ll wa_h va_eueu_r ta_ii_ng\n",
            "  Target:    soh ru wri hlé veng wih hé zeu nung wla wah veur ting\n",
            "  Predicted: soh ru wri hlé veng wih hé zeu nung wla wah veur ting\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 81:\n",
            "  Source:    ra_ee_ll za_h fa_ii_h ya_ee_yy ca_uu_ll ra_oo_yy ba_ll ca_uu_yy wa_rr xa_h sa_ex_h\n",
            "  Target:    rle zah fih yye clu ryo bla cyu wra xah séh\n",
            "  Predicted: rle zah fih yye clu ryo bla cyu wra xah séh\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 82:\n",
            "  Source:    da_ii_ng\n",
            "  Target:    ding\n",
            "  Predicted: ding\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 83:\n",
            "  Source:    pa_ex_yy\n",
            "  Target:    pyé\n",
            "  Predicted: pyé\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 84:\n",
            "  Source:    ga_uu_ng ma_oo_ll\n",
            "  Target:    gung mlo\n",
            "  Predicted: gung mlo\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 85:\n",
            "  Source:    ta_ii_ll za_ii ja_ee_yy wa_oo_rr sa_r qa_ii_ng sa_ex_h o za_ee ga_rr ta_eueu_yy sya_ee na_ee ba_oo_ng\n",
            "  Target:    tli zi jye wro sar qing séh o ze gra tyeu sye ne bong\n",
            "  Predicted: tli zi jye wro sar qing séh o ze gra tyeu sye ne bong\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 86:\n",
            "  Source:    la_rr\n",
            "  Target:    lra\n",
            "  Predicted: lra\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 87:\n",
            "  Source:    sa_ee_ll ha_eueu_r la_ex_r\n",
            "  Target:    sle heur lér\n",
            "  Predicted: sle heur lér\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 88:\n",
            "  Source:    wa_ex_yy ca_eueu_h fa_ex_yy\n",
            "  Target:    wyé ceuh fyé\n",
            "  Predicted: wyé ceuh fyé\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 89:\n",
            "  Source:    dalapan va_oo sa_ii_ll ka_eueu_rr fa_ex_ng wa_rr nya_ee kha_r da_eueu_r pa_ii pa_ex_h na_ee_r la_ii_yy\n",
            "  Target:    8 vo sli kreu féng wra nye khar deur pi péh ner lyi\n",
            "  Predicted: 8 vo sli kreu féng wra nye khar deur pi péh ner lyi\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 90:\n",
            "  Source:    ca_oo_ll fa_eueu_ng wa_ii_ng ga_ee_h ba_ii_r\n",
            "  Target:    clo feung wing geh bir\n",
            "  Predicted: clo feung wing geh bir\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 91:\n",
            "  Source:    nya_ee\n",
            "  Target:    nye\n",
            "  Predicted: nye\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 92:\n",
            "  Source:    ha_uu_h o xa_eueu na_ex_yy sa_uu_ll ba_ex_r ka_oo_ll qa_ex_r ga_ex_yy ta_pamaeh ta_ex xa_ex_ng qa_eueu_r ka_ee_ng ga_oo_ng ca_r va_ex_ng ba_ii_r kha_ee_r ca_h\n",
            "  Target:    huh o xeu nyé slu bér klo qér gyé t té xéng qeur keng gong car véng bir kher cah\n",
            "  Predicted: huh o xeu nyé slu bér klo qér gyé t té xéng qeur keng gong véng bir kher cah\n",
            "  CER: 4.92%, WER: 5.00%\n",
            "\n",
            "Example 93:\n",
            "  Source:    sa_oo_h sa_uu_h la_uu_ng kha_uu wa_eueu ma_ex_ng ma_rr qa_ex ca_eueu_r ka_uu_r na_ii_ll ja_uu_h qa_oo_r\n",
            "  Target:    soh suh lung khu weu méng mra qé ceur kur nli juh qor\n",
            "  Predicted: soh suh lung khu weu méng mra qé ceur kur nli juh qor\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 94:\n",
            "  Source:    ra_uu_rr nya_pamaeh ba_eueu_ng kha_ee_r ma_ex_ng ga_ex_r za ra_oo_ng fa_ee_r xa_h ya_uu wa_oo_ng sa_eueu_ll ba_uu_ng sa_oo_h ya_ex_yy ja_ii_yy ba_ee_h va_uu_ng ha_ex_ll\n",
            "  Target:    rru ny beung kher méng gér za rong fer xah yu wong sleu bung soh yyé jyi beh vung hlé\n",
            "  Predicted: rru ny beung kher méng gér za rong fer xah yu wong sleu bung soh jyi jyi beh hlé\n",
            "  CER: 9.09%, WER: 10.00%\n",
            "\n",
            "Example 95:\n",
            "  Source:    fa_uu_ng wa_eueu_rr sya_oo_r sya_ee_ng za_ex_h sa_ii_yy qa_ee_r ja_h na_ii_ll ra_eueu_r qa_uu kha_ii ma_uu_ng da ha_oo_yy ja_ee_yy ba_ex_h ga_ee_yy qa_ii ha_uu_yy\n",
            "  Target:    fung wreu syor syeng zéh syi qer jah nli reur qu khi mung da hyo jye béh gye qi hyu\n",
            "  Predicted: fung wreu syor syeng zéh syi qer jah nli reur qu khi mung da hyo jye béh gye qi\n",
            "  CER: 4.69%, WER: 5.00%\n",
            "\n",
            "Example 96:\n",
            "  Source:    ma_eueu_h\n",
            "  Target:    meuh\n",
            "  Predicted: meuh\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 97:\n",
            "  Source:    ya_yy wa_ee_r la_oo da_rr ga_ee_r ba_ee wa_oo_h sa_oo_yy la_ee_rr ga_rr za kha_oo ra_uu_rr da_ee_ll la_ee_ng kha_ex_r la_eueu_ng la_ii_ng\n",
            "  Target:    yya wer lo dra ger be woh syo lre gra za kho rru dle leng khér leung ling\n",
            "  Predicted: yya wer lo dra ger be woh syo lre gra za kho rru dle leng leng khér leung ling\n",
            "  CER: 7.14%, WER: 5.56%\n",
            "\n",
            "Example 98:\n",
            "  Source:    ja_ll\n",
            "  Target:    jla\n",
            "  Predicted: jla\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 99:\n",
            "  Source:    qa_rr\n",
            "  Target:    qra\n",
            "  Predicted: qra\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 100:\n",
            "  Source:    fa_yy wa_eueu_ng ya_ex_r fa_oo_rr ra_eueu_yy ma_oo_r ka_uu_r la_uu_ll ba_oo_rr ca_ii_h za_ex wa_ii\n",
            "  Target:    fya weung yér fro ryeu mor kur llu bro cih zé wi\n",
            "  Predicted: fya weung yér fro ryeu mor kur llu bro cih zé wi\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "CER: 1.27%, WER: 1.28%\n"
          ]
        }
      ],
      "source": [
        "    model.eval()\n",
        "    total_cer = 0\n",
        "    total_wer = 0\n",
        "    n_samples = 0\n",
        "    with torch.no_grad():\n",
        "        example_printed = 0\n",
        "        for src, tgt, src_lens, tgt_lens in test_loader:\n",
        "            src = src.to(device)\n",
        "            for i in range(src.size(0)):\n",
        "                src_sentence = ' '.join([SRC_IVOCAB[idx.item()] for idx in src[i] if idx.item() != SRC_VOCAB[\"<pad>\"]])\n",
        "                tgt_sentence = ' '.join([TGT_IVOCAB[idx.item()] for idx in tgt[i] if idx.item() not in [TGT_VOCAB[\"<pad>\"], TGT_VOCAB[\"<sos>\"], TGT_VOCAB[\"<eos>\"]]])\n",
        "                pred_sentence = translate(model, src_sentence)\n",
        "                cer = compute_cer(tgt_sentence, pred_sentence)\n",
        "                wer = compute_wer(tgt_sentence, pred_sentence)\n",
        "                total_cer += cer\n",
        "                total_wer += wer\n",
        "                n_samples += 1\n",
        "                # Print a few examples\n",
        "                if example_printed < 100:\n",
        "                    print(f\"Example {example_printed+1}:\")\n",
        "                    print(f\"  Source:    {src_sentence}\")\n",
        "                    print(f\"  Target:    {tgt_sentence}\")\n",
        "                    print(f\"  Predicted: {pred_sentence}\")\n",
        "                    print(f\"  CER: {cer:.2%}, WER: {wer:.2%}\\n\")\n",
        "                    example_printed += 1\n",
        "    print(f\"CER: {total_cer/n_samples:.2%}, WER: {total_wer/n_samples:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJV6DG2my7H_"
      },
      "outputs": [],
      "source": [
        "# Save only the model weights\n",
        "torch.save(model.state_dict(), \"seq2seq_model_bi_attention.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BKfSfdZzEOx"
      },
      "outputs": [],
      "source": [
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    # Optionally, save epoch, loss, etc.\n",
        "    'epoch': epoch,\n",
        "    'loss': loss,\n",
        "}, \"seq2seq_checkpoint_bi_attention.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSrnmi2bzEHy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
