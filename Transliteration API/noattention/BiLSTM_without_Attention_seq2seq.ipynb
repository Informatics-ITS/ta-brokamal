{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5B7IqwMEyfvO"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import random\n",
        "\n",
        "base_source_tokens = ['source', 'a', 'i', 'u', 'e', 'o', 'eu', 'é', 'a_ng', 'a_hh', 'a_rr',\n",
        "          'i_ng', 'i_hh', 'i_rr',\n",
        "          'u_ng', 'u_hh', 'u_rr',\n",
        "          'e_ng', 'e_hh', 'e_rr',\n",
        "          'o_ng', 'o_hh', 'o_rr','hiji', 'dua', 'tilu', 'opat', 'lima', 'genep', 'tujuh', 'dalapan', 'salapan', 'enol', 'ka', 'na', 'pa', 'ma', 'ta', 'da', 'ba', 'ga', 'ja', 'ra', 'la', 'sa', 'ya', 'wa', 'ha', 'za', 'xa', 'fa', 'va', 'ca', 'nya', 'kha', 'sya', 'qa', 'ka_ng', 'ka_rr', 'ka_hh', 'na_ng', 'na_rr', 'na_hh', 'pa_ng', 'pa_rr', 'pa_hh', 'ma_ng', 'ma_rr', 'ma_hh', 'ta_ng', 'ta_rr', 'ta_hh', 'da_ng', 'da_rr', 'da_hh', 'ba_ng', 'ba_rr', 'ba_hh', 'ga_ng', 'ga_rr', 'ga_hh', 'ja_ng', 'ja_rr', 'ja_hh', 'ra_ng', 'ra_rr', 'ra_hh', 'la_ng', 'la_rr', 'la_hh', 'sa_ng', 'sa_rr', 'sa_hh', 'ya_ng', 'ya_rr', 'ya_hh', 'wa_ng', 'wa_rr', 'wa_hh', 'ha_ng', 'ha_rr', 'ha_hh', 'za_ng', 'za_rr', 'za_hh', 'xa_ng', 'xa_rr', 'xa_hh', 'fa_ng', 'fa_rr', 'fa_hh', 'va_ng', 'va_rr', 'va_hh', 'ca_ng', 'ca_rr', 'ca_hh', 'nya_ng', 'nya_rr', 'nya_hh', 'kha_ng', 'kha_rr', 'kha_hh', 'sya_ng', 'sya_rr', 'sya_hh', 'qa_ng', 'qa_rr', 'qa_hh', 'ka_rrr', 'ka_lll', 'ka_yyy', 'na_rrr', 'na_lll', 'na_yyy', 'pa_rrr', 'pa_lll', 'pa_yyy', 'ma_rrr', 'ma_lll', 'ma_yyy', 'ta_rrr', 'ta_lll', 'ta_yyy', 'da_rrr', 'da_lll', 'da_yyy', 'ba_rrr', 'ba_lll', 'ba_yyy', 'ga_rrr', 'ga_lll', 'ga_yyy', 'ja_rrr', 'ja_lll', 'ja_yyy', 'ra_rrr', 'ra_lll', 'ra_yyy', 'la_rrr', 'la_lll', 'la_yyy', 'sa_rrr', 'sa_lll', 'sa_yyy', 'ya_rrr', 'ya_lll', 'ya_yyy', 'wa_rrr', 'wa_lll', 'wa_yyy', 'ha_rrr', 'ha_lll', 'ha_yyy', 'za_rrr', 'za_lll', 'za_yyy', 'xa_rrr', 'xa_lll', 'xa_yyy', 'fa_rrr', 'fa_lll', 'fa_yyy', 'va_rrr', 'va_lll', 'va_yyy', 'ca_rrr', 'ca_lll', 'ca_yyy', 'qa_rrr', 'qa_lll', 'qa_yyy', 'ka_ex', 'ka_ii', 'ka_oo', 'ka_uu', 'ka_ee', 'ka_eueu', 'ka_pamaeh', 'na_ex', 'na_ii', 'na_oo', 'na_uu', 'na_ee', 'na_eueu', 'na_pamaeh', 'pa_ex', 'pa_ii', 'pa_oo', 'pa_uu', 'pa_ee', 'pa_eueu', 'pa_pamaeh', 'ma_ex', 'ma_ii', 'ma_oo', 'ma_uu', 'ma_ee', 'ma_eueu', 'ma_pamaeh', 'ta_ex', 'ta_ii', 'ta_oo', 'ta_uu', 'ta_ee', 'ta_eueu', 'ta_pamaeh', 'da_ex', 'da_ii', 'da_oo', 'da_uu', 'da_ee', 'da_eueu', 'da_pamaeh', 'ba_ex', 'ba_ii', 'ba_oo', 'ba_uu', 'ba_ee', 'ba_eueu', 'ba_pamaeh', 'ga_ex', 'ga_ii', 'ga_oo', 'ga_uu', 'ga_ee', 'ga_eueu', 'ga_pamaeh', 'ja_ex', 'ja_ii', 'ja_oo', 'ja_uu', 'ja_ee', 'ja_eueu', 'ja_pamaeh', 'ra_ex', 'ra_ii', 'ra_oo', 'ra_uu', 'ra_ee', 'ra_eueu', 'ra_pamaeh', 'la_ex', 'la_ii', 'la_oo', 'la_uu', 'la_ee', 'la_eueu', 'la_pamaeh', 'sa_ex', 'sa_ii', 'sa_oo', 'sa_uu', 'sa_ee', 'sa_eueu', 'sa_pamaeh', 'ya_ex', 'ya_ii', 'ya_oo', 'ya_uu', 'ya_ee', 'ya_eueu', 'ya_pamaeh', 'wa_ex', 'wa_ii', 'wa_oo', 'wa_uu', 'wa_ee', 'wa_eueu', 'wa_pamaeh', 'ha_ex', 'ha_ii', 'ha_oo', 'ha_uu', 'ha_ee', 'ha_eueu', 'ha_pamaeh', 'za_ex', 'za_ii', 'za_oo', 'za_uu', 'za_ee', 'za_eueu', 'za_pamaeh', 'xa_ex', 'xa_ii', 'xa_oo', 'xa_uu', 'xa_ee', 'xa_eueu', 'xa_pamaeh', 'fa_ex', 'fa_ii', 'fa_oo', 'fa_uu', 'fa_ee', 'fa_eueu', 'fa_pamaeh', 'va_ex', 'va_ii', 'va_oo', 'va_uu', 'va_ee', 'va_eueu', 'va_pamaeh', 'ca_ex', 'ca_ii', 'ca_oo', 'ca_uu', 'ca_ee', 'ca_eueu', 'ca_pamaeh', 'nya_ex', 'nya_ii', 'nya_oo', 'nya_uu', 'nya_ee', 'nya_eueu', 'nya_pamaeh', 'kha_ex', 'kha_ii', 'kha_oo', 'kha_uu', 'kha_ee', 'kha_eueu', 'kha_pamaeh', 'sya_ex', 'sya_ii', 'sya_oo', 'sya_uu', 'sya_ee', 'sya_eueu', 'sya_pamaeh', 'qa_ex', 'qa_ii', 'qa_oo', 'qa_uu', 'qa_ee', 'qa_eueu', 'qa_pamaeh', 'ka_ex_ng', 'ka_ex_rr', 'ka_ex_hh', 'ka_ii_ng', 'ka_ii_rr', 'ka_ii_hh', 'ka_oo_ng', 'ka_oo_rr', 'ka_oo_hh', 'ka_uu_ng', 'ka_uu_rr', 'ka_uu_hh', 'ka_ee_ng', 'ka_ee_rr', 'ka_ee_hh', 'ka_eueu_ng', 'ka_eueu_rr', 'ka_eueu_hh', 'na_ex_ng', 'na_ex_rr', 'na_ex_hh', 'na_ii_ng', 'na_ii_rr', 'na_ii_hh', 'na_oo_ng', 'na_oo_rr', 'na_oo_hh', 'na_uu_ng', 'na_uu_rr', 'na_uu_hh', 'na_ee_ng', 'na_ee_rr', 'na_ee_hh', 'na_eueu_ng', 'na_eueu_rr', 'na_eueu_hh', 'pa_ex_ng', 'pa_ex_rr', 'pa_ex_hh', 'pa_ii_ng', 'pa_ii_rr', 'pa_ii_hh', 'pa_oo_ng', 'pa_oo_rr', 'pa_oo_hh', 'pa_uu_ng', 'pa_uu_rr', 'pa_uu_hh', 'pa_ee_ng', 'pa_ee_rr', 'pa_ee_hh', 'pa_eueu_ng', 'pa_eueu_rr', 'pa_eueu_hh', 'ma_ex_ng', 'ma_ex_rr', 'ma_ex_hh', 'ma_ii_ng', 'ma_ii_rr', 'ma_ii_hh', 'ma_oo_ng', 'ma_oo_rr', 'ma_oo_hh', 'ma_uu_ng', 'ma_uu_rr', 'ma_uu_hh', 'ma_ee_ng', 'ma_ee_rr', 'ma_ee_hh', 'ma_eueu_ng', 'ma_eueu_rr', 'ma_eueu_hh', 'ta_ex_ng', 'ta_ex_rr', 'ta_ex_hh', 'ta_ii_ng', 'ta_ii_rr', 'ta_ii_hh', 'ta_oo_ng', 'ta_oo_rr', 'ta_oo_hh', 'ta_uu_ng', 'ta_uu_rr', 'ta_uu_hh', 'ta_ee_ng', 'ta_ee_rr', 'ta_ee_hh', 'ta_eueu_ng', 'ta_eueu_rr', 'ta_eueu_hh', 'da_ex_ng', 'da_ex_rr', 'da_ex_hh', 'da_ii_ng', 'da_ii_rr', 'da_ii_hh', 'da_oo_ng', 'da_oo_rr', 'da_oo_hh', 'da_uu_ng', 'da_uu_rr', 'da_uu_hh', 'da_ee_ng', 'da_ee_rr', 'da_ee_hh', 'da_eueu_ng', 'da_eueu_rr', 'da_eueu_hh', 'ba_ex_ng', 'ba_ex_rr', 'ba_ex_hh', 'ba_ii_ng', 'ba_ii_rr', 'ba_ii_hh', 'ba_oo_ng', 'ba_oo_rr', 'ba_oo_hh', 'ba_uu_ng', 'ba_uu_rr', 'ba_uu_hh', 'ba_ee_ng', 'ba_ee_rr', 'ba_ee_hh', 'ba_eueu_ng', 'ba_eueu_rr', 'ba_eueu_hh', 'ga_ex_ng', 'ga_ex_rr', 'ga_ex_hh', 'ga_ii_ng', 'ga_ii_rr', 'ga_ii_hh', 'ga_oo_ng', 'ga_oo_rr', 'ga_oo_hh', 'ga_uu_ng', 'ga_uu_rr', 'ga_uu_hh', 'ga_ee_ng', 'ga_ee_rr', 'ga_ee_hh', 'ga_eueu_ng', 'ga_eueu_rr', 'ga_eueu_hh', 'ja_ex_ng', 'ja_ex_rr', 'ja_ex_hh', 'ja_ii_ng', 'ja_ii_rr', 'ja_ii_hh', 'ja_oo_ng', 'ja_oo_rr', 'ja_oo_hh', 'ja_uu_ng', 'ja_uu_rr', 'ja_uu_hh', 'ja_ee_ng', 'ja_ee_rr', 'ja_ee_hh', 'ja_eueu_ng', 'ja_eueu_rr', 'ja_eueu_hh', 'ra_ex_ng', 'ra_ex_rr', 'ra_ex_hh', 'ra_ii_ng', 'ra_ii_rr', 'ra_ii_hh', 'ra_oo_ng', 'ra_oo_rr', 'ra_oo_hh', 'ra_uu_ng', 'ra_uu_rr', 'ra_uu_hh', 'ra_ee_ng', 'ra_ee_rr', 'ra_ee_hh', 'ra_eueu_ng', 'ra_eueu_rr', 'ra_eueu_hh', 'la_ex_ng', 'la_ex_rr', 'la_ex_hh', 'la_ii_ng', 'la_ii_rr', 'la_ii_hh', 'la_oo_ng', 'la_oo_rr', 'la_oo_hh', 'la_uu_ng', 'la_uu_rr', 'la_uu_hh', 'la_ee_ng', 'la_ee_rr', 'la_ee_hh', 'la_eueu_ng', 'la_eueu_rr', 'la_eueu_hh', 'sa_ex_ng', 'sa_ex_rr', 'sa_ex_hh', 'sa_ii_ng', 'sa_ii_rr', 'sa_ii_hh', 'sa_oo_ng', 'sa_oo_rr', 'sa_oo_hh', 'sa_uu_ng', 'sa_uu_rr', 'sa_uu_hh', 'sa_ee_ng', 'sa_ee_rr', 'sa_ee_hh', 'sa_eueu_ng', 'sa_eueu_rr', 'sa_eueu_hh', 'ya_ex_ng', 'ya_ex_rr', 'ya_ex_hh', 'ya_ii_ng', 'ya_ii_rr', 'ya_ii_hh', 'ya_oo_ng', 'ya_oo_rr', 'ya_oo_hh', 'ya_uu_ng', 'ya_uu_rr', 'ya_uu_hh', 'ya_ee_ng', 'ya_ee_rr', 'ya_ee_hh', 'ya_eueu_ng', 'ya_eueu_rr', 'ya_eueu_hh', 'wa_ex_ng', 'wa_ex_rr', 'wa_ex_hh', 'wa_ii_ng', 'wa_ii_rr', 'wa_ii_hh', 'wa_oo_ng', 'wa_oo_rr', 'wa_oo_hh', 'wa_uu_ng', 'wa_uu_rr', 'wa_uu_hh', 'wa_ee_ng', 'wa_ee_rr', 'wa_ee_hh', 'wa_eueu_ng', 'wa_eueu_rr', 'wa_eueu_hh', 'ha_ex_ng', 'ha_ex_rr', 'ha_ex_hh', 'ha_ii_ng', 'ha_ii_rr', 'ha_ii_hh', 'ha_oo_ng', 'ha_oo_rr', 'ha_oo_hh', 'ha_uu_ng', 'ha_uu_rr', 'ha_uu_hh', 'ha_ee_ng', 'ha_ee_rr', 'ha_ee_hh', 'ha_eueu_ng', 'ha_eueu_rr', 'ha_eueu_hh', 'za_ex_ng', 'za_ex_rr', 'za_ex_hh', 'za_ii_ng', 'za_ii_rr', 'za_ii_hh', 'za_oo_ng', 'za_oo_rr', 'za_oo_hh', 'za_uu_ng', 'za_uu_rr', 'za_uu_hh', 'za_ee_ng', 'za_ee_rr', 'za_ee_hh', 'za_eueu_ng', 'za_eueu_rr', 'za_eueu_hh', 'xa_ex_ng', 'xa_ex_rr', 'xa_ex_hh', 'xa_ii_ng', 'xa_ii_rr', 'xa_ii_hh', 'fa_ex_ng', 'fa_ex_rr', 'fa_ex_hh', 'fa_ii_ng', 'fa_ii_rr', 'fa_ii_hh', 'fa_oo_ng', 'fa_oo_rr', 'fa_oo_hh', 'fa_uu_ng', 'fa_uu_rr', 'fa_uu_hh', 'fa_ee_ng', 'fa_ee_rr', 'fa_ee_hh', 'fa_eueu_ng', 'fa_eueu_rr', 'fa_eueu_hh', 'va_ex_ng', 'va_ex_rr', 'va_ex_hh', 'va_ii_ng', 'va_ii_rr', 'va_ii_hh', 'va_oo_ng', 'va_oo_rr', 'va_oo_hh', 'va_uu_ng', 'va_uu_rr', 'va_uu_hh', 'va_ee_ng', 'va_ee_rr', 'va_ee_hh', 'va_eueu_ng', 'va_eueu_rr', 'va_eueu_hh', 'ca_ex_ng', 'ca_ex_rr', 'ca_ex_hh', 'ca_ii_ng', 'ca_ii_rr', 'ca_ii_hh', 'ca_oo_ng', 'ca_oo_rr', 'ca_oo_hh', 'ca_uu_ng', 'ca_uu_rr', 'ca_uu_hh', 'ca_ee_ng', 'ca_ee_rr', 'ca_ee_hh', 'ca_eueu_ng', 'ca_eueu_rr', 'ca_eueu_hh', 'nya_ex_ng', 'nya_ex_rr', 'nya_ex_hh', 'nya_ii_ng', 'nya_ii_rr', 'nya_ii_hh', 'nya_oo_ng', 'nya_oo_rr', 'nya_oo_hh', 'nya_uu_ng', 'nya_uu_rr', 'nya_uu_hh', 'nya_ee_ng', 'nya_ee_rr', 'nya_ee_hh', 'nya_eueu_ng', 'nya_eueu_rr', 'nya_eueu_hh', 'kha_ex_ng', 'kha_ex_rr', 'kha_ex_hh', 'kha_ee_ng', 'kha_ee_rr', 'kha_ee_hh', 'kha_eueu_ng', 'kha_eueu_rr', 'kha_eueu_hh', 'sya_ex_ng', 'sya_ex_rr', 'sya_ex_hh', 'sya_ii_ng', 'sya_ii_rr', 'sya_ii_hh', 'sya_oo_ng', 'sya_oo_rr', 'sya_oo_hh', 'sya_uu_ng', 'sya_uu_rr', 'sya_uu_hh', 'sya_ee_ng', 'sya_ee_rr', 'sya_ee_hh', 'sya_eueu_ng', 'sya_eueu_rr', 'sya_eueu_hh', 'qa_ex_ng', 'qa_ex_rr', 'qa_ex_hh', 'qa_ii_ng', 'qa_ii_rr', 'qa_ii_hh', 'qa_oo_ng', 'qa_oo_rr', 'qa_oo_hh', 'qa_uu_ng', 'qa_uu_rr', 'qa_uu_hh', 'qa_ee_ng', 'qa_ee_rr', 'qa_ee_hh', 'qa_eueu_ng', 'qa_eueu_rr', 'qa_eueu_hh', 'ka_ex_rrr', 'ka_ex_lll', 'ka_ex_yyy', 'ka_ii_rrr', 'ka_ii_lll', 'ka_ii_yyy', 'ka_oo_rrr', 'ka_oo_lll', 'ka_oo_yyy', 'ka_uu_rrr', 'ka_uu_lll', 'ka_uu_yyy', 'ka_ee_rrr', 'ka_ee_lll', 'ka_ee_yyy', 'ka_eueu_rrr', 'ka_eueu_lll', 'ka_eueu_yyy', 'na_ex_rrr', 'na_ex_lll', 'na_ex_yyy', 'na_ii_rrr', 'na_ii_lll', 'na_ii_yyy', 'na_oo_rrr', 'na_oo_lll', 'na_oo_yyy', 'na_uu_rrr', 'na_uu_lll', 'na_uu_yyy', 'na_ee_rrr', 'na_ee_lll', 'na_ee_yyy', 'na_eueu_rrr', 'na_eueu_lll', 'na_eueu_yyy', 'pa_ex_rrr', 'pa_ex_lll', 'pa_ex_yyy', 'pa_ii_rrr', 'pa_ii_lll', 'pa_ii_yyy', 'pa_oo_rrr', 'pa_oo_lll', 'pa_oo_yyy', 'pa_uu_rrr', 'pa_uu_lll', 'pa_uu_yyy', 'pa_ee_rrr', 'pa_ee_lll', 'pa_ee_yyy', 'pa_eueu_rrr', 'pa_eueu_lll', 'pa_eueu_yyy', 'ma_ex_rrr', 'ma_ex_lll', 'ma_ex_yyy', 'ma_ii_rrr', 'ma_ii_lll', 'ma_ii_yyy', 'ma_oo_rrr', 'ma_oo_lll', 'ma_oo_yyy', 'ma_uu_rrr', 'ma_uu_lll', 'ma_uu_yyy', 'ma_ee_rrr', 'ma_ee_lll', 'ma_ee_yyy', 'ma_eueu_rrr', 'ma_eueu_lll', 'ma_eueu_yyy', 'ta_ex_rrr', 'ta_ex_lll', 'ta_ex_yyy', 'ta_ii_rrr', 'ta_ii_lll', 'ta_ii_yyy', 'ta_oo_rrr', 'ta_oo_lll', 'ta_oo_yyy', 'ta_uu_rrr', 'ta_uu_lll', 'ta_uu_yyy', 'ta_ee_rrr', 'ta_ee_lll', 'ta_ee_yyy', 'ta_eueu_rrr', 'ta_eueu_lll', 'ta_eueu_yyy', 'da_ex_rrr', 'da_ex_lll', 'da_ex_yyy', 'da_ii_rrr', 'da_ii_lll', 'da_ii_yyy', 'da_oo_rrr', 'da_oo_lll', 'da_oo_yyy', 'da_uu_rrr', 'da_uu_lll', 'da_uu_yyy', 'da_ee_rrr', 'da_ee_lll', 'da_ee_yyy', 'da_eueu_rrr', 'da_eueu_lll', 'da_eueu_yyy', 'ba_ex_rrr', 'ba_ex_lll', 'ba_ex_yyy', 'ba_ii_rrr', 'ba_ii_lll', 'ba_ii_yyy', 'ba_oo_rrr', 'ba_oo_lll', 'ba_oo_yyy', 'ba_uu_rrr', 'ba_uu_lll', 'ba_uu_yyy', 'ba_ee_rrr', 'ba_ee_lll', 'ba_ee_yyy', 'ba_eueu_rrr', 'ba_eueu_lll', 'ba_eueu_yyy', 'ga_ex_rrr', 'ga_ex_lll', 'ga_ex_yyy', 'ga_ii_rrr', 'ga_ii_lll', 'ga_ii_yyy', 'ga_oo_rrr', 'ga_oo_lll', 'ga_oo_yyy', 'ga_uu_rrr', 'ga_uu_lll', 'ga_uu_yyy', 'ga_ee_rrr', 'ga_ee_lll', 'ga_ee_yyy', 'ga_eueu_rrr', 'ga_eueu_lll', 'ga_eueu_yyy', 'ja_ex_rrr', 'ja_ex_lll', 'ja_ex_yyy', 'ja_ii_rrr', 'ja_ii_lll', 'ja_ii_yyy', 'ja_oo_rrr', 'ja_oo_lll', 'ja_oo_yyy', 'ja_uu_rrr', 'ja_uu_lll', 'ja_uu_yyy', 'ja_ee_rrr', 'ja_ee_lll', 'ja_ee_yyy', 'ra_ii_rrr', 'ra_ii_lll', 'ra_ii_yyy', 'ra_oo_rrr', 'ra_oo_lll', 'ra_oo_yyy', 'ra_uu_rrr', 'ra_uu_lll', 'ra_uu_yyy', 'ra_ee_rrr', 'ra_ee_lll', 'ra_ee_yyy', 'ra_eueu_rrr', 'ra_eueu_lll', 'ra_eueu_yyy', 'la_ex_rrr', 'la_ex_lll', 'la_ex_yyy', 'la_ii_rrr', 'la_ii_lll', 'la_ii_yyy', 'la_oo_rrr', 'la_oo_lll', 'la_oo_yyy', 'la_uu_rrr', 'la_uu_lll', 'la_uu_yyy', 'la_ee_rrr', 'la_ee_lll', 'la_ee_yyy', 'sa_ex_rrr', 'sa_ex_lll', 'sa_ex_yyy', 'sa_ii_rrr', 'sa_ii_lll', 'sa_ii_yyy', 'sa_oo_rrr', 'sa_oo_lll', 'sa_oo_yyy', 'sa_uu_rrr', 'sa_uu_lll', 'sa_uu_yyy', 'sa_ee_rrr', 'sa_ee_lll', 'sa_ee_yyy', 'sa_eueu_rrr', 'sa_eueu_lll', 'sa_eueu_yyy', 'ya_ex_rrr', 'ya_ex_lll', 'ya_ex_yyy', 'ya_ii_rrr', 'ya_ii_lll', 'ya_ii_yyy', 'ya_oo_rrr', 'ya_oo_lll', 'ya_oo_yyy', 'ya_uu_rrr', 'ya_uu_lll', 'ya_uu_yyy', 'ya_ee_rrr', 'ya_ee_lll', 'ya_ee_yyy', 'ya_eueu_rrr', 'ya_eueu_lll', 'ya_eueu_yyy', 'wa_ex_rrr', 'wa_ex_lll', 'wa_ex_yyy', 'wa_ii_rrr', 'wa_ii_lll', 'wa_ii_yyy', 'wa_oo_rrr', 'wa_oo_lll', 'wa_oo_yyy', 'wa_uu_rrr', 'wa_uu_lll', 'wa_uu_yyy', 'wa_ee_rrr', 'wa_ee_lll', 'wa_ee_yyy', 'wa_eueu_rrr', 'wa_eueu_lll', 'wa_eueu_yyy', 'ha_ex_rrr', 'ha_ex_lll', 'ha_ex_yyy', 'ha_ii_rrr', 'ha_ii_lll', 'ha_ii_yyy', 'ha_oo_rrr', 'ha_oo_lll', 'ha_oo_yyy', 'ha_uu_rrr', 'ha_uu_lll', 'ha_uu_yyy', 'ha_ee_rrr', 'ha_ee_lll', 'ha_ee_yyy', 'ha_eueu_rrr', 'ha_eueu_lll', 'ha_eueu_yyy', 'fa_ex_rrr', 'fa_ex_lll', 'fa_ex_yyy', 'fa_ii_rrr', 'fa_ii_lll', 'fa_ii_yyy', 'fa_oo_rrr', 'fa_oo_lll', 'fa_oo_yyy', 'fa_uu_rrr', 'fa_uu_lll', 'fa_ee_rrr', 'fa_ee_lll', 'ca_ii_rrr', 'ca_ii_lll', 'ca_ii_yyy', 'ca_oo_rrr', 'ca_oo_lll', 'ca_oo_yyy', 'ca_uu_rrr', 'ca_uu_lll', 'ca_uu_yyy']\n",
        "base_target_tokens = ['target', 'a', 'i', 'u', 'e', 'o', 'eu', 'é' ,'ang', 'ah', 'ar',\n",
        "          'ing', 'ih', 'ir',\n",
        "          'ung', 'uh', 'ur',\n",
        "          'eng', 'eh', 'er',\n",
        "          'ong', 'oh', 'or', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', 'ka', 'na', 'pa', 'ma', 'ta', 'da', 'ba', 'ga', 'ja', 'ra', 'la', 'sa', 'ya', 'wa', 'ha', 'za', 'xa', 'fa', 'va', 'ca', 'nya', 'kha', 'sya', 'qa', 'kang', 'kar', 'kah', 'nang', 'nar', 'nah', 'pang', 'par', 'pah', 'mang', 'mar', 'mah', 'tang', 'tar', 'tah', 'dang', 'dar', 'dah', 'bang', 'bar', 'bah', 'gang', 'gar', 'gah', 'jang', 'jar', 'jah', 'rang', 'rar', 'rah', 'lang', 'lar', 'lah', 'sang', 'sar', 'sah', 'yang', 'yar', 'yah', 'wang', 'war', 'wah', 'hang', 'har', 'hah', 'zang', 'zar', 'zah', 'xang', 'xar', 'xah', 'fang', 'far', 'fah', 'vang', 'var', 'vah', 'cang', 'car', 'cah', 'nyang', 'nyar', 'nyah', 'khang', 'khar', 'khah', 'syang', 'syar', 'syah', 'qang', 'qar', 'qah', 'kra', 'kla', 'kya', 'nra', 'nla', 'nya', 'pra', 'pla', 'pya', 'mra', 'mla', 'mya', 'tra', 'tla', 'tya', 'dra', 'dla', 'dya', 'bra', 'bla', 'bya', 'gra', 'gla', 'gya', 'jra', 'jla', 'jya', 'rra', 'rla', 'rya', 'lra', 'lla', 'lya', 'sra', 'sla', 'sya', 'yra', 'yla', 'yya', 'wra', 'wla', 'wya', 'hra', 'hla', 'hya', 'zra', 'zla', 'zya', 'xra', 'xla', 'xya', 'fra', 'fla', 'fya', 'vra', 'vla', 'vya', 'cra', 'cla', 'cya', 'qra', 'qla', 'qya', 'ké', 'ki', 'ko', 'ku', 'ke', 'keu', 'k', 'né', 'ni', 'no', 'nu', 'ne', 'neu', 'n', 'pé', 'pi', 'po', 'pu', 'pe', 'peu', 'p', 'mé', 'mi', 'mo', 'mu', 'me', 'meu', 'm', 'té', 'ti', 'to', 'tu', 'te', 'teu', 't', 'dé', 'di', 'do', 'du', 'de', 'deu', 'd', 'bé', 'bi', 'bo', 'bu', 'be', 'beu', 'b', 'gé', 'gi', 'go', 'gu', 'ge', 'geu', 'g', 'jé', 'ji', 'jo', 'ju', 'je', 'jeu', 'j', 'ré', 'ri', 'ro', 'ru', 're', 'reu', 'r', 'lé', 'li', 'lo', 'lu', 'le', 'leu', 'l', 'sé', 'si', 'so', 'su', 'se', 'seu', 's', 'yé', 'yi', 'yo', 'yu', 'ye', 'yeu', 'y', 'wé', 'wi', 'wo', 'wu', 'we', 'weu', 'w', 'hé', 'hi', 'ho', 'hu', 'he', 'heu', 'h', 'zé', 'zi', 'zo', 'zu', 'ze', 'zeu', 'z', 'xé', 'xi', 'xo', 'xu', 'xe', 'xeu', 'x', 'fé', 'fi', 'fo', 'fu', 'fe', 'feu', 'f', 'vé', 'vi', 'vo', 'vu', 've', 'veu', 'v', 'cé', 'ci', 'co', 'cu', 'ce', 'ceu', 'c', 'nyé', 'nyi', 'nyo', 'nyu', 'nye', 'nyeu', 'ny', 'khé', 'khi', 'kho', 'khu', 'khe', 'kheu', 'kh', 'syé', 'syi', 'syo', 'syu', 'sye', 'syeu', 'sy', 'qé', 'qi', 'qo', 'qu', 'qe', 'qeu', 'q', 'kéng', 'kér', 'kéh', 'king', 'kir', 'kih', 'kong', 'kor', 'koh', 'kung', 'kur', 'kuh', 'keng', 'ker', 'keh', 'keung', 'keur', 'keuh', 'néng', 'nér', 'néh', 'ning', 'nir', 'nih', 'nong', 'nor', 'noh', 'nung', 'nur', 'nuh', 'neng', 'ner', 'neh', 'neung', 'neur', 'neuh', 'péng', 'pér', 'péh', 'ping', 'pir', 'pih', 'pong', 'por', 'poh', 'pung', 'pur', 'puh', 'peng', 'per', 'peh', 'peung', 'peur', 'peuh', 'méng', 'mér', 'méh', 'ming', 'mir', 'mih', 'mong', 'mor', 'moh', 'mung', 'mur', 'muh', 'meng', 'mer', 'meh', 'meung', 'meur', 'meuh', 'téng', 'tér', 'téh', 'ting', 'tir', 'tih', 'tong', 'tor', 'toh', 'tung', 'tur', 'tuh', 'teng', 'ter', 'teh', 'teung', 'teur', 'teuh', 'déng', 'dér', 'déh', 'ding', 'dir', 'dih', 'dong', 'dor', 'doh', 'dung', 'dur', 'duh', 'deng', 'der', 'deh', 'deung', 'deur', 'deuh', 'béng', 'bér', 'béh', 'bing', 'bir', 'bih', 'bong', 'bor', 'boh', 'bung', 'bur', 'buh', 'beng', 'ber', 'beh', 'beung', 'beur', 'beuh', 'géng', 'gér', 'géh', 'ging', 'gir', 'gih', 'gong', 'gor', 'goh', 'gung', 'gur', 'guh', 'geng', 'ger', 'geh', 'geung', 'geur', 'geuh', 'jéng', 'jér', 'jéh', 'jing', 'jir', 'jih', 'jong', 'jor', 'joh', 'jung', 'jur', 'juh', 'jeng', 'jer', 'jeh', 'jeung', 'jeur', 'jeuh', 'réng', 'rér', 'réh', 'ring', 'rir', 'rih', 'rong', 'ror', 'roh', 'rung', 'rur', 'ruh', 'reng', 'rer', 'reh', 'reung', 'reur', 'reuh', 'léng', 'lér', 'léh', 'ling', 'lir', 'lih', 'long', 'lor', 'loh', 'lung', 'lur', 'luh', 'leng', 'ler', 'leh', 'leung', 'leur', 'leuh', 'séng', 'sér', 'séh', 'sing', 'sir', 'sih', 'song', 'sor', 'soh', 'sung', 'sur', 'suh', 'seng', 'ser', 'seh', 'seung', 'seur', 'seuh', 'yéng', 'yér', 'yéh', 'ying', 'yir', 'yih', 'yong', 'yor', 'yoh', 'yung', 'yur', 'yuh', 'yeng', 'yer', 'yeh', 'yeung', 'yeur', 'yeuh', 'wéng', 'wér', 'wéh', 'wing', 'wir', 'wih', 'wong', 'wor', 'woh', 'wung', 'wur', 'wuh', 'weng', 'wer', 'weh', 'weung', 'weur', 'weuh', 'héng', 'hér', 'héh', 'hing', 'hir', 'hih', 'hong', 'hor', 'hoh', 'hung', 'hur', 'huh', 'heng', 'her', 'heh', 'heung', 'heur', 'heuh', 'zéng', 'zér', 'zéh', 'zing', 'zir', 'zih', 'zong', 'zor', 'zoh', 'zung', 'zur', 'zuh', 'zeng', 'zer', 'zeh', 'zeung', 'zeur', 'zeuh', 'xéng', 'xér', 'xéh', 'xing', 'xir', 'xih', 'féng', 'fér', 'féh', 'fing', 'fir', 'fih', 'fong', 'for', 'foh', 'fung', 'fur', 'fuh', 'feng', 'fer', 'feh', 'feung', 'feur', 'feuh', 'véng', 'vér', 'véh', 'ving', 'vir', 'vih', 'vong', 'vor', 'voh', 'vung', 'vur', 'vuh', 'veng', 'ver', 'veh', 'veung', 'veur', 'veuh', 'céng', 'cér', 'céh', 'cing', 'cir', 'cih', 'cong', 'cor', 'coh', 'cung', 'cur', 'cuh', 'ceng', 'cer', 'ceh', 'ceung', 'ceur', 'ceuh', 'nyéng', 'nyér', 'nyéh', 'nying', 'nyir', 'nyih', 'nyong', 'nyor', 'nyoh', 'nyung', 'nyur', 'nyuh', 'nyeng', 'nyer', 'nyeh', 'nyeung', 'nyeur', 'nyeuh', 'khéng', 'khér', 'khéh', 'kheng', 'kher', 'kheh', 'kheung', 'kheur', 'kheuh', 'syéng', 'syér', 'syéh', 'sying', 'syir', 'syih', 'syong', 'syor', 'syoh', 'syung', 'syur', 'syuh', 'syeng', 'syer', 'syeh', 'syeung', 'syeur', 'syeuh', 'qéng', 'qér', 'qéh', 'qing', 'qir', 'qih', 'qong', 'qor', 'qoh', 'qung', 'qur', 'quh', 'qeng', 'qer', 'qeh', 'qeung', 'qeur', 'qeuh', 'kré', 'klé', 'kyé', 'kri', 'kli', 'kyi', 'kro', 'klo', 'kyo', 'kru', 'klu', 'kyu', 'kre', 'kle', 'kye', 'kreu', 'kleu', 'kyeu', 'nré', 'nlé', 'nyé', 'nri', 'nli', 'nyi', 'nro', 'nlo', 'nyo', 'nru', 'nlu', 'nyu', 'nre', 'nle', 'nye', 'nreu', 'nleu', 'nyeu', 'pré', 'plé', 'pyé', 'pri', 'pli', 'pyi', 'pro', 'plo', 'pyo', 'pru', 'plu', 'pyu', 'pre', 'ple', 'pye', 'preu', 'pleu', 'pyeu', 'mré', 'mlé', 'myé', 'mri', 'mli', 'myi', 'mro', 'mlo', 'myo', 'mru', 'mlu', 'myu', 'mre', 'mle', 'mye', 'mreu', 'mleu', 'myeu', 'tré', 'tlé', 'tyé', 'tri', 'tli', 'tyi', 'tro', 'tlo', 'tyo', 'tru', 'tlu', 'tyu', 'tre', 'tle', 'tye', 'treu', 'tleu', 'tyeu', 'dré', 'dlé', 'dyé', 'dri', 'dli', 'dyi', 'dro', 'dlo', 'dyo', 'dru', 'dlu', 'dyu', 'dre', 'dle', 'dye', 'dreu', 'dleu', 'dyeu', 'bré', 'blé', 'byé', 'bri', 'bli', 'byi', 'bro', 'blo', 'byo', 'bru', 'blu', 'byu', 'bre', 'ble', 'bye', 'breu', 'bleu', 'byeu', 'gré', 'glé', 'gyé', 'gri', 'gli', 'gyi', 'gro', 'glo', 'gyo', 'gru', 'glu', 'gyu', 'gre', 'gle', 'gye', 'greu', 'gleu', 'gyeu', 'jré', 'jlé', 'jyé', 'jri', 'jli', 'jyi', 'jro', 'jlo', 'jyo', 'jru', 'jlu', 'jyu', 'jre', 'jle', 'jye', 'rri', 'rli', 'ryi', 'rro', 'rlo', 'ryo', 'rru', 'rlu', 'ryu', 'rre', 'rle', 'rye', 'rreu', 'rleu', 'ryeu', 'lré', 'llé', 'lyé', 'lri', 'lli', 'lyi', 'lro', 'llo', 'lyo', 'lru', 'llu', 'lyu', 'lre', 'lle', 'lye', 'sré', 'slé', 'syé', 'sri', 'sli', 'syi', 'sro', 'slo', 'syo', 'sru', 'slu', 'syu', 'sre', 'sle', 'sye', 'sreu', 'sleu', 'syeu', 'yré', 'ylé', 'yyé', 'yri', 'yli', 'yyi', 'yro', 'ylo', 'yyo', 'yru', 'ylu', 'yyu', 'yre', 'yle', 'yye', 'yreu', 'yleu', 'yyeu', 'wré', 'wlé', 'wyé', 'wri', 'wli', 'wyi', 'wro', 'wlo', 'wyo', 'wru', 'wlu', 'wyu', 'wre', 'wle', 'wye', 'wreu', 'wleu', 'wyeu', 'hré', 'hlé', 'hyé', 'hri', 'hli', 'hyi', 'hro', 'hlo', 'hyo', 'hru', 'hlu', 'hyu', 'hre', 'hle', 'hye', 'hreu', 'hleu', 'hyeu', 'fré', 'flé', 'fyé', 'fri', 'fli', 'fyi', 'fro', 'flo', 'fyo', 'fru', 'flu', 'fre', 'fle', 'cri', 'cli', 'cyi', 'cro', 'clo', 'cyo', 'cru', 'clu', 'cyu']\n",
        "\n",
        "# dataset generation\n",
        "filename = \"dataset.csv\"\n",
        "with open(filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"source\", \"target\"])\n",
        "\n",
        "    total_rrows = 0\n",
        "    target_rrows = 3000\n",
        "\n",
        "    # First ensure every token is used at least once\n",
        "    for src_token in base_source_tokens:\n",
        "        tgt_token = base_target_tokens[base_source_tokens.index(src_token)]\n",
        "        writer.writerow([src_token.lower(), tgt_token.lower()])\n",
        "        total_rrows += 1\n",
        "\n",
        "    # Then fill remaining rows with random combinations\n",
        "    while total_rrows < target_rrows:\n",
        "        length = random.randint(1, 30)\n",
        "        src_tokens = random.sample(base_source_tokens, k=length)\n",
        "        tgt_tokens = [\n",
        "            base_target_tokens[base_source_tokens.index(w)] if w in base_source_tokens else w\n",
        "            for w in src_tokens\n",
        "        ]\n",
        "        writer.writerow([\" \".join(src_tokens).lower(), \" \".join(tgt_tokens).lower()])\n",
        "        total_rrows += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vJ8sY47yxxb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Data Preparation\n",
        "df = pd.read_csv(\"dataset.csv\")\n",
        "\n",
        "# Split into train and test sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "def build_vocab(tokens):\n",
        "    vocab = {tok: i+4 for i, tok in enumerate(tokens)}\n",
        "    vocab[\"<pad>\"] = 0\n",
        "    vocab[\"<sos>\"] = 1\n",
        "    vocab[\"<eos>\"] = 2\n",
        "    vocab[\"<unk>\"] = 3\n",
        "    return vocab\n",
        "\n",
        "source_tokens = [t.lower() for t in df['source'].str.split().explode().unique()]\n",
        "target_tokens = [t.lower() for t in df['target'].str.split().explode().unique()]\n",
        "SRC_VOCAB = build_vocab(source_tokens)\n",
        "TGT_VOCAB = build_vocab(target_tokens)\n",
        "SRC_IVOCAB = {i: t for t, i in SRC_VOCAB.items()}\n",
        "TGT_IVOCAB = {i: t for t, i in TGT_VOCAB.items()}\n",
        "\n",
        "def encode(tokens, vocab):\n",
        "    return [vocab.get(tok, vocab[\"<unk>\"]) for tok in tokens]\n",
        "\n",
        "class Seq2SeqDataset(Dataset):\n",
        "    def __init__(self, df, src_vocab, tgt_vocab):\n",
        "        self.pairs = []\n",
        "        for _, row in df.iterrows():\n",
        "            src = encode(row['source'].split(), src_vocab)\n",
        "            tgt = [tgt_vocab[\"<sos>\"]] + encode(row['target'].split(), tgt_vocab) + [tgt_vocab[\"<eos>\"]]\n",
        "            self.pairs.append((src, tgt))\n",
        "    def __len__(self): return len(self.pairs)\n",
        "    def __getitem__(self, idx): return self.pairs[idx]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    srcs, tgts = zip(*batch)\n",
        "    src_lens = [len(s) for s in srcs]\n",
        "    tgt_lens = [len(t) for t in tgts]\n",
        "    src_pad = torch.zeros(len(srcs), max(src_lens), dtype=torch.long)\n",
        "    tgt_pad = torch.zeros(len(tgts), max(tgt_lens), dtype=torch.long)\n",
        "    for i, (s, t) in enumerate(zip(srcs, tgts)):\n",
        "        src_pad[i, :len(s)] = torch.tensor(s)\n",
        "        tgt_pad[i, :len(t)] = torch.tensor(t)\n",
        "    return src_pad, tgt_pad, src_lens, tgt_lens\n",
        "\n",
        "# Use train_df and test_df to create datasets and loaders\n",
        "train_dataset = Seq2SeqDataset(train_df, SRC_VOCAB, TGT_VOCAB)\n",
        "test_dataset = Seq2SeqDataset(test_df, SRC_VOCAB, TGT_VOCAB)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXho7Wo5y24F"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 2. Model Definition\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim, n_layers=1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=SRC_VOCAB[\"<pad>\"])\n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers, bidirectional=True, batch_first=True)\n",
        "    def forward(self, src, src_lens):\n",
        "        emb = self.embedding(src)\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(emb, src_lens, batch_first=True, enforce_sorted=False)\n",
        "        outputs, (h, c) = self.lstm(packed)\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
        "        return outputs, (h, c)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, dec_hid_dim, n_layers=1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=TGT_VOCAB[\"<pad>\"])\n",
        "        self.lstm = nn.LSTM(emb_dim, dec_hid_dim, n_layers, batch_first=True)\n",
        "        self.fc_out = nn.Linear(dec_hid_dim, vocab_size)\n",
        "    def forward(self, input, hidden, cell):\n",
        "        input = input.unsqueeze(1)\n",
        "        emb = self.embedding(input)\n",
        "        output, (hidden, cell) = self.lstm(emb, (hidden, cell))\n",
        "        output = output.squeeze(1)\n",
        "        pred = self.fc_out(output)\n",
        "        return pred, hidden, cell\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.device = device\n",
        "        self.fc_hidden = nn.Linear(encoder.lstm.hidden_size * 2, decoder.lstm.hidden_size)\n",
        "        self.fc_cell = nn.Linear(encoder.lstm.hidden_size * 2, decoder.lstm.hidden_size)\n",
        "    def forward(self, src, src_lens, tgt, teacher_forcing_ratio=0.5):\n",
        "        batch_size, tgt_len = tgt.shape\n",
        "        outputs = torch.zeros(batch_size, tgt_len, self.decoder.embedding.num_embeddings).to(self.device)\n",
        "        encoder_outputs, (h, c) = self.encoder(src, src_lens)\n",
        "        h_cat = torch.cat((h[-2,:,:], h[-1,:,:]), dim=1)\n",
        "        c_cat = torch.cat((c[-2,:,:], c[-1,:,:]), dim=1)\n",
        "        h_dec = torch.tanh(self.fc_hidden(h_cat)).unsqueeze(0)\n",
        "        c_dec = torch.tanh(self.fc_cell(c_cat)).unsqueeze(0)\n",
        "        input = tgt[:,0]\n",
        "        for t in range(1, tgt_len):\n",
        "            output, h_dec, c_dec = self.decoder(input, h_dec, c_dec)\n",
        "            outputs[:,t] = output\n",
        "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "            input = tgt[:,t] if teacher_force else top1\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY7SZY1wy5c6",
        "outputId": "d516a743-de04-4504-9b8a-220a04dadbba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 6.5901\n",
            "Epoch 2, Loss: 6.2643\n",
            "Epoch 3, Loss: 6.1655\n",
            "Epoch 4, Loss: 6.0946\n",
            "Epoch 5, Loss: 6.0053\n",
            "Epoch 6, Loss: 5.8933\n",
            "Epoch 7, Loss: 5.7493\n",
            "Epoch 8, Loss: 5.5648\n",
            "Epoch 9, Loss: 5.3578\n",
            "Epoch 10, Loss: 5.1571\n",
            "Epoch 11, Loss: 4.9410\n",
            "Epoch 12, Loss: 4.7730\n",
            "Epoch 13, Loss: 4.5853\n",
            "Epoch 14, Loss: 4.3865\n",
            "Epoch 15, Loss: 4.2363\n",
            "Epoch 16, Loss: 4.0776\n",
            "Epoch 17, Loss: 3.9465\n",
            "Epoch 18, Loss: 3.8092\n",
            "Epoch 19, Loss: 3.6874\n",
            "Epoch 20, Loss: 3.5674\n",
            "Epoch 21, Loss: 3.4502\n",
            "Epoch 22, Loss: 3.3256\n",
            "Epoch 23, Loss: 3.2317\n",
            "Epoch 24, Loss: 3.1587\n",
            "Epoch 25, Loss: 3.0766\n",
            "Epoch 26, Loss: 2.9683\n",
            "Epoch 27, Loss: 2.8795\n",
            "Epoch 28, Loss: 2.8089\n",
            "Epoch 29, Loss: 2.7190\n",
            "Epoch 30, Loss: 2.6637\n",
            "Epoch 31, Loss: 2.5691\n",
            "Epoch 32, Loss: 2.4787\n",
            "Epoch 33, Loss: 2.4259\n",
            "Epoch 34, Loss: 2.3703\n",
            "Epoch 35, Loss: 2.2950\n",
            "Epoch 36, Loss: 2.2391\n",
            "Epoch 37, Loss: 2.1600\n",
            "Epoch 38, Loss: 2.1209\n",
            "Epoch 39, Loss: 2.0625\n",
            "Epoch 40, Loss: 1.9978\n",
            "Epoch 41, Loss: 1.9530\n",
            "Epoch 42, Loss: 1.8737\n",
            "Epoch 43, Loss: 1.8250\n",
            "Epoch 44, Loss: 1.7542\n",
            "Epoch 45, Loss: 1.7134\n",
            "Epoch 46, Loss: 1.6448\n",
            "Epoch 47, Loss: 1.6238\n",
            "Epoch 48, Loss: 1.5705\n",
            "Epoch 49, Loss: 1.5205\n",
            "Epoch 50, Loss: 1.4600\n",
            "Epoch 51, Loss: 1.3900\n",
            "Epoch 52, Loss: 1.3344\n",
            "Epoch 53, Loss: 1.2917\n",
            "Epoch 54, Loss: 1.2364\n",
            "Epoch 55, Loss: 1.1784\n",
            "Epoch 56, Loss: 1.1554\n",
            "Epoch 57, Loss: 1.1095\n",
            "Epoch 58, Loss: 1.0684\n",
            "Epoch 59, Loss: 1.0052\n",
            "Epoch 60, Loss: 0.9404\n",
            "Epoch 61, Loss: 0.8882\n",
            "Epoch 62, Loss: 0.8664\n",
            "Epoch 63, Loss: 0.8263\n",
            "Epoch 64, Loss: 0.7901\n",
            "Epoch 65, Loss: 0.7604\n",
            "Epoch 66, Loss: 0.7161\n",
            "Epoch 67, Loss: 0.6628\n",
            "Epoch 68, Loss: 0.6128\n",
            "Epoch 69, Loss: 0.5642\n",
            "Epoch 70, Loss: 0.5185\n",
            "Epoch 71, Loss: 0.4926\n",
            "Epoch 72, Loss: 0.4590\n",
            "Epoch 73, Loss: 0.4310\n",
            "Epoch 74, Loss: 0.4135\n",
            "Epoch 75, Loss: 0.3942\n",
            "Epoch 76, Loss: 0.3777\n",
            "Epoch 77, Loss: 0.3492\n",
            "Epoch 78, Loss: 0.3149\n",
            "Epoch 79, Loss: 0.2955\n",
            "Epoch 80, Loss: 0.2804\n",
            "Epoch 81, Loss: 0.2702\n",
            "Epoch 82, Loss: 0.2644\n",
            "Epoch 83, Loss: 0.2507\n",
            "Epoch 84, Loss: 0.2438\n",
            "Epoch 85, Loss: 0.2455\n",
            "Epoch 86, Loss: 0.2434\n",
            "Epoch 87, Loss: 0.2443\n",
            "Epoch 88, Loss: 0.2589\n",
            "Epoch 89, Loss: 0.2714\n",
            "Epoch 90, Loss: 0.2805\n",
            "Epoch 91, Loss: 0.3024\n",
            "Epoch 92, Loss: 0.3032\n",
            "Epoch 93, Loss: 0.2925\n",
            "Epoch 94, Loss: 0.2772\n",
            "Epoch 95, Loss: 0.2401\n",
            "Epoch 96, Loss: 0.1994\n",
            "Epoch 97, Loss: 0.1601\n",
            "Epoch 98, Loss: 0.1328\n",
            "Epoch 99, Loss: 0.1136\n",
            "Epoch 100, Loss: 0.1023\n"
          ]
        }
      ],
      "source": [
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "INPUT_DIM = len(SRC_VOCAB)\n",
        "OUTPUT_DIM = len(TGT_VOCAB)\n",
        "ENC_EMB_DIM = 128\n",
        "DEC_EMB_DIM = 128\n",
        "HID_DIM = 256\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, DEC_EMB_DIM)\n",
        "model = Seq2Seq(enc, dec, SRC_VOCAB[\"<pad>\"], device).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TGT_VOCAB[\"<pad>\"])\n",
        "\n",
        "def levenshtein(ref, hyp):\n",
        "    m, n = len(ref), len(hyp)\n",
        "    dp = np.zeros((m + 1, n + 1), dtype=int)\n",
        "    for i in range(m + 1):\n",
        "        dp[i][0] = i\n",
        "    for j in range(n + 1):\n",
        "        dp[0][j] = j\n",
        "    for i in range(1, m + 1):\n",
        "        for j in range(1, n + 1):\n",
        "            if ref[i - 1] == hyp[j - 1]:\n",
        "                dp[i][j] = dp[i - 1][j - 1]\n",
        "            else:\n",
        "                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n",
        "    return dp[m][n]\n",
        "\n",
        "def compute_cer(ref, hyp):\n",
        "    ref = ref.replace(' ', '')\n",
        "    hyp = hyp.replace(' ', '')\n",
        "    if len(ref) == 0:\n",
        "        return 0.0 if len(hyp) == 0 else 1.0\n",
        "    return levenshtein(ref, hyp) / len(ref)\n",
        "\n",
        "def compute_wer(ref, hyp):\n",
        "    ref_words = ref.split()\n",
        "    hyp_words = hyp.split()\n",
        "    if len(ref_words) == 0:\n",
        "        return 0.0 if len(hyp_words) == 0 else 1.0\n",
        "    return levenshtein(ref_words, hyp_words) / len(ref_words)\n",
        "\n",
        "# Use train_loader for training\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for src, tgt, src_lens, tgt_lens in train_loader:\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, src_lens, tgt)\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[:,1:].reshape(-1, output_dim)\n",
        "        tgt = tgt[:,1:].reshape(-1)\n",
        "        loss = criterion(output, tgt)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxICBpZ53x3j",
        "outputId": "50c81ecd-e025-4641-cdbb-a6366fa9fa40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "na ka\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def translate(model, src_sentence, max_len=30):\n",
        "    model.eval()\n",
        "    src_tokens = encode(src_sentence.lower().split(), SRC_VOCAB)\n",
        "    src_tensor = torch.tensor(src_tokens).unsqueeze(0).to(device)\n",
        "    src_lens = [len(src_tokens)]\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, (h, c) = model.encoder(src_tensor, src_lens)\n",
        "        h_cat = torch.cat((h[-2,:,:], h[-1,:,:]), dim=1)\n",
        "        c_cat = torch.cat((c[-2,:,:], c[-1,:,:]), dim=1)\n",
        "        h_dec = torch.tanh(model.fc_hidden(h_cat)).unsqueeze(0)\n",
        "        c_dec = torch.tanh(model.fc_cell(c_cat)).unsqueeze(0)\n",
        "        input = torch.tensor([TGT_VOCAB[\"<sos>\"]]).to(device)\n",
        "        result = []\n",
        "        for _ in range(max_len):\n",
        "            output, h_dec, c_dec = model.decoder(input, h_dec, c_dec)\n",
        "            top1 = output.argmax(1)\n",
        "            if top1.item() == TGT_VOCAB[\"<eos>\"]:\n",
        "                break\n",
        "            result.append(TGT_IVOCAB[top1.item()])\n",
        "            input = top1\n",
        "    return \" \".join(result)\n",
        "\n",
        "# Example usage:\n",
        "print(translate(model, \"ka na pa\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ3hqKUh5nb9",
        "outputId": "4960123a-9925-4f95-8cdb-3afb41ee4348"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 1:\n",
            "  Source:    ba_rr za_uu_h va_ll ba_ii_h ga_eueu_ll ka_ii_r wa_eueu sya_ii_h ka_ii_ll ta_ee_ng ja_ii_ll da_oo_h na_ee_ng va_eueu_r ya_r i ca_eueu za_ii_h\n",
            "  Target:    bra zuh vla bih gleu kir weu syih kli teng jli doh neng veur yar i ceu zih\n",
            "  Predicted: xra ceu tor bong véh kheu véh kheung hle tli tli g sya rar jeung\n",
            "  CER: 68.42%, WER: 100.00%\n",
            "\n",
            "Example 2:\n",
            "  Source:    ra_uu_ng ta_ee_ng fa_uu_ng wa_yy ja_ex_r ja_eueu_h ma_ex_rr ya_ee_r ka_ii_ll xa_yy sya_ii_r xa_r ha_oo_h nya_r wa_uu_r ra_eueu_r da_ee\n",
            "  Target:    rung teng fung wya jér jeuh mré yer kli xya syir xar hoh nyar wur reur de\n",
            "  Predicted: rung rung zur khah kheu kheu véh dyo hreu wer teur neung zla sli jeung\n",
            "  CER: 77.19%, WER: 94.12%\n",
            "\n",
            "Example 3:\n",
            "  Source:    va_pamaeh kha_ng\n",
            "  Target:    v khang\n",
            "  Predicted: khang\n",
            "  CER: 16.67%, WER: 50.00%\n",
            "\n",
            "Example 4:\n",
            "  Source:    la_ee\n",
            "  Target:    le\n",
            "  Predicted: lung\n",
            "  CER: 150.00%, WER: 100.00%\n",
            "\n",
            "Example 5:\n",
            "  Source:    pa_uu_r na_ii_r ra_ii_rr wa xa_ii_ng sa_ee_yy\n",
            "  Target:    pur nir rri wa xing sye\n",
            "  Predicted: pur song fer pur lri ter\n",
            "  CER: 83.33%, WER: 83.33%\n",
            "\n",
            "Example 6:\n",
            "  Source:    ba_uu_ll fa_eueu ca_rr\n",
            "  Target:    blu feu cra\n",
            "  Predicted: cra song\n",
            "  CER: 100.00%, WER: 100.00%\n",
            "\n",
            "Example 7:\n",
            "  Source:    za_eueu_h va_r ka_rr qa_eueu_ng ra_ii_r fa_r ba_ex_ll fa_rr na_uu na_uu_h\n",
            "  Target:    zeuh var kra qeung rir far blé fra nu nuh\n",
            "  Predicted: feung kra wru zer zer nyoh kyi hi khe tah hyo\n",
            "  CER: 87.50%, WER: 110.00%\n",
            "\n",
            "Example 8:\n",
            "  Source:    qa_uu_r ba_ll wa_ex_ll ta_ii_yy za_ee_h ja_pamaeh ma_ee_r fa_ii_ll pa_eueu_ng ra_yy\n",
            "  Target:    qur bla wlé tyi zeh j mer fli peung rya\n",
            "  Predicted: wir qur qur flé kheng por qur syung yong yong\n",
            "  CER: 90.00%, WER: 100.00%\n",
            "\n",
            "Example 9:\n",
            "  Source:    ma_uu_ng\n",
            "  Target:    mung\n",
            "  Predicted: mung\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 10:\n",
            "  Source:    ya_ee_ll ma_oo_rr ta_ee_ng qa_oo ra_ee_ll ba_oo_rr\n",
            "  Target:    yle mro teng qo rle bro\n",
            "  Predicted: mro vih vah kré wli ji dye tir\n",
            "  CER: 111.11%, WER: 133.33%\n",
            "\n",
            "Example 11:\n",
            "  Source:    pa_uu_rr ka_ee la_oo_rr ta_eueu_rr ta_rr ja_ii sa_uu_r na_eueu_rr wa_oo_ng\n",
            "  Target:    pru ke lro treu tra ji sur nreu wong\n",
            "  Predicted: lro pru par pru syoh syoh par xéng pru syeu\n",
            "  CER: 96.43%, WER: 100.00%\n",
            "\n",
            "Example 12:\n",
            "  Source:    ma_r\n",
            "  Target:    mar\n",
            "  Predicted: mar\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 13:\n",
            "  Source:    fa_ii_h\n",
            "  Target:    fih\n",
            "  Predicted: lu\n",
            "  CER: 100.00%, WER: 100.00%\n",
            "\n",
            "Example 14:\n",
            "  Source:    da_uu_yy ba_oo_yy ba_ii_h na_eueu_h la_ee_yy fa_uu na_pamaeh la_uu_rr ga_pamaeh ta_ii_ng\n",
            "  Target:    dyu byo bih neuh lye fu n lru g ting\n",
            "  Predicted: cih bih neuh le péng llé le peng zor\n",
            "  CER: 70.37%, WER: 80.00%\n",
            "\n",
            "Example 15:\n",
            "  Source:    da_ex_ll ca_uu ra_uu_ng pa_oo_h ga_ii_ng kha_eueu ra_eueu_rr pa_rr ta_ex_ng\n",
            "  Target:    dlé cu rung poh ging kheu rreu pra téng\n",
            "  Predicted: kre zih fé dlo mla jang heh jang\n",
            "  CER: 80.65%, WER: 100.00%\n",
            "\n",
            "Example 16:\n",
            "  Source:    ja_ex_rr\n",
            "  Target:    jré\n",
            "  Predicted: jré\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 17:\n",
            "  Source:    ba_uu xa_yy za_ii ra_ee_ng ra_uu_h ma_uu va_ex ja_ee_yy ya_eueu_r ja_ee_r ta_eueu_ll\n",
            "  Target:    bu xya zi reng ruh mu vé jye yeur jer tleu\n",
            "  Predicted: nreu wyeu wa wa jyo syu dar myu dar myu dar myu nyo\n",
            "  CER: 103.12%, WER: 118.18%\n",
            "\n",
            "Example 18:\n",
            "  Source:    ga_ex_r\n",
            "  Target:    gér\n",
            "  Predicted: gér\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 19:\n",
            "  Source:    xa_ng ha_ii_ng nya_ii ca_r ma_ex ya_uu_ng\n",
            "  Target:    xang hing nyi car mé yung\n",
            "  Predicted: yung yung gro qi qi mor vur\n",
            "  CER: 80.00%, WER: 116.67%\n",
            "\n",
            "Example 20:\n",
            "  Source:    ka_ii_r la_ng ya_ll da_yy pa_ex_r ma_oo_yy sya_oo_r nya_oo_r la_ex_rr la_ii_h wa_ee ga_ee_yy\n",
            "  Target:    kir lang yla dya pér myo syor nyor lré lih we gye\n",
            "  Predicted: kir kir kir moh syo moh moh gor co fur\n",
            "  CER: 76.32%, WER: 91.67%\n",
            "\n",
            "Example 21:\n",
            "  Source:    ka_h\n",
            "  Target:    kah\n",
            "  Predicted: kah\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 22:\n",
            "  Source:    xa_ex\n",
            "  Target:    xé\n",
            "  Predicted: xé\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 23:\n",
            "  Source:    ja_ee_rr\n",
            "  Target:    jre\n",
            "  Predicted: \n",
            "  CER: 100.00%, WER: 100.00%\n",
            "\n",
            "Example 24:\n",
            "  Source:    da_oo ma_ll ba_ii_rr sa_ex_ll ka_ee_ll ta_ee_rr wa_eueu_ng nya_oo_h pa_oo_yy ba_ee_ng na_rr pa_ee_r va_oo_ng xa_ii_h ba_eueu_yy\n",
            "  Target:    do mla bri slé kle tre weung nyoh pyo beng nra per vong xih byeu\n",
            "  Predicted: do slé glo slé xu ti to ti ti yong yer xéh xéh far syar\n",
            "  CER: 74.00%, WER: 86.67%\n",
            "\n",
            "Example 25:\n",
            "  Source:    za_ii_ng sa_eueu_ng ba_oo_ng i ca_ii_ll za ya_ee_ng xa_ii_r da_ii_rr ha_uu_yy ma ta_ex_h sa_ex sa_ii_ng ba_ex_rr da_uu_h\n",
            "  Target:    zing seung bong i cli za yeng xir dri hyu ma téh sé sing bré duh\n",
            "  Predicted: zing weu weu ye mong tér yeur kheng gla 1 kor yri 1 ri ger fah\n",
            "  CER: 75.51%, WER: 93.75%\n",
            "\n",
            "Example 26:\n",
            "  Source:    va_uu_h ga_uu_h dua ca_ex_h ca_h va_yy na_uu_ll ha wa_oo_ng fa_ii_ll ma_ee_r ya_ex nya_ex_ng fa_oo_ll wa_oo ya_ee_r\n",
            "  Target:    vuh guh 2 céh cah vya nlu ha wong fli mer yé nyéng flo wo yer\n",
            "  Predicted: vuh vuh vuh vih z vuh rlu reng syeur rli kheung tlu kré héng khéh quh\n",
            "  CER: 86.96%, WER: 93.75%\n",
            "\n",
            "Example 27:\n",
            "  Source:    ma_ex_yy ra_ex_h ma_ng pa_ii_yy ca_r ca_pamaeh va_uu\n",
            "  Target:    myé réh mang pyi car c vu\n",
            "  Predicted: car kyu pyi y pra yeung\n",
            "  CER: 84.21%, WER: 85.71%\n",
            "\n",
            "Example 28:\n",
            "  Source:    sya_ii_r ga_ng ha_ex_h ma_ii_yy ra_ex_h sa_ii_rr ma_ii_h va_ii_ng ra_ii_rr na_eueu_yy wa_oo ba_eueu_rr la_oo_r\n",
            "  Target:    syir gang héh myi réh sri mih ving rri nyeu wo breu lor\n",
            "  Predicted: myi qeung qeung bri du qang jéh jéh har ping mru nyé\n",
            "  CER: 81.40%, WER: 100.00%\n",
            "\n",
            "Example 29:\n",
            "  Source:    fa_ex\n",
            "  Target:    fé\n",
            "  Predicted: fé\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 30:\n",
            "  Source:    la_ee_ng ba_oo_yy qa_r xa_pamaeh ta_oo_ll sya_uu ja_ii_rr ta_ii ka_eueu_h ga_ex_h ha_h la_uu_yy pa_oo_rr na_ii_yy ga_ee_ll sya_ee sa_ex_ng da_oo_ll\n",
            "  Target:    leng byo qar x tlo syu jri ti keuh géh hah lyu pro nyi gle sye séng dlo\n",
            "  Predicted: leng leng har dli kah yung kah lé jya bih jya pah tle zla\n",
            "  CER: 74.07%, WER: 94.44%\n",
            "\n",
            "Example 31:\n",
            "  Source:    ha_oo_rr\n",
            "  Target:    hro\n",
            "  Predicted: hro\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 32:\n",
            "  Source:    ka_ex_ll la_uu_ll ba_eueu nya_ng la_eueu_r na_uu_h wa_oo_r qa_r ya ta_ii za_oo_r da_ii ga_oo_r da_uu_yy ka_ex_rr ja_ex sya_ee_h pa_ee_rr\n",
            "  Target:    klé llu beu nyang leur nuh wor qar ya ti zor di gor dyu kré jé syeh pre\n",
            "  Predicted: pi vuh juh juh lé héng juh ler héng ler peur weng zar bi wa pre luh heur\n",
            "  CER: 87.04%, WER: 100.00%\n",
            "\n",
            "Example 33:\n",
            "  Source:    qa_oo_h\n",
            "  Target:    qoh\n",
            "  Predicted: ruh\n",
            "  CER: 66.67%, WER: 100.00%\n",
            "\n",
            "Example 34:\n",
            "  Source:    ha_ii ka_uu_ll sya_eueu\n",
            "  Target:    hi klu syeu\n",
            "  Predicted: hi hi syeu\n",
            "  CER: 33.33%, WER: 33.33%\n",
            "\n",
            "Example 35:\n",
            "  Source:    xa_oo\n",
            "  Target:    xo\n",
            "  Predicted: bah\n",
            "  CER: 150.00%, WER: 100.00%\n",
            "\n",
            "Example 36:\n",
            "  Source:    na_oo_ll\n",
            "  Target:    nlo\n",
            "  Predicted: nlo\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 37:\n",
            "  Source:    ca_eueu_h ka_oo sa_ex_ll ra_ex_ng ja_oo_ng ta_eueu ka_uu_yy ja_r za_yy na_oo_r nya_oo_h ra_oo_r ba_uu ca_oo qa_oo_r la_r\n",
            "  Target:    ceuh ko slé réng jong teu kyu jar zya nor nyoh ror bu co qor lar\n",
            "  Predicted: zo quh nuh for 5 her dur her nur wuh bro jya x khang sro\n",
            "  CER: 81.63%, WER: 100.00%\n",
            "\n",
            "Example 38:\n",
            "  Source:    nya_eueu\n",
            "  Target:    nyeu\n",
            "  Predicted: nyeu\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 39:\n",
            "  Source:    fa_oo\n",
            "  Target:    fo\n",
            "  Predicted: fo\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 40:\n",
            "  Source:    ha_ii_ll ja_oo_h xa_r nya_oo_ng ra_ex_h kha_ee_h ha_ex_h\n",
            "  Target:    hli joh xar nyong réh kheh héh\n",
            "  Predicted: gyeu sra kur tya yor\n",
            "  CER: 91.67%, WER: 100.00%\n",
            "\n",
            "Example 41:\n",
            "  Source:    pa_uu\n",
            "  Target:    pu\n",
            "  Predicted: reng\n",
            "  CER: 200.00%, WER: 100.00%\n",
            "\n",
            "Example 42:\n",
            "  Source:    ga_ng\n",
            "  Target:    gang\n",
            "  Predicted: jlé\n",
            "  CER: 100.00%, WER: 100.00%\n",
            "\n",
            "Example 43:\n",
            "  Source:    pa_ee_ng\n",
            "  Target:    peng\n",
            "  Predicted: peng\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 44:\n",
            "  Source:    sya_oo_r\n",
            "  Target:    syor\n",
            "  Predicted: syor\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 45:\n",
            "  Source:    wa_uu_ng ra_h wa_ex_yy ga_eueu_ng ka_r la_uu ha_ee_yy kha_uu ka_oo_h\n",
            "  Target:    wung rah wyé geung kar lu hye khu koh\n",
            "  Predicted: wung 8 dyeu qeu syeung wyeu teh pri zung zar\n",
            "  CER: 86.21%, WER: 100.00%\n",
            "\n",
            "Example 46:\n",
            "  Source:    ta_oo na_ex ka_eueu_yy wa_uu_ng ya_ii_ll sa_oo_ll ka_ee_yy ga_ng la_ee_ll ma_oo_yy ba_uu pa_oo_ng nya_oo_ng ba_eueu_yy\n",
            "  Target:    to né kyeu wung yli slo kye gang lle myo bu pong nyong byeu\n",
            "  Predicted: syér syér syér syér ceh ceh wor yyi wor bré bré ké luh kro\n",
            "  CER: 91.30%, WER: 100.00%\n",
            "\n",
            "Example 47:\n",
            "  Source:    ga_ii_yy ta_eueu_r ma_ee_ng wa_oo_yy sya_pamaeh na_ex\n",
            "  Target:    gyi teur meng wyo sy né\n",
            "  Predicted: dye jra neung lyu huh slé\n",
            "  CER: 77.78%, WER: 100.00%\n",
            "\n",
            "Example 48:\n",
            "  Source:    tujuh\n",
            "  Target:    7\n",
            "  Predicted: 7\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 49:\n",
            "  Source:    sa_ii_r nya_ii qa_oo_r ya ba_r ma_ii_r ra_ii_ng ka_ii_ll ha_ex_ng sya_eueu_ng ra_ex_r ma_oo_rr ba_ii ja_pamaeh ma_eueu_r\n",
            "  Target:    sir nyi qor ya bar mir ring kli héng syeung rér mro bi j meur\n",
            "  Predicted: sir qor pa por pyé breu nyi lir pa sré fyé féh feu deu keuh hla koh\n",
            "  CER: 82.98%, WER: 106.67%\n",
            "\n",
            "Example 50:\n",
            "  Source:    fa_oo_ll sa_ee_ng za_oo_h ma_oo_ll fa_ng nya_uu_r sya_ii na_oo_yy fa_uu_r za_pamaeh na_uu_ng ra ga_eueu_ng xa_r\n",
            "  Target:    flo seng zoh mlo fang nyur syi nyo fur z nung ra geung xar\n",
            "  Predicted: nyé lor flo moh moh moh muh pri pri lyé v he he su ling\n",
            "  CER: 82.22%, WER: 107.14%\n",
            "\n",
            "Example 51:\n",
            "  Source:    ta_yy ga_ee_h sa_ex_rr ma_ii_rr ga_uu_h sya_uu_r va_ii_r ba_ii_ll na_eueu_h qa_ee da_uu_r pa_h pa_ii_ng la_ex_ll ca_oo_ll qa_rr\n",
            "  Target:    tya geh sré mri guh syur vir bli neuh qe dur pah ping llé clo qra\n",
            "  Predicted: tya flo kyeu lér lér dyi ylé syo rar hyo ror tli war ceung pang lye zong\n",
            "  CER: 84.00%, WER: 100.00%\n",
            "\n",
            "Example 52:\n",
            "  Source:    pa_oo_yy ya_ee la_ii_ll za_ex_h ka_ex_ng pa_ee_r kha_r va_ii_ng ha_uu_ll qa_pamaeh ka_ii_yy ba_oo_h ka va_ee va_uu_r da_ii_yy ja qa_eueu_ng xa_oo ga_oo_h\n",
            "  Target:    pyo ye lli zéh kéng per khar ving hlu q kyi boh ka ve vur dyi ja qeung xo goh\n",
            "  Predicted: lli pyo ye heung heung do hru gé dyeu qeuh nra sih leung yah\n",
            "  CER: 70.69%, WER: 95.00%\n",
            "\n",
            "Example 53:\n",
            "  Source:    ma_eueu\n",
            "  Target:    meu\n",
            "  Predicted: meu\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 54:\n",
            "  Source:    pa_uu_h ra_uu_ll za_uu_h na_ex_rr wa_ex_rr wa_ex_ll\n",
            "  Target:    puh rlu zuh nré wré wlé\n",
            "  Predicted: jyi jyi wye har ceuh zir\n",
            "  CER: 94.44%, WER: 100.00%\n",
            "\n",
            "Example 55:\n",
            "  Source:    ya_yy\n",
            "  Target:    yya\n",
            "  Predicted: yya\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 56:\n",
            "  Source:    ta_pamaeh ja_ii_rr ja_uu_ll ha_ee_rr ka_ex_r ka_uu_ll sa_eueu_rr qa_oo ka_ex_h ja_eueu_ng va_ex ha_uu_rr sa_oo ga\n",
            "  Target:    t jri jlu hre kér klu sreu qo kéh jeung vé hru so ga\n",
            "  Predicted: léng léng léng nyo keng keng nuh rlu nur rar veuh tra nlu veu fyi\n",
            "  CER: 107.69%, WER: 107.14%\n",
            "\n",
            "Example 57:\n",
            "  Source:    sa_eueu_ll\n",
            "  Target:    sleu\n",
            "  Predicted: sleu\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 58:\n",
            "  Source:    ka_eueu_ll\n",
            "  Target:    kleu\n",
            "  Predicted: fong\n",
            "  CER: 100.00%, WER: 100.00%\n",
            "\n",
            "Example 59:\n",
            "  Source:    u sa_ii_rr ga_oo va_eueu_ng ra_uu_r fa_ii ha_ee_rr ha_ii_r sa_uu_rr ya_uu_ll va_ng wa_ii_ll ja_eueu_h sa_eueu_r\n",
            "  Target:    u sri go veung rur fi hre hir sru ylu vang wli jeuh seur\n",
            "  Predicted: u u u ha bri bri quh syih xeu nyo bye u bye séng nying\n",
            "  CER: 86.05%, WER: 100.00%\n",
            "\n",
            "Example 60:\n",
            "  Source:    ha_ex_yy\n",
            "  Target:    hyé\n",
            "  Predicted: hyé\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 61:\n",
            "  Source:    kha_eueu_r\n",
            "  Target:    kheur\n",
            "  Predicted: kheur\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 62:\n",
            "  Source:    ha_eueu_ng\n",
            "  Target:    heung\n",
            "  Predicted: heung\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 63:\n",
            "  Source:    ta_ee_yy\n",
            "  Target:    tye\n",
            "  Predicted: yih\n",
            "  CER: 100.00%, WER: 100.00%\n",
            "\n",
            "Example 64:\n",
            "  Source:    ya_eueu\n",
            "  Target:    yeu\n",
            "  Predicted: qo\n",
            "  CER: 100.00%, WER: 100.00%\n",
            "\n",
            "Example 65:\n",
            "  Source:    ma_ng\n",
            "  Target:    mang\n",
            "  Predicted: mang\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 66:\n",
            "  Source:    ra_ii_h ba_ee_yy\n",
            "  Target:    rih bye\n",
            "  Predicted: rih\n",
            "  CER: 50.00%, WER: 50.00%\n",
            "\n",
            "Example 67:\n",
            "  Source:    fa_uu_rr ya_eueu_ng pa_ee_rr la_ii ra_ee_rr pa_ee_yy ja_uu_r\n",
            "  Target:    fru yeung pre li rre pye jur\n",
            "  Predicted: ri ri vi qeh yeung rong syir\n",
            "  CER: 86.36%, WER: 100.00%\n",
            "\n",
            "Example 68:\n",
            "  Source:    ma_eueu_ng ja_pamaeh ga_ii_rr sya_ng ka_oo_r ba_ii_rr ha_ex_h ra_uu_ll ca_uu_h na_ii_h na_uu_yy ta_r za_ex_ng qa_uu_ng ka_eueu_ng fa_r sa_ng ra_oo_yy nya_ii_h ra_ex\n",
            "  Target:    meung j gri syang kor bri héh rlu cuh nih nyu tar zéng qung keung far sang ryo nyih ré\n",
            "  Predicted: meung meung meung breu keur breu wor jér nyu pre nyu b j sih sah her jer\n",
            "  CER: 74.63%, WER: 90.00%\n",
            "\n",
            "Example 69:\n",
            "  Source:    za_ex_ng za_ii_r da_ng ha_ee_rr ja_ii ra_ex_h qa_pamaeh nya_ee_r ja_ex_yy ya_eueu_r ja_ii_ng sa_oo_r ya_eueu_ll sa_oo wa_ii va_ii\n",
            "  Target:    zéng zir dang hre ji réh q nyer jyé yeur jing sor yleu so wi vi\n",
            "  Predicted: rung jyo wo jyo weng weng beung jyo nyé jyo llo nyé lyé nyé weu\n",
            "  CER: 85.42%, WER: 100.00%\n",
            "\n",
            "Example 70:\n",
            "  Source:    ra_ee_h\n",
            "  Target:    reh\n",
            "  Predicted: reh\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 71:\n",
            "  Source:    ba_r la_uu_ng wa_ii kha_ii ya_yy ya_eueu_h sya_ii ca_ii_r ha_ee_ll ta_eueu_yy pa_uu_ll ba_ii_r la_ii_ng ha_ng ta_pamaeh\n",
            "  Target:    bar lung wi khi yya yeuh syi cir hle tyeu plu bir ling hang t\n",
            "  Predicted: bar qih mér nih suh seh suh sang xi seh tri geu sla\n",
            "  CER: 76.60%, WER: 93.33%\n",
            "\n",
            "Example 72:\n",
            "  Source:    ya_ee\n",
            "  Target:    ye\n",
            "  Predicted: ye\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 73:\n",
            "  Source:    ja_ii_ll ka_ex ra_pamaeh sa_rr sya_uu nya_pamaeh ga_ii_ng fa_ii_ll sya_oo_ng ga_eueu_yy pa_oo_r ga_uu_h ra_ii_rr ta\n",
            "  Target:    jli ké r sra syu ny ging fli syong gyeu por guh rri ta\n",
            "  Predicted: nyang nyang cri toh xé wang dli toh yri peur syeuh xing sré\n",
            "  CER: 92.68%, WER: 100.00%\n",
            "\n",
            "Example 74:\n",
            "  Source:    ha_ii_yy fa_ee_ng sa_ee la_uu_ng da_h ba_rr ha_oo_ng sya_ex_h ma_oo_h\n",
            "  Target:    hyi feng se lung dah bra hong syéh moh\n",
            "  Predicted: hyi syeur dah hang suh lu par hré\n",
            "  CER: 70.00%, WER: 88.89%\n",
            "\n",
            "Example 75:\n",
            "  Source:    nya_ng\n",
            "  Target:    nyang\n",
            "  Predicted: nyang\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 76:\n",
            "  Source:    nya_ex_h\n",
            "  Target:    nyéh\n",
            "  Predicted: nyéh\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 77:\n",
            "  Source:    ba_oo_r pa_ee_ng ca_ii_yy ma_ee_ll ta_rr ya_ex_r ma_uu_ng va_oo_r\n",
            "  Target:    bor peng cyi mle tra yér mung vor\n",
            "  Predicted: jor khi khi fyé yér kle myu cor\n",
            "  CER: 76.92%, WER: 100.00%\n",
            "\n",
            "Example 78:\n",
            "  Source:    la_pamaeh ca_ee_ng ya_ee_ll sa_uu_h fa_ex la_eueu_h da_h ba_ex_h fa_ee_rr ka_uu ya_ii_ll ya_ii ba_uu_r za_ee_h ra_ll\n",
            "  Target:    l ceng yle suh fé leuh dah béh fre ku yli yi bur zeh rla\n",
            "  Predicted: wuh he he long deh long nyah long lur ring qe m vé sor\n",
            "  CER: 90.48%, WER: 100.00%\n",
            "\n",
            "Example 79:\n",
            "  Source:    ya_yy ba_oo ya_ii_yy ma_oo_ll ca_ex_r va_ex_r ca_oo_r ja_h da_uu_ll ra_r xa_ll ka_eueu_rr pa_ee_rr ba_ii_h la_uu_h pa_oo_h ra_oo_ng ba_ex wa_ex_r\n",
            "  Target:    yya bo yyi mlo cér vér cor jah dlu rar xla kreu pre bih luh poh rong bé wér\n",
            "  Predicted: nyar ruh nyar peh nyar nyar peh nyar tle kir vang céh vang wo kheng byeu\n",
            "  CER: 80.70%, WER: 100.00%\n",
            "\n",
            "Example 80:\n",
            "  Source:    ja_yy sa_uu_rr da_yy ka_r na_h sya_oo_r qa_eueu_h sa_eueu_rr qa_yy sa_ii_h ga_oo_h sa_ee_rr ca_ee_ng fa_ex_h ga_h ha_oo sa_ii_yy ya_rr ca_uu_r ja_ii\n",
            "  Target:    jya sru dya kar nah syor qeuh sreu qya sih goh sre ceng féh gah ho syi yra cur ji\n",
            "  Predicted: nyé plu klé mé khu nye yér sih sih wlé yle roh roh ze wla d yru\n",
            "  CER: 79.03%, WER: 95.00%\n",
            "\n",
            "Example 81:\n",
            "  Source:    ba_ee_yy ka_uu_ng la_eueu_r wa_uu ya_oo_r ya_uu_ll kha_ee_r kha_uu za_eueu pa_ii_ll\n",
            "  Target:    bye kung leur wu yor ylu kher khu zeu pli\n",
            "  Predicted: bye mo tyu fé péng fyo beung péng cra qeh bli tle\n",
            "  CER: 93.75%, WER: 110.00%\n",
            "\n",
            "Example 82:\n",
            "  Source:    ba_yy va_ng ga_oo_r za_oo_h sya_ee_r ra_eueu_rr na_ii ja_ex_rr ra_eueu_ng la_ex_r ca_ee_r ha_ng sa_eueu_rr ha_yy ha_eueu_rr ya_ee_h é\n",
            "  Target:    bya vang gor zoh syer rreu ni jré reung lér cer hang sreu hya hreu yeh é\n",
            "  Predicted: eu lang mla gor béng gor rreu béng fang heung é pir leung mlo leung wor xah\n",
            "  CER: 73.21%, WER: 94.12%\n",
            "\n",
            "Example 83:\n",
            "  Source:    pa_ex_yy\n",
            "  Target:    pyé\n",
            "  Predicted: pyé\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 84:\n",
            "  Source:    ca_ex_r da_yy pa_eueu_r kha_ex_h wa_pamaeh da_ii va_ii_r ra_uu_h sya_ex pa_eueu sa_uu_ng xa_ll ha_eueu_h da_ex ca_pamaeh ga_ex_ng ga_ii_h ba_ii_r va_ll ya_eueu\n",
            "  Target:    cér dya peur khéh w di vir ruh syé peu sung xla heuh dé c géng gih bir vla yeu\n",
            "  Predicted: ci ci dya dya syeng khéh tér pa khéh peur dor hra lru gah luh jeu sye cli\n",
            "  CER: 79.66%, WER: 100.00%\n",
            "\n",
            "Example 85:\n",
            "  Source:    na_ee_ng ra_ee_rr ya_eueu_ng da_eueu_r ba_ee_rr na_ex_ll kha_ex_ng la_h la_uu_yy\n",
            "  Target:    neng rre yeung deur bre nlé khéng lah lyu\n",
            "  Predicted: lli lli khéng kheng nyung nyung nyung\n",
            "  CER: 84.85%, WER: 100.00%\n",
            "\n",
            "Example 86:\n",
            "  Source:    la_rr\n",
            "  Target:    lra\n",
            "  Predicted: lra\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 87:\n",
            "  Source:    ka_eueu_r ha_oo_ng wa_r la_ex va_ex_ng fa_ex_r ya_eueu_ll ya_ex sa_ii_ll\n",
            "  Target:    keur hong war lé véng fér yleu yé sli\n",
            "  Predicted: wé war mong mong mong ra yong llu mih guh\n",
            "  CER: 86.21%, WER: 111.11%\n",
            "\n",
            "Example 88:\n",
            "  Source:    ra_ii_r nya_oo_h e za_ii_ng sa_oo_ng ja_ee_r va_eueu_ng ma_ex_ll ra_ee_h\n",
            "  Target:    rir nyoh e zing song jer veung mlé reh\n",
            "  Predicted: nyoh yle to to cyi jye seh\n",
            "  CER: 73.33%, WER: 88.89%\n",
            "\n",
            "Example 89:\n",
            "  Source:    ba_uu_r sa_h nya_ex_ng ha_eueu_ng u pa_ex_rr ma_eueu xa_ex_ng\n",
            "  Target:    bur sah nyéng heung u pré meu xéng\n",
            "  Predicted: kuh kuh kuh mleu tuh kyo klé klé nyé\n",
            "  CER: 85.19%, WER: 112.50%\n",
            "\n",
            "Example 90:\n",
            "  Source:    ka_ii_ng ma_eueu ka_ii_rr source na_r ta_rr ha_ee_ll va_oo da_eueu_yy da_ee_yy ra_oo_rr wa_ex_yy\n",
            "  Target:    king meu kri target nar tra hle vo dyeu dye rro wyé\n",
            "  Predicted: king king yla hor khér joh khér tli yuh pya lé\n",
            "  CER: 75.00%, WER: 91.67%\n",
            "\n",
            "Example 91:\n",
            "  Source:    nya_ee\n",
            "  Target:    nye\n",
            "  Predicted: nye\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 92:\n",
            "  Source:    ca_ex_ng ha_uu na_ex\n",
            "  Target:    céng hu né\n",
            "  Predicted: syeu nyeu bir keuh\n",
            "  CER: 162.50%, WER: 133.33%\n",
            "\n",
            "Example 93:\n",
            "  Source:    fa_uu_ll fa_ex xa_ii_h sya_oo_r\n",
            "  Target:    flu fé xih syor\n",
            "  Predicted: feng syor xih\n",
            "  CER: 83.33%, WER: 75.00%\n",
            "\n",
            "Example 94:\n",
            "  Source:    za_eueu_h va_rr xa_uu ya_ex da_oo_yy ra_oo_ll ja_ex_h za_ii_r va_yy pa_uu_rr ja_ii_rr ka_ex_r da_oo_r ka_uu_rr\n",
            "  Target:    zeuh vra xu yé dyo rlo jéh zir vya pru jri kér dor kru\n",
            "  Predicted: preu vra hlé ying gro toh xo toh gro peng hir rro\n",
            "  CER: 75.61%, WER: 92.86%\n",
            "\n",
            "Example 95:\n",
            "  Source:    pa_oo_ng wa_ll wa_eueu_yy wa_ex_h ra_r pa_uu_rr sa_pamaeh\n",
            "  Target:    pong wla wyeu wéh rar pru s\n",
            "  Predicted: fyé zar wla s dyu veur dyu pré\n",
            "  CER: 80.95%, WER: 100.00%\n",
            "\n",
            "Example 96:\n",
            "  Source:    ma_eueu_h\n",
            "  Target:    meuh\n",
            "  Predicted: meuh meuh\n",
            "  CER: 100.00%, WER: 100.00%\n",
            "\n",
            "Example 97:\n",
            "  Source:    ra_oo ma_uu_ll la_rr va_oo ra_uu_rr ha_pamaeh ja_ex_yy ba_oo_h qa_ii ka_uu_yy sa_ee_r da_ex na_ee_yy\n",
            "  Target:    ro mlu lra vo rru h jyé boh qi kyu ser dé nye\n",
            "  Predicted: vo pré pré pré syu khu vo wi vo cyi bye nying sye\n",
            "  CER: 84.85%, WER: 100.00%\n",
            "\n",
            "Example 98:\n",
            "  Source:    kha_eueu_h ya_ii_rr pa_ex_ll va_eueu_ng va_ex da_pamaeh ka_ee_yy qa_oo_ng ya_ee_rr ba_r kha_ex_h ka_r kha_ee ja_uu ja_ii_ng\n",
            "  Target:    kheuh yri plé veung vé d kye qong yre bar khéh kar khe ju jing\n",
            "  Predicted: kye ju kye fli bing pri gang gru gya jli zung é neung wér te rong\n",
            "  CER: 83.33%, WER: 106.67%\n",
            "\n",
            "Example 99:\n",
            "  Source:    qa_rr\n",
            "  Target:    qra\n",
            "  Predicted: bro\n",
            "  CER: 66.67%, WER: 100.00%\n",
            "\n",
            "Example 100:\n",
            "  Source:    sya_eueu_h va_oo_r ba_ex_ng ta_uu_yy nya_ex_ng na_ll ka_eueu_ll ya_eueu_r za_ii_ng ya_ex_ng nya_oo_ng\n",
            "  Target:    syeuh vor béng tyu nyéng nla kleu yeur zing yéng nyong\n",
            "  Predicted: kéh céh neung héng héng tah syung nyoh vih\n",
            "  CER: 75.00%, WER: 100.00%\n",
            "\n",
            "CER: 66.91%, WER: 73.13%\n"
          ]
        }
      ],
      "source": [
        "    # Metric evaluation on the test set (unseen data)\n",
        "    model.eval()\n",
        "    total_cer = 0\n",
        "    total_wer = 0\n",
        "    n_samples = 0\n",
        "    with torch.no_grad():\n",
        "        example_printed = 0\n",
        "        for src, tgt, src_lens, tgt_lens in test_loader:\n",
        "            src = src.to(device)\n",
        "            for i in range(src.size(0)):\n",
        "                src_sentence = ' '.join([SRC_IVOCAB[idx.item()] for idx in src[i] if idx.item() != SRC_VOCAB[\"<pad>\"]])\n",
        "                tgt_sentence = ' '.join([TGT_IVOCAB[idx.item()] for idx in tgt[i] if idx.item() not in [TGT_VOCAB[\"<pad>\"], TGT_VOCAB[\"<sos>\"], TGT_VOCAB[\"<eos>\"]]])\n",
        "                pred_sentence = translate(model, src_sentence)\n",
        "                cer = compute_cer(tgt_sentence, pred_sentence)\n",
        "                wer = compute_wer(tgt_sentence, pred_sentence)\n",
        "                total_cer += cer\n",
        "                total_wer += wer\n",
        "                n_samples += 1\n",
        "                # Print a few examples\n",
        "                if example_printed < 100:\n",
        "                    print(f\"Example {example_printed+1}:\")\n",
        "                    print(f\"  Source:    {src_sentence}\")\n",
        "                    print(f\"  Target:    {tgt_sentence}\")\n",
        "                    print(f\"  Predicted: {pred_sentence}\")\n",
        "                    print(f\"  CER: {cer:.2%}, WER: {wer:.2%}\\n\")\n",
        "                    example_printed += 1\n",
        "    print(f\"CER: {total_cer/n_samples:.2%}, WER: {total_wer/n_samples:.2%}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
