{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "htuD_cMA48cX"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import random\n",
        "\n",
        "base_source_tokens = ['source', 'a', 'i', 'u', 'e', 'o', 'eu', 'é', 'a_ng', 'a_hh', 'a_rr',\n",
        "          'i_ng', 'i_hh', 'i_rr',\n",
        "          'u_ng', 'u_hh', 'u_rr',\n",
        "          'e_ng', 'e_hh', 'e_rr',\n",
        "          'o_ng', 'o_hh', 'o_rr','hiji', 'dua', 'tilu', 'opat', 'lima', 'genep', 'tujuh', 'dalapan', 'salapan', 'enol', 'ka', 'na', 'pa', 'ma', 'ta', 'da', 'ba', 'ga', 'ja', 'ra', 'la', 'sa', 'ya', 'wa', 'ha', 'za', 'xa', 'fa', 'va', 'ca', 'nya', 'kha', 'sya', 'qa', 'ka_ng', 'ka_rr', 'ka_hh', 'na_ng', 'na_rr', 'na_hh', 'pa_ng', 'pa_rr', 'pa_hh', 'ma_ng', 'ma_rr', 'ma_hh', 'ta_ng', 'ta_rr', 'ta_hh', 'da_ng', 'da_rr', 'da_hh', 'ba_ng', 'ba_rr', 'ba_hh', 'ga_ng', 'ga_rr', 'ga_hh', 'ja_ng', 'ja_rr', 'ja_hh', 'ra_ng', 'ra_rr', 'ra_hh', 'la_ng', 'la_rr', 'la_hh', 'sa_ng', 'sa_rr', 'sa_hh', 'ya_ng', 'ya_rr', 'ya_hh', 'wa_ng', 'wa_rr', 'wa_hh', 'ha_ng', 'ha_rr', 'ha_hh', 'za_ng', 'za_rr', 'za_hh', 'xa_ng', 'xa_rr', 'xa_hh', 'fa_ng', 'fa_rr', 'fa_hh', 'va_ng', 'va_rr', 'va_hh', 'ca_ng', 'ca_rr', 'ca_hh', 'nya_ng', 'nya_rr', 'nya_hh', 'kha_ng', 'kha_rr', 'kha_hh', 'sya_ng', 'sya_rr', 'sya_hh', 'qa_ng', 'qa_rr', 'qa_hh', 'ka_rrr', 'ka_lll', 'ka_yyy', 'na_rrr', 'na_lll', 'na_yyy', 'pa_rrr', 'pa_lll', 'pa_yyy', 'ma_rrr', 'ma_lll', 'ma_yyy', 'ta_rrr', 'ta_lll', 'ta_yyy', 'da_rrr', 'da_lll', 'da_yyy', 'ba_rrr', 'ba_lll', 'ba_yyy', 'ga_rrr', 'ga_lll', 'ga_yyy', 'ja_rrr', 'ja_lll', 'ja_yyy', 'ra_rrr', 'ra_lll', 'ra_yyy', 'la_rrr', 'la_lll', 'la_yyy', 'sa_rrr', 'sa_lll', 'sa_yyy', 'ya_rrr', 'ya_lll', 'ya_yyy', 'wa_rrr', 'wa_lll', 'wa_yyy', 'ha_rrr', 'ha_lll', 'ha_yyy', 'za_rrr', 'za_lll', 'za_yyy', 'xa_rrr', 'xa_lll', 'xa_yyy', 'fa_rrr', 'fa_lll', 'fa_yyy', 'va_rrr', 'va_lll', 'va_yyy', 'ca_rrr', 'ca_lll', 'ca_yyy', 'qa_rrr', 'qa_lll', 'qa_yyy', 'ka_ex', 'ka_ii', 'ka_oo', 'ka_uu', 'ka_ee', 'ka_eueu', 'ka_pamaeh', 'na_ex', 'na_ii', 'na_oo', 'na_uu', 'na_ee', 'na_eueu', 'na_pamaeh', 'pa_ex', 'pa_ii', 'pa_oo', 'pa_uu', 'pa_ee', 'pa_eueu', 'pa_pamaeh', 'ma_ex', 'ma_ii', 'ma_oo', 'ma_uu', 'ma_ee', 'ma_eueu', 'ma_pamaeh', 'ta_ex', 'ta_ii', 'ta_oo', 'ta_uu', 'ta_ee', 'ta_eueu', 'ta_pamaeh', 'da_ex', 'da_ii', 'da_oo', 'da_uu', 'da_ee', 'da_eueu', 'da_pamaeh', 'ba_ex', 'ba_ii', 'ba_oo', 'ba_uu', 'ba_ee', 'ba_eueu', 'ba_pamaeh', 'ga_ex', 'ga_ii', 'ga_oo', 'ga_uu', 'ga_ee', 'ga_eueu', 'ga_pamaeh', 'ja_ex', 'ja_ii', 'ja_oo', 'ja_uu', 'ja_ee', 'ja_eueu', 'ja_pamaeh', 'ra_ex', 'ra_ii', 'ra_oo', 'ra_uu', 'ra_ee', 'ra_eueu', 'ra_pamaeh', 'la_ex', 'la_ii', 'la_oo', 'la_uu', 'la_ee', 'la_eueu', 'la_pamaeh', 'sa_ex', 'sa_ii', 'sa_oo', 'sa_uu', 'sa_ee', 'sa_eueu', 'sa_pamaeh', 'ya_ex', 'ya_ii', 'ya_oo', 'ya_uu', 'ya_ee', 'ya_eueu', 'ya_pamaeh', 'wa_ex', 'wa_ii', 'wa_oo', 'wa_uu', 'wa_ee', 'wa_eueu', 'wa_pamaeh', 'ha_ex', 'ha_ii', 'ha_oo', 'ha_uu', 'ha_ee', 'ha_eueu', 'ha_pamaeh', 'za_ex', 'za_ii', 'za_oo', 'za_uu', 'za_ee', 'za_eueu', 'za_pamaeh', 'xa_ex', 'xa_ii', 'xa_oo', 'xa_uu', 'xa_ee', 'xa_eueu', 'xa_pamaeh', 'fa_ex', 'fa_ii', 'fa_oo', 'fa_uu', 'fa_ee', 'fa_eueu', 'fa_pamaeh', 'va_ex', 'va_ii', 'va_oo', 'va_uu', 'va_ee', 'va_eueu', 'va_pamaeh', 'ca_ex', 'ca_ii', 'ca_oo', 'ca_uu', 'ca_ee', 'ca_eueu', 'ca_pamaeh', 'nya_ex', 'nya_ii', 'nya_oo', 'nya_uu', 'nya_ee', 'nya_eueu', 'nya_pamaeh', 'kha_ex', 'kha_ii', 'kha_oo', 'kha_uu', 'kha_ee', 'kha_eueu', 'kha_pamaeh', 'sya_ex', 'sya_ii', 'sya_oo', 'sya_uu', 'sya_ee', 'sya_eueu', 'sya_pamaeh', 'qa_ex', 'qa_ii', 'qa_oo', 'qa_uu', 'qa_ee', 'qa_eueu', 'qa_pamaeh', 'ka_ex_ng', 'ka_ex_rr', 'ka_ex_hh', 'ka_ii_ng', 'ka_ii_rr', 'ka_ii_hh', 'ka_oo_ng', 'ka_oo_rr', 'ka_oo_hh', 'ka_uu_ng', 'ka_uu_rr', 'ka_uu_hh', 'ka_ee_ng', 'ka_ee_rr', 'ka_ee_hh', 'ka_eueu_ng', 'ka_eueu_rr', 'ka_eueu_hh', 'na_ex_ng', 'na_ex_rr', 'na_ex_hh', 'na_ii_ng', 'na_ii_rr', 'na_ii_hh', 'na_oo_ng', 'na_oo_rr', 'na_oo_hh', 'na_uu_ng', 'na_uu_rr', 'na_uu_hh', 'na_ee_ng', 'na_ee_rr', 'na_ee_hh', 'na_eueu_ng', 'na_eueu_rr', 'na_eueu_hh', 'pa_ex_ng', 'pa_ex_rr', 'pa_ex_hh', 'pa_ii_ng', 'pa_ii_rr', 'pa_ii_hh', 'pa_oo_ng', 'pa_oo_rr', 'pa_oo_hh', 'pa_uu_ng', 'pa_uu_rr', 'pa_uu_hh', 'pa_ee_ng', 'pa_ee_rr', 'pa_ee_hh', 'pa_eueu_ng', 'pa_eueu_rr', 'pa_eueu_hh', 'ma_ex_ng', 'ma_ex_rr', 'ma_ex_hh', 'ma_ii_ng', 'ma_ii_rr', 'ma_ii_hh', 'ma_oo_ng', 'ma_oo_rr', 'ma_oo_hh', 'ma_uu_ng', 'ma_uu_rr', 'ma_uu_hh', 'ma_ee_ng', 'ma_ee_rr', 'ma_ee_hh', 'ma_eueu_ng', 'ma_eueu_rr', 'ma_eueu_hh', 'ta_ex_ng', 'ta_ex_rr', 'ta_ex_hh', 'ta_ii_ng', 'ta_ii_rr', 'ta_ii_hh', 'ta_oo_ng', 'ta_oo_rr', 'ta_oo_hh', 'ta_uu_ng', 'ta_uu_rr', 'ta_uu_hh', 'ta_ee_ng', 'ta_ee_rr', 'ta_ee_hh', 'ta_eueu_ng', 'ta_eueu_rr', 'ta_eueu_hh', 'da_ex_ng', 'da_ex_rr', 'da_ex_hh', 'da_ii_ng', 'da_ii_rr', 'da_ii_hh', 'da_oo_ng', 'da_oo_rr', 'da_oo_hh', 'da_uu_ng', 'da_uu_rr', 'da_uu_hh', 'da_ee_ng', 'da_ee_rr', 'da_ee_hh', 'da_eueu_ng', 'da_eueu_rr', 'da_eueu_hh', 'ba_ex_ng', 'ba_ex_rr', 'ba_ex_hh', 'ba_ii_ng', 'ba_ii_rr', 'ba_ii_hh', 'ba_oo_ng', 'ba_oo_rr', 'ba_oo_hh', 'ba_uu_ng', 'ba_uu_rr', 'ba_uu_hh', 'ba_ee_ng', 'ba_ee_rr', 'ba_ee_hh', 'ba_eueu_ng', 'ba_eueu_rr', 'ba_eueu_hh', 'ga_ex_ng', 'ga_ex_rr', 'ga_ex_hh', 'ga_ii_ng', 'ga_ii_rr', 'ga_ii_hh', 'ga_oo_ng', 'ga_oo_rr', 'ga_oo_hh', 'ga_uu_ng', 'ga_uu_rr', 'ga_uu_hh', 'ga_ee_ng', 'ga_ee_rr', 'ga_ee_hh', 'ga_eueu_ng', 'ga_eueu_rr', 'ga_eueu_hh', 'ja_ex_ng', 'ja_ex_rr', 'ja_ex_hh', 'ja_ii_ng', 'ja_ii_rr', 'ja_ii_hh', 'ja_oo_ng', 'ja_oo_rr', 'ja_oo_hh', 'ja_uu_ng', 'ja_uu_rr', 'ja_uu_hh', 'ja_ee_ng', 'ja_ee_rr', 'ja_ee_hh', 'ja_eueu_ng', 'ja_eueu_rr', 'ja_eueu_hh', 'ra_ex_ng', 'ra_ex_rr', 'ra_ex_hh', 'ra_ii_ng', 'ra_ii_rr', 'ra_ii_hh', 'ra_oo_ng', 'ra_oo_rr', 'ra_oo_hh', 'ra_uu_ng', 'ra_uu_rr', 'ra_uu_hh', 'ra_ee_ng', 'ra_ee_rr', 'ra_ee_hh', 'ra_eueu_ng', 'ra_eueu_rr', 'ra_eueu_hh', 'la_ex_ng', 'la_ex_rr', 'la_ex_hh', 'la_ii_ng', 'la_ii_rr', 'la_ii_hh', 'la_oo_ng', 'la_oo_rr', 'la_oo_hh', 'la_uu_ng', 'la_uu_rr', 'la_uu_hh', 'la_ee_ng', 'la_ee_rr', 'la_ee_hh', 'la_eueu_ng', 'la_eueu_rr', 'la_eueu_hh', 'sa_ex_ng', 'sa_ex_rr', 'sa_ex_hh', 'sa_ii_ng', 'sa_ii_rr', 'sa_ii_hh', 'sa_oo_ng', 'sa_oo_rr', 'sa_oo_hh', 'sa_uu_ng', 'sa_uu_rr', 'sa_uu_hh', 'sa_ee_ng', 'sa_ee_rr', 'sa_ee_hh', 'sa_eueu_ng', 'sa_eueu_rr', 'sa_eueu_hh', 'ya_ex_ng', 'ya_ex_rr', 'ya_ex_hh', 'ya_ii_ng', 'ya_ii_rr', 'ya_ii_hh', 'ya_oo_ng', 'ya_oo_rr', 'ya_oo_hh', 'ya_uu_ng', 'ya_uu_rr', 'ya_uu_hh', 'ya_ee_ng', 'ya_ee_rr', 'ya_ee_hh', 'ya_eueu_ng', 'ya_eueu_rr', 'ya_eueu_hh', 'wa_ex_ng', 'wa_ex_rr', 'wa_ex_hh', 'wa_ii_ng', 'wa_ii_rr', 'wa_ii_hh', 'wa_oo_ng', 'wa_oo_rr', 'wa_oo_hh', 'wa_uu_ng', 'wa_uu_rr', 'wa_uu_hh', 'wa_ee_ng', 'wa_ee_rr', 'wa_ee_hh', 'wa_eueu_ng', 'wa_eueu_rr', 'wa_eueu_hh', 'ha_ex_ng', 'ha_ex_rr', 'ha_ex_hh', 'ha_ii_ng', 'ha_ii_rr', 'ha_ii_hh', 'ha_oo_ng', 'ha_oo_rr', 'ha_oo_hh', 'ha_uu_ng', 'ha_uu_rr', 'ha_uu_hh', 'ha_ee_ng', 'ha_ee_rr', 'ha_ee_hh', 'ha_eueu_ng', 'ha_eueu_rr', 'ha_eueu_hh', 'za_ex_ng', 'za_ex_rr', 'za_ex_hh', 'za_ii_ng', 'za_ii_rr', 'za_ii_hh', 'za_oo_ng', 'za_oo_rr', 'za_oo_hh', 'za_uu_ng', 'za_uu_rr', 'za_uu_hh', 'za_ee_ng', 'za_ee_rr', 'za_ee_hh', 'za_eueu_ng', 'za_eueu_rr', 'za_eueu_hh', 'xa_ex_ng', 'xa_ex_rr', 'xa_ex_hh', 'xa_ii_ng', 'xa_ii_rr', 'xa_ii_hh', 'fa_ex_ng', 'fa_ex_rr', 'fa_ex_hh', 'fa_ii_ng', 'fa_ii_rr', 'fa_ii_hh', 'fa_oo_ng', 'fa_oo_rr', 'fa_oo_hh', 'fa_uu_ng', 'fa_uu_rr', 'fa_uu_hh', 'fa_ee_ng', 'fa_ee_rr', 'fa_ee_hh', 'fa_eueu_ng', 'fa_eueu_rr', 'fa_eueu_hh', 'va_ex_ng', 'va_ex_rr', 'va_ex_hh', 'va_ii_ng', 'va_ii_rr', 'va_ii_hh', 'va_oo_ng', 'va_oo_rr', 'va_oo_hh', 'va_uu_ng', 'va_uu_rr', 'va_uu_hh', 'va_ee_ng', 'va_ee_rr', 'va_ee_hh', 'va_eueu_ng', 'va_eueu_rr', 'va_eueu_hh', 'ca_ex_ng', 'ca_ex_rr', 'ca_ex_hh', 'ca_ii_ng', 'ca_ii_rr', 'ca_ii_hh', 'ca_oo_ng', 'ca_oo_rr', 'ca_oo_hh', 'ca_uu_ng', 'ca_uu_rr', 'ca_uu_hh', 'ca_ee_ng', 'ca_ee_rr', 'ca_ee_hh', 'ca_eueu_ng', 'ca_eueu_rr', 'ca_eueu_hh', 'nya_ex_ng', 'nya_ex_rr', 'nya_ex_hh', 'nya_ii_ng', 'nya_ii_rr', 'nya_ii_hh', 'nya_oo_ng', 'nya_oo_rr', 'nya_oo_hh', 'nya_uu_ng', 'nya_uu_rr', 'nya_uu_hh', 'nya_ee_ng', 'nya_ee_rr', 'nya_ee_hh', 'nya_eueu_ng', 'nya_eueu_rr', 'nya_eueu_hh', 'kha_ex_ng', 'kha_ex_rr', 'kha_ex_hh', 'kha_ee_ng', 'kha_ee_rr', 'kha_ee_hh', 'kha_eueu_ng', 'kha_eueu_rr', 'kha_eueu_hh', 'sya_ex_ng', 'sya_ex_rr', 'sya_ex_hh', 'sya_ii_ng', 'sya_ii_rr', 'sya_ii_hh', 'sya_oo_ng', 'sya_oo_rr', 'sya_oo_hh', 'sya_uu_ng', 'sya_uu_rr', 'sya_uu_hh', 'sya_ee_ng', 'sya_ee_rr', 'sya_ee_hh', 'sya_eueu_ng', 'sya_eueu_rr', 'sya_eueu_hh', 'qa_ex_ng', 'qa_ex_rr', 'qa_ex_hh', 'qa_ii_ng', 'qa_ii_rr', 'qa_ii_hh', 'qa_oo_ng', 'qa_oo_rr', 'qa_oo_hh', 'qa_uu_ng', 'qa_uu_rr', 'qa_uu_hh', 'qa_ee_ng', 'qa_ee_rr', 'qa_ee_hh', 'qa_eueu_ng', 'qa_eueu_rr', 'qa_eueu_hh', 'ka_ex_rrr', 'ka_ex_lll', 'ka_ex_yyy', 'ka_ii_rrr', 'ka_ii_lll', 'ka_ii_yyy', 'ka_oo_rrr', 'ka_oo_lll', 'ka_oo_yyy', 'ka_uu_rrr', 'ka_uu_lll', 'ka_uu_yyy', 'ka_ee_rrr', 'ka_ee_lll', 'ka_ee_yyy', 'ka_eueu_rrr', 'ka_eueu_lll', 'ka_eueu_yyy', 'na_ex_rrr', 'na_ex_lll', 'na_ex_yyy', 'na_ii_rrr', 'na_ii_lll', 'na_ii_yyy', 'na_oo_rrr', 'na_oo_lll', 'na_oo_yyy', 'na_uu_rrr', 'na_uu_lll', 'na_uu_yyy', 'na_ee_rrr', 'na_ee_lll', 'na_ee_yyy', 'na_eueu_rrr', 'na_eueu_lll', 'na_eueu_yyy', 'pa_ex_rrr', 'pa_ex_lll', 'pa_ex_yyy', 'pa_ii_rrr', 'pa_ii_lll', 'pa_ii_yyy', 'pa_oo_rrr', 'pa_oo_lll', 'pa_oo_yyy', 'pa_uu_rrr', 'pa_uu_lll', 'pa_uu_yyy', 'pa_ee_rrr', 'pa_ee_lll', 'pa_ee_yyy', 'pa_eueu_rrr', 'pa_eueu_lll', 'pa_eueu_yyy', 'ma_ex_rrr', 'ma_ex_lll', 'ma_ex_yyy', 'ma_ii_rrr', 'ma_ii_lll', 'ma_ii_yyy', 'ma_oo_rrr', 'ma_oo_lll', 'ma_oo_yyy', 'ma_uu_rrr', 'ma_uu_lll', 'ma_uu_yyy', 'ma_ee_rrr', 'ma_ee_lll', 'ma_ee_yyy', 'ma_eueu_rrr', 'ma_eueu_lll', 'ma_eueu_yyy', 'ta_ex_rrr', 'ta_ex_lll', 'ta_ex_yyy', 'ta_ii_rrr', 'ta_ii_lll', 'ta_ii_yyy', 'ta_oo_rrr', 'ta_oo_lll', 'ta_oo_yyy', 'ta_uu_rrr', 'ta_uu_lll', 'ta_uu_yyy', 'ta_ee_rrr', 'ta_ee_lll', 'ta_ee_yyy', 'ta_eueu_rrr', 'ta_eueu_lll', 'ta_eueu_yyy', 'da_ex_rrr', 'da_ex_lll', 'da_ex_yyy', 'da_ii_rrr', 'da_ii_lll', 'da_ii_yyy', 'da_oo_rrr', 'da_oo_lll', 'da_oo_yyy', 'da_uu_rrr', 'da_uu_lll', 'da_uu_yyy', 'da_ee_rrr', 'da_ee_lll', 'da_ee_yyy', 'da_eueu_rrr', 'da_eueu_lll', 'da_eueu_yyy', 'ba_ex_rrr', 'ba_ex_lll', 'ba_ex_yyy', 'ba_ii_rrr', 'ba_ii_lll', 'ba_ii_yyy', 'ba_oo_rrr', 'ba_oo_lll', 'ba_oo_yyy', 'ba_uu_rrr', 'ba_uu_lll', 'ba_uu_yyy', 'ba_ee_rrr', 'ba_ee_lll', 'ba_ee_yyy', 'ba_eueu_rrr', 'ba_eueu_lll', 'ba_eueu_yyy', 'ga_ex_rrr', 'ga_ex_lll', 'ga_ex_yyy', 'ga_ii_rrr', 'ga_ii_lll', 'ga_ii_yyy', 'ga_oo_rrr', 'ga_oo_lll', 'ga_oo_yyy', 'ga_uu_rrr', 'ga_uu_lll', 'ga_uu_yyy', 'ga_ee_rrr', 'ga_ee_lll', 'ga_ee_yyy', 'ga_eueu_rrr', 'ga_eueu_lll', 'ga_eueu_yyy', 'ja_ex_rrr', 'ja_ex_lll', 'ja_ex_yyy', 'ja_ii_rrr', 'ja_ii_lll', 'ja_ii_yyy', 'ja_oo_rrr', 'ja_oo_lll', 'ja_oo_yyy', 'ja_uu_rrr', 'ja_uu_lll', 'ja_uu_yyy', 'ja_ee_rrr', 'ja_ee_lll', 'ja_ee_yyy', 'ra_ii_rrr', 'ra_ii_lll', 'ra_ii_yyy', 'ra_oo_rrr', 'ra_oo_lll', 'ra_oo_yyy', 'ra_uu_rrr', 'ra_uu_lll', 'ra_uu_yyy', 'ra_ee_rrr', 'ra_ee_lll', 'ra_ee_yyy', 'ra_eueu_rrr', 'ra_eueu_lll', 'ra_eueu_yyy', 'la_ex_rrr', 'la_ex_lll', 'la_ex_yyy', 'la_ii_rrr', 'la_ii_lll', 'la_ii_yyy', 'la_oo_rrr', 'la_oo_lll', 'la_oo_yyy', 'la_uu_rrr', 'la_uu_lll', 'la_uu_yyy', 'la_ee_rrr', 'la_ee_lll', 'la_ee_yyy', 'sa_ex_rrr', 'sa_ex_lll', 'sa_ex_yyy', 'sa_ii_rrr', 'sa_ii_lll', 'sa_ii_yyy', 'sa_oo_rrr', 'sa_oo_lll', 'sa_oo_yyy', 'sa_uu_rrr', 'sa_uu_lll', 'sa_uu_yyy', 'sa_ee_rrr', 'sa_ee_lll', 'sa_ee_yyy', 'sa_eueu_rrr', 'sa_eueu_lll', 'sa_eueu_yyy', 'ya_ex_rrr', 'ya_ex_lll', 'ya_ex_yyy', 'ya_ii_rrr', 'ya_ii_lll', 'ya_ii_yyy', 'ya_oo_rrr', 'ya_oo_lll', 'ya_oo_yyy', 'ya_uu_rrr', 'ya_uu_lll', 'ya_uu_yyy', 'ya_ee_rrr', 'ya_ee_lll', 'ya_ee_yyy', 'ya_eueu_rrr', 'ya_eueu_lll', 'ya_eueu_yyy', 'wa_ex_rrr', 'wa_ex_lll', 'wa_ex_yyy', 'wa_ii_rrr', 'wa_ii_lll', 'wa_ii_yyy', 'wa_oo_rrr', 'wa_oo_lll', 'wa_oo_yyy', 'wa_uu_rrr', 'wa_uu_lll', 'wa_uu_yyy', 'wa_ee_rrr', 'wa_ee_lll', 'wa_ee_yyy', 'wa_eueu_rrr', 'wa_eueu_lll', 'wa_eueu_yyy', 'ha_ex_rrr', 'ha_ex_lll', 'ha_ex_yyy', 'ha_ii_rrr', 'ha_ii_lll', 'ha_ii_yyy', 'ha_oo_rrr', 'ha_oo_lll', 'ha_oo_yyy', 'ha_uu_rrr', 'ha_uu_lll', 'ha_uu_yyy', 'ha_ee_rrr', 'ha_ee_lll', 'ha_ee_yyy', 'ha_eueu_rrr', 'ha_eueu_lll', 'ha_eueu_yyy', 'fa_ex_rrr', 'fa_ex_lll', 'fa_ex_yyy', 'fa_ii_rrr', 'fa_ii_lll', 'fa_ii_yyy', 'fa_oo_rrr', 'fa_oo_lll', 'fa_oo_yyy', 'fa_uu_rrr', 'fa_uu_lll', 'fa_ee_rrr', 'fa_ee_lll', 'ca_ii_rrr', 'ca_ii_lll', 'ca_ii_yyy', 'ca_oo_rrr', 'ca_oo_lll', 'ca_oo_yyy', 'ca_uu_rrr', 'ca_uu_lll', 'ca_uu_yyy']\n",
        "base_target_tokens = ['target', 'a', 'i', 'u', 'e', 'o', 'eu', 'é' ,'ang', 'ah', 'ar',\n",
        "          'ing', 'ih', 'ir',\n",
        "          'ung', 'uh', 'ur',\n",
        "          'eng', 'eh', 'er',\n",
        "          'ong', 'oh', 'or', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', 'ka', 'na', 'pa', 'ma', 'ta', 'da', 'ba', 'ga', 'ja', 'ra', 'la', 'sa', 'ya', 'wa', 'ha', 'za', 'xa', 'fa', 'va', 'ca', 'nya', 'kha', 'sya', 'qa', 'kang', 'kar', 'kah', 'nang', 'nar', 'nah', 'pang', 'par', 'pah', 'mang', 'mar', 'mah', 'tang', 'tar', 'tah', 'dang', 'dar', 'dah', 'bang', 'bar', 'bah', 'gang', 'gar', 'gah', 'jang', 'jar', 'jah', 'rang', 'rar', 'rah', 'lang', 'lar', 'lah', 'sang', 'sar', 'sah', 'yang', 'yar', 'yah', 'wang', 'war', 'wah', 'hang', 'har', 'hah', 'zang', 'zar', 'zah', 'xang', 'xar', 'xah', 'fang', 'far', 'fah', 'vang', 'var', 'vah', 'cang', 'car', 'cah', 'nyang', 'nyar', 'nyah', 'khang', 'khar', 'khah', 'syang', 'syar', 'syah', 'qang', 'qar', 'qah', 'kra', 'kla', 'kya', 'nra', 'nla', 'nya', 'pra', 'pla', 'pya', 'mra', 'mla', 'mya', 'tra', 'tla', 'tya', 'dra', 'dla', 'dya', 'bra', 'bla', 'bya', 'gra', 'gla', 'gya', 'jra', 'jla', 'jya', 'rra', 'rla', 'rya', 'lra', 'lla', 'lya', 'sra', 'sla', 'sya', 'yra', 'yla', 'yya', 'wra', 'wla', 'wya', 'hra', 'hla', 'hya', 'zra', 'zla', 'zya', 'xra', 'xla', 'xya', 'fra', 'fla', 'fya', 'vra', 'vla', 'vya', 'cra', 'cla', 'cya', 'qra', 'qla', 'qya', 'ké', 'ki', 'ko', 'ku', 'ke', 'keu', 'k', 'né', 'ni', 'no', 'nu', 'ne', 'neu', 'n', 'pé', 'pi', 'po', 'pu', 'pe', 'peu', 'p', 'mé', 'mi', 'mo', 'mu', 'me', 'meu', 'm', 'té', 'ti', 'to', 'tu', 'te', 'teu', 't', 'dé', 'di', 'do', 'du', 'de', 'deu', 'd', 'bé', 'bi', 'bo', 'bu', 'be', 'beu', 'b', 'gé', 'gi', 'go', 'gu', 'ge', 'geu', 'g', 'jé', 'ji', 'jo', 'ju', 'je', 'jeu', 'j', 'ré', 'ri', 'ro', 'ru', 're', 'reu', 'r', 'lé', 'li', 'lo', 'lu', 'le', 'leu', 'l', 'sé', 'si', 'so', 'su', 'se', 'seu', 's', 'yé', 'yi', 'yo', 'yu', 'ye', 'yeu', 'y', 'wé', 'wi', 'wo', 'wu', 'we', 'weu', 'w', 'hé', 'hi', 'ho', 'hu', 'he', 'heu', 'h', 'zé', 'zi', 'zo', 'zu', 'ze', 'zeu', 'z', 'xé', 'xi', 'xo', 'xu', 'xe', 'xeu', 'x', 'fé', 'fi', 'fo', 'fu', 'fe', 'feu', 'f', 'vé', 'vi', 'vo', 'vu', 've', 'veu', 'v', 'cé', 'ci', 'co', 'cu', 'ce', 'ceu', 'c', 'nyé', 'nyi', 'nyo', 'nyu', 'nye', 'nyeu', 'ny', 'khé', 'khi', 'kho', 'khu', 'khe', 'kheu', 'kh', 'syé', 'syi', 'syo', 'syu', 'sye', 'syeu', 'sy', 'qé', 'qi', 'qo', 'qu', 'qe', 'qeu', 'q', 'kéng', 'kér', 'kéh', 'king', 'kir', 'kih', 'kong', 'kor', 'koh', 'kung', 'kur', 'kuh', 'keng', 'ker', 'keh', 'keung', 'keur', 'keuh', 'néng', 'nér', 'néh', 'ning', 'nir', 'nih', 'nong', 'nor', 'noh', 'nung', 'nur', 'nuh', 'neng', 'ner', 'neh', 'neung', 'neur', 'neuh', 'péng', 'pér', 'péh', 'ping', 'pir', 'pih', 'pong', 'por', 'poh', 'pung', 'pur', 'puh', 'peng', 'per', 'peh', 'peung', 'peur', 'peuh', 'méng', 'mér', 'méh', 'ming', 'mir', 'mih', 'mong', 'mor', 'moh', 'mung', 'mur', 'muh', 'meng', 'mer', 'meh', 'meung', 'meur', 'meuh', 'téng', 'tér', 'téh', 'ting', 'tir', 'tih', 'tong', 'tor', 'toh', 'tung', 'tur', 'tuh', 'teng', 'ter', 'teh', 'teung', 'teur', 'teuh', 'déng', 'dér', 'déh', 'ding', 'dir', 'dih', 'dong', 'dor', 'doh', 'dung', 'dur', 'duh', 'deng', 'der', 'deh', 'deung', 'deur', 'deuh', 'béng', 'bér', 'béh', 'bing', 'bir', 'bih', 'bong', 'bor', 'boh', 'bung', 'bur', 'buh', 'beng', 'ber', 'beh', 'beung', 'beur', 'beuh', 'géng', 'gér', 'géh', 'ging', 'gir', 'gih', 'gong', 'gor', 'goh', 'gung', 'gur', 'guh', 'geng', 'ger', 'geh', 'geung', 'geur', 'geuh', 'jéng', 'jér', 'jéh', 'jing', 'jir', 'jih', 'jong', 'jor', 'joh', 'jung', 'jur', 'juh', 'jeng', 'jer', 'jeh', 'jeung', 'jeur', 'jeuh', 'réng', 'rér', 'réh', 'ring', 'rir', 'rih', 'rong', 'ror', 'roh', 'rung', 'rur', 'ruh', 'reng', 'rer', 'reh', 'reung', 'reur', 'reuh', 'léng', 'lér', 'léh', 'ling', 'lir', 'lih', 'long', 'lor', 'loh', 'lung', 'lur', 'luh', 'leng', 'ler', 'leh', 'leung', 'leur', 'leuh', 'séng', 'sér', 'séh', 'sing', 'sir', 'sih', 'song', 'sor', 'soh', 'sung', 'sur', 'suh', 'seng', 'ser', 'seh', 'seung', 'seur', 'seuh', 'yéng', 'yér', 'yéh', 'ying', 'yir', 'yih', 'yong', 'yor', 'yoh', 'yung', 'yur', 'yuh', 'yeng', 'yer', 'yeh', 'yeung', 'yeur', 'yeuh', 'wéng', 'wér', 'wéh', 'wing', 'wir', 'wih', 'wong', 'wor', 'woh', 'wung', 'wur', 'wuh', 'weng', 'wer', 'weh', 'weung', 'weur', 'weuh', 'héng', 'hér', 'héh', 'hing', 'hir', 'hih', 'hong', 'hor', 'hoh', 'hung', 'hur', 'huh', 'heng', 'her', 'heh', 'heung', 'heur', 'heuh', 'zéng', 'zér', 'zéh', 'zing', 'zir', 'zih', 'zong', 'zor', 'zoh', 'zung', 'zur', 'zuh', 'zeng', 'zer', 'zeh', 'zeung', 'zeur', 'zeuh', 'xéng', 'xér', 'xéh', 'xing', 'xir', 'xih', 'féng', 'fér', 'féh', 'fing', 'fir', 'fih', 'fong', 'for', 'foh', 'fung', 'fur', 'fuh', 'feng', 'fer', 'feh', 'feung', 'feur', 'feuh', 'véng', 'vér', 'véh', 'ving', 'vir', 'vih', 'vong', 'vor', 'voh', 'vung', 'vur', 'vuh', 'veng', 'ver', 'veh', 'veung', 'veur', 'veuh', 'céng', 'cér', 'céh', 'cing', 'cir', 'cih', 'cong', 'cor', 'coh', 'cung', 'cur', 'cuh', 'ceng', 'cer', 'ceh', 'ceung', 'ceur', 'ceuh', 'nyéng', 'nyér', 'nyéh', 'nying', 'nyir', 'nyih', 'nyong', 'nyor', 'nyoh', 'nyung', 'nyur', 'nyuh', 'nyeng', 'nyer', 'nyeh', 'nyeung', 'nyeur', 'nyeuh', 'khéng', 'khér', 'khéh', 'kheng', 'kher', 'kheh', 'kheung', 'kheur', 'kheuh', 'syéng', 'syér', 'syéh', 'sying', 'syir', 'syih', 'syong', 'syor', 'syoh', 'syung', 'syur', 'syuh', 'syeng', 'syer', 'syeh', 'syeung', 'syeur', 'syeuh', 'qéng', 'qér', 'qéh', 'qing', 'qir', 'qih', 'qong', 'qor', 'qoh', 'qung', 'qur', 'quh', 'qeng', 'qer', 'qeh', 'qeung', 'qeur', 'qeuh', 'kré', 'klé', 'kyé', 'kri', 'kli', 'kyi', 'kro', 'klo', 'kyo', 'kru', 'klu', 'kyu', 'kre', 'kle', 'kye', 'kreu', 'kleu', 'kyeu', 'nré', 'nlé', 'nyé', 'nri', 'nli', 'nyi', 'nro', 'nlo', 'nyo', 'nru', 'nlu', 'nyu', 'nre', 'nle', 'nye', 'nreu', 'nleu', 'nyeu', 'pré', 'plé', 'pyé', 'pri', 'pli', 'pyi', 'pro', 'plo', 'pyo', 'pru', 'plu', 'pyu', 'pre', 'ple', 'pye', 'preu', 'pleu', 'pyeu', 'mré', 'mlé', 'myé', 'mri', 'mli', 'myi', 'mro', 'mlo', 'myo', 'mru', 'mlu', 'myu', 'mre', 'mle', 'mye', 'mreu', 'mleu', 'myeu', 'tré', 'tlé', 'tyé', 'tri', 'tli', 'tyi', 'tro', 'tlo', 'tyo', 'tru', 'tlu', 'tyu', 'tre', 'tle', 'tye', 'treu', 'tleu', 'tyeu', 'dré', 'dlé', 'dyé', 'dri', 'dli', 'dyi', 'dro', 'dlo', 'dyo', 'dru', 'dlu', 'dyu', 'dre', 'dle', 'dye', 'dreu', 'dleu', 'dyeu', 'bré', 'blé', 'byé', 'bri', 'bli', 'byi', 'bro', 'blo', 'byo', 'bru', 'blu', 'byu', 'bre', 'ble', 'bye', 'breu', 'bleu', 'byeu', 'gré', 'glé', 'gyé', 'gri', 'gli', 'gyi', 'gro', 'glo', 'gyo', 'gru', 'glu', 'gyu', 'gre', 'gle', 'gye', 'greu', 'gleu', 'gyeu', 'jré', 'jlé', 'jyé', 'jri', 'jli', 'jyi', 'jro', 'jlo', 'jyo', 'jru', 'jlu', 'jyu', 'jre', 'jle', 'jye', 'rri', 'rli', 'ryi', 'rro', 'rlo', 'ryo', 'rru', 'rlu', 'ryu', 'rre', 'rle', 'rye', 'rreu', 'rleu', 'ryeu', 'lré', 'llé', 'lyé', 'lri', 'lli', 'lyi', 'lro', 'llo', 'lyo', 'lru', 'llu', 'lyu', 'lre', 'lle', 'lye', 'sré', 'slé', 'syé', 'sri', 'sli', 'syi', 'sro', 'slo', 'syo', 'sru', 'slu', 'syu', 'sre', 'sle', 'sye', 'sreu', 'sleu', 'syeu', 'yré', 'ylé', 'yyé', 'yri', 'yli', 'yyi', 'yro', 'ylo', 'yyo', 'yru', 'ylu', 'yyu', 'yre', 'yle', 'yye', 'yreu', 'yleu', 'yyeu', 'wré', 'wlé', 'wyé', 'wri', 'wli', 'wyi', 'wro', 'wlo', 'wyo', 'wru', 'wlu', 'wyu', 'wre', 'wle', 'wye', 'wreu', 'wleu', 'wyeu', 'hré', 'hlé', 'hyé', 'hri', 'hli', 'hyi', 'hro', 'hlo', 'hyo', 'hru', 'hlu', 'hyu', 'hre', 'hle', 'hye', 'hreu', 'hleu', 'hyeu', 'fré', 'flé', 'fyé', 'fri', 'fli', 'fyi', 'fro', 'flo', 'fyo', 'fru', 'flu', 'fre', 'fle', 'cri', 'cli', 'cyi', 'cro', 'clo', 'cyo', 'cru', 'clu', 'cyu']\n",
        "\n",
        "# dataset generation\n",
        "filename = \"dataset.csv\"\n",
        "with open(filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"source\", \"target\"])\n",
        "\n",
        "    total_rrows = 0\n",
        "    target_rrows = 3000\n",
        "\n",
        "    # First ensure every token is used at least once\n",
        "    for src_token in base_source_tokens:\n",
        "        tgt_token = base_target_tokens[base_source_tokens.index(src_token)]\n",
        "        writer.writerow([src_token.lower(), tgt_token.lower()])\n",
        "        total_rrows += 1\n",
        "\n",
        "    # Then fill remaining rows with random combinations\n",
        "    while total_rrows < target_rrows:\n",
        "        length = random.randint(1, 30)\n",
        "        src_tokens = random.sample(base_source_tokens, k=length)\n",
        "        tgt_tokens = [\n",
        "            base_target_tokens[base_source_tokens.index(w)] if w in base_source_tokens else w\n",
        "            for w in src_tokens\n",
        "        ]\n",
        "        writer.writerow([\" \".join(src_tokens).lower(), \" \".join(tgt_tokens).lower()])\n",
        "        total_rrows += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8N0wiRQ5EXo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# 1. Data Preparation\n",
        "df = pd.read_csv(\"dataset.csv\")\n",
        "\n",
        "# Split into train and test sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "def build_vocab(tokens):\n",
        "    vocab = {tok: i+4 for i, tok in enumerate(tokens)}\n",
        "    vocab[\"<pad>\"] = 0\n",
        "    vocab[\"<sos>\"] = 1\n",
        "    vocab[\"<eos>\"] = 2\n",
        "    vocab[\"<unk>\"] = 3\n",
        "    return vocab\n",
        "\n",
        "source_tokens = [t.lower() for t in df['source'].str.split().explode().unique()]\n",
        "target_tokens = [t.lower() for t in df['target'].str.split().explode().unique()]\n",
        "SRC_VOCAB = build_vocab(source_tokens)\n",
        "TGT_VOCAB = build_vocab(target_tokens)\n",
        "SRC_IVOCAB = {i: t for t, i in SRC_VOCAB.items()}\n",
        "TGT_IVOCAB = {i: t for t, i in TGT_VOCAB.items()}\n",
        "\n",
        "def encode(tokens, vocab):\n",
        "    return [vocab.get(tok, vocab[\"<unk>\"]) for tok in tokens]\n",
        "\n",
        "class Seq2SeqDataset(Dataset):\n",
        "    def __init__(self, df, src_vocab, tgt_vocab):\n",
        "        self.pairs = []\n",
        "        for _, row in df.iterrows():\n",
        "            src = encode(row['source'].split(), src_vocab)\n",
        "            tgt = [tgt_vocab[\"<sos>\"]] + encode(row['target'].split(), tgt_vocab) + [tgt_vocab[\"<eos>\"]]\n",
        "            self.pairs.append((src, tgt))\n",
        "    def __len__(self): return len(self.pairs)\n",
        "    def __getitem__(self, idx): return self.pairs[idx]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    srcs, tgts = zip(*batch)\n",
        "    src_lens = [len(s) for s in srcs]\n",
        "    tgt_lens = [len(t) for t in tgts]\n",
        "    src_pad = torch.zeros(len(srcs), max(src_lens), dtype=torch.long)\n",
        "    tgt_pad = torch.zeros(len(tgts), max(tgt_lens), dtype=torch.long)\n",
        "    for i, (s, t) in enumerate(zip(srcs, tgts)):\n",
        "        src_pad[i, :len(s)] = torch.tensor(s)\n",
        "        tgt_pad[i, :len(t)] = torch.tensor(t)\n",
        "    return src_pad, tgt_pad, src_lens, tgt_lens\n",
        "\n",
        "# Use train_df and test_df to create datasets and loaders\n",
        "train_dataset = Seq2SeqDataset(train_df, SRC_VOCAB, TGT_VOCAB)\n",
        "test_dataset = Seq2SeqDataset(test_df, SRC_VOCAB, TGT_VOCAB)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xza1LHyv5J28"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 2. Model Definition\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim, n_layers=1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=SRC_VOCAB[\"<pad>\"])\n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers, bidirectional=False, batch_first=True)\n",
        "    def forward(self, src, src_lens):\n",
        "        emb = self.embedding(src)\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(emb, src_lens, batch_first=True, enforce_sorted=False)\n",
        "        outputs, (h, c) = self.lstm(packed)\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
        "        return outputs, (h, c)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim, n_layers=1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=TGT_VOCAB[\"<pad>\"])\n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers, batch_first=True)\n",
        "        self.fc_out = nn.Linear(hid_dim, vocab_size)\n",
        "    def forward(self, input, hidden, cell):\n",
        "        input = input.unsqueeze(1)\n",
        "        emb = self.embedding(input)\n",
        "        output, (hidden, cell) = self.lstm(emb, (hidden, cell))\n",
        "        output = output.squeeze(1)\n",
        "        pred = self.fc_out(output)\n",
        "        return pred, hidden, cell\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.device = device\n",
        "    def forward(self, src, src_lens, tgt, teacher_forcing_ratio=0.5):\n",
        "        batch_size, tgt_len = tgt.shape\n",
        "        outputs = torch.zeros(batch_size, tgt_len, self.decoder.embedding.num_embeddings).to(self.device)\n",
        "        encoder_outputs, (h, c) = self.encoder(src, src_lens)\n",
        "        h_dec = h\n",
        "        c_dec = c\n",
        "        input = tgt[:,0]\n",
        "        for t in range(1, tgt_len):\n",
        "            output, h_dec, c_dec = self.decoder(input, h_dec, c_dec)\n",
        "            outputs[:,t] = output\n",
        "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "            input = tgt[:,t] if teacher_force else top1\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OGoFkhF5YXV",
        "outputId": "0c56b1d8-8be0-4497-aa44-7cbe4c5eee83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 6.5498\n",
            "Epoch 2, Loss: 6.2325\n",
            "Epoch 3, Loss: 6.0990\n",
            "Epoch 4, Loss: 6.0183\n",
            "Epoch 5, Loss: 5.9480\n",
            "Epoch 6, Loss: 5.8234\n",
            "Epoch 7, Loss: 5.5892\n",
            "Epoch 8, Loss: 5.2487\n",
            "Epoch 9, Loss: 4.8467\n",
            "Epoch 10, Loss: 4.4323\n",
            "Epoch 11, Loss: 4.0217\n",
            "Epoch 12, Loss: 3.6427\n",
            "Epoch 13, Loss: 3.3047\n",
            "Epoch 14, Loss: 3.0003\n",
            "Epoch 15, Loss: 2.7282\n",
            "Epoch 16, Loss: 2.4757\n",
            "Epoch 17, Loss: 2.2396\n",
            "Epoch 18, Loss: 2.0612\n",
            "Epoch 19, Loss: 1.8654\n",
            "Epoch 20, Loss: 1.7051\n",
            "Epoch 21, Loss: 1.5496\n",
            "Epoch 22, Loss: 1.4023\n",
            "Epoch 23, Loss: 1.2646\n",
            "Epoch 24, Loss: 1.1412\n",
            "Epoch 25, Loss: 1.0351\n",
            "Epoch 26, Loss: 0.9332\n",
            "Epoch 27, Loss: 0.8364\n",
            "Epoch 28, Loss: 0.7479\n",
            "Epoch 29, Loss: 0.6647\n",
            "Epoch 30, Loss: 0.5855\n",
            "Epoch 31, Loss: 0.5025\n",
            "Epoch 32, Loss: 0.4426\n",
            "Epoch 33, Loss: 0.3863\n",
            "Epoch 34, Loss: 0.3448\n",
            "Epoch 35, Loss: 0.3013\n",
            "Epoch 36, Loss: 0.2600\n",
            "Epoch 37, Loss: 0.2261\n",
            "Epoch 38, Loss: 0.2011\n",
            "Epoch 39, Loss: 0.1789\n",
            "Epoch 40, Loss: 0.1578\n",
            "Epoch 41, Loss: 0.1417\n",
            "Epoch 42, Loss: 0.1254\n",
            "Epoch 43, Loss: 0.1136\n",
            "Epoch 44, Loss: 0.1032\n",
            "Epoch 45, Loss: 0.0937\n",
            "Epoch 46, Loss: 0.0869\n",
            "Epoch 47, Loss: 0.0822\n",
            "Epoch 48, Loss: 0.0766\n",
            "Epoch 49, Loss: 0.0706\n",
            "Epoch 50, Loss: 0.0640\n",
            "Epoch 51, Loss: 0.0583\n",
            "Epoch 52, Loss: 0.0552\n",
            "Epoch 53, Loss: 0.0525\n",
            "Epoch 54, Loss: 0.0481\n",
            "Epoch 55, Loss: 0.0447\n",
            "Epoch 56, Loss: 0.0406\n",
            "Epoch 57, Loss: 0.0375\n",
            "Epoch 58, Loss: 0.0348\n",
            "Epoch 59, Loss: 0.0327\n",
            "Epoch 60, Loss: 0.0304\n",
            "Epoch 61, Loss: 0.0286\n",
            "Epoch 62, Loss: 0.0269\n",
            "Epoch 63, Loss: 0.0254\n",
            "Epoch 64, Loss: 0.0240\n",
            "Epoch 65, Loss: 0.0226\n",
            "Epoch 66, Loss: 0.0214\n",
            "Epoch 67, Loss: 0.0206\n",
            "Epoch 68, Loss: 0.0217\n",
            "Epoch 69, Loss: 0.0210\n",
            "Epoch 70, Loss: 0.0249\n",
            "Epoch 71, Loss: 0.0334\n",
            "Epoch 72, Loss: 0.1377\n",
            "Epoch 73, Loss: 0.6154\n",
            "Epoch 74, Loss: 0.5704\n",
            "Epoch 75, Loss: 0.2971\n",
            "Epoch 76, Loss: 0.1304\n",
            "Epoch 77, Loss: 0.0601\n",
            "Epoch 78, Loss: 0.0351\n"
          ]
        }
      ],
      "source": [
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "INPUT_DIM = len(SRC_VOCAB)\n",
        "OUTPUT_DIM = len(TGT_VOCAB)\n",
        "ENC_EMB_DIM = 128\n",
        "DEC_EMB_DIM = 128\n",
        "HID_DIM = 256\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM)\n",
        "model = Seq2Seq(enc, dec, SRC_VOCAB[\"<pad>\"], device).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TGT_VOCAB[\"<pad>\"])\n",
        "\n",
        "# Metric evaluation functions\n",
        "def levenshtein(ref, hyp):\n",
        "    m, n = len(ref), len(hyp)\n",
        "    dp = np.zeros((m + 1, n + 1), dtype=int)\n",
        "    for i in range(m + 1):\n",
        "        dp[i][0] = i\n",
        "    for j in range(n + 1):\n",
        "        dp[0][j] = j\n",
        "    for i in range(1, m + 1):\n",
        "        for j in range(1, n + 1):\n",
        "            if ref[i - 1] == hyp[j - 1]:\n",
        "                dp[i][j] = dp[i - 1][j - 1]\n",
        "            else:\n",
        "                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n",
        "    return dp[m][n]\n",
        "\n",
        "def compute_cer(ref, hyp):\n",
        "    ref = ref.replace(' ', '')\n",
        "    hyp = hyp.replace(' ', '')\n",
        "    if len(ref) == 0:\n",
        "        return 0.0 if len(hyp) == 0 else 1.0\n",
        "    return levenshtein(ref, hyp) / len(ref)\n",
        "\n",
        "def compute_wer(ref, hyp):\n",
        "    ref_words = ref.split()\n",
        "    hyp_words = hyp.split()\n",
        "    if len(ref_words) == 0:\n",
        "        return 0.0 if len(hyp_words) == 0 else 1.0\n",
        "    return levenshtein(ref_words, hyp_words) / len(ref_words)\n",
        "\n",
        "# Use train_loader for training\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for src, tgt, src_lens, tgt_lens in train_loader:\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, src_lens, tgt)\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[:,1:].reshape(-1, output_dim)\n",
        "        tgt = tgt[:,1:].reshape(-1)\n",
        "        loss = criterion(output, tgt)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-6h5g3O6XTH"
      },
      "outputs": [],
      "source": [
        "def translate(model, src_sentence, max_len=30):\n",
        "    model.eval()\n",
        "    src_tokens = encode(src_sentence.lower().split(), SRC_VOCAB)\n",
        "    src_tensor = torch.tensor(src_tokens).unsqueeze(0).to(device)\n",
        "    src_lens = [len(src_tokens)]\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, (h, c) = model.encoder(src_tensor, src_lens)\n",
        "        h_dec = h\n",
        "        c_dec = c\n",
        "        input = torch.tensor([TGT_VOCAB[\"<sos>\"]]).to(device)\n",
        "        result = []\n",
        "        for _ in range(max_len):\n",
        "            output, h_dec, c_dec = model.decoder(input, h_dec, c_dec)\n",
        "            top1 = output.argmax(1)\n",
        "            if top1.item() == TGT_VOCAB[\"<eos>\"]:\n",
        "                break\n",
        "            result.append(TGT_IVOCAB[top1.item()])\n",
        "            input = top1\n",
        "    return \" \".join(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTRBYcaZ6TIc",
        "outputId": "f49d1d9a-b2ab-4f6d-8c7d-78e2681e6498"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 1:\n",
            "  Source:    ca_ng qa_rr nya_ii_r fa_ee_h la_ii_yy ya_pamaeh ba_uu_r da_h ja_oo_h\n",
            "  Target:    cang qra nyir feh lyi y bur dah joh\n",
            "  Predicted: heu cing kar hyu heng mreu joh voh la\n",
            "  CER: 85.19%, WER: 100.00%\n",
            "\n",
            "Example 2:\n",
            "  Source:    ka_eueu_ll va_ee_h ga_r ya_ii_h pa_ii_yy\n",
            "  Target:    kleu veh gar yih pyi\n",
            "  Predicted: veh veh gar kleu\n",
            "  CER: 56.25%, WER: 60.00%\n",
            "\n",
            "Example 3:\n",
            "  Source:    ma_ee_r la_ee_ll ka_eueu_ng ca_eueu_h pa_oo_rr da_ee_rr ha_eueu_rr ga_ex_yy xa_ii_h xa_ll ra_ii_ng ca_eueu_r na_oo_yy da_ii_h nya_ex_h sa na_uu_h fa_ex_r kha_ee_ng na_ee_h\n",
            "  Target:    mer lle keung ceuh pro dre hreu gyé xih xla ring ceur nyo dih nyéh sa nuh fér kheng neh\n",
            "  Predicted: jyo nlé mlé kyé zeh qong nreu xih bli 8 zo je hleu ceur wreu tyo khang wung hle\n",
            "  CER: 79.41%, WER: 95.00%\n",
            "\n",
            "Example 4:\n",
            "  Source:    la_pamaeh\n",
            "  Target:    l\n",
            "  Predicted: nye\n",
            "  CER: 300.00%, WER: 100.00%\n",
            "\n",
            "Example 5:\n",
            "  Source:    ya_r za_eueu_r pa_oo_yy ta_uu_h ra_ee_ng pa_oo ma pa_pamaeh ca_oo_h ca_oo_r na_ii_yy ta_ex_h da_ex\n",
            "  Target:    yar zeur pyo tuh reng po ma p coh cor nyi téh dé\n",
            "  Predicted: tuh xéng tuh ma vong ylu mya fri dyi héh heung xéh gi\n",
            "  CER: 94.44%, WER: 100.00%\n",
            "\n",
            "Example 6:\n",
            "  Source:    da_ii pa_eueu_ll pa_oo_ng ba_r ja_ii_yy za_eueu_h wa_ll va_h ga_oo_ng ha_ee_r ya_ii_ng sya_oo na_uu_rr\n",
            "  Target:    di pleu pong bar jyi zeuh wla vah gong her ying syo nru\n",
            "  Predicted: c pleu veuh yyé gong kor gong bar 0 cung jer yong byi\n",
            "  CER: 74.42%, WER: 92.31%\n",
            "\n",
            "Example 7:\n",
            "  Source:    pa_uu_yy sa_ng fa_oo_h ta_ex_ll ha_eueu_rr la_uu_h sa_ii_r\n",
            "  Target:    pyu sang foh tlé hreu luh sir\n",
            "  Predicted: sang bér to kho pyu feh\n",
            "  CER: 69.57%, WER: 85.71%\n",
            "\n",
            "Example 8:\n",
            "  Source:    pa_eueu_r ja_ex nya_ex_r la_ex_h fa_ee_rr ra_ee ga_eueu_r nya_r ka_ee_yy wa_pamaeh pa_ex_yy ja_eueu_h la_eueu ta_ex_r ta_ex_yy kha_eueu_r ca_ex fa_uu_r pa_yy ma_eueu\n",
            "  Target:    peur jé nyér léh fre re geur nyar kye w pyé jeuh leu tér tyé kheur cé fur pya meu\n",
            "  Predicted: por néh peur mih peur klu ye tor véh pra teung pra bé téng zir téng zéng yle mleu suh\n",
            "  CER: 82.26%, WER: 100.00%\n",
            "\n",
            "Example 9:\n",
            "  Source:    ma_uu_h\n",
            "  Target:    muh\n",
            "  Predicted: muh\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 10:\n",
            "  Source:    pa_ee_ll fa_yy ta_ll ma_ex_ll la_uu_ll na_ii_ng ya_uu_rr ya_ii_rr pa_ee_yy ma_ee_ng wa_eueu ha_eueu_rr da_uu_h fa_uu_h na_ng dua\n",
            "  Target:    ple fya tla mlé llu ning yru yri pye meng weu hreu duh fuh nang 2\n",
            "  Predicted: fuh gé sar veu gé weu muh dor nyi byeu pro dah zéng hér ja\n",
            "  CER: 80.00%, WER: 100.00%\n",
            "\n",
            "Example 11:\n",
            "  Source:    ca_oo_ng ka_ee_ll ca_eueu_ng xa_ii_r ka_uu_rr ra_ii_rr ja_oo_rr na_oo_yy ca_ii_ng ba_oo_ng fa_ee\n",
            "  Target:    cong kle ceung xir kru rri jro nyo cing bong fe\n",
            "  Predicted: kle rla kle xir nru ryi lré seuh hong seuh cing\n",
            "  CER: 75.68%, WER: 90.91%\n",
            "\n",
            "Example 12:\n",
            "  Source:    ta_ng\n",
            "  Target:    tang\n",
            "  Predicted: tang\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 13:\n",
            "  Source:    fa_oo_r\n",
            "  Target:    for\n",
            "  Predicted: for\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 14:\n",
            "  Source:    sa_oo_r nya_h opat na_ii_h ka_ii qa_eueu_r na_eueu_h na_ee_yy wa_ii_ll za_ll kha_ee_r ya_oo_ll na_uu_ll da_pamaeh\n",
            "  Target:    sor nyah 4 nih ki qeur neuh nye wli zla kher ylo nlu d\n",
            "  Predicted: sor tlu nyor gli gyeu sye bré dih mreu feur dih clo yla fung\n",
            "  CER: 82.93%, WER: 92.86%\n",
            "\n",
            "Example 15:\n",
            "  Source:    ga_ii_r wa_ee_ll ta_ex_rr ta ca_uu_rr ma_ll za_oo_ng ga_r ca_eueu\n",
            "  Target:    gir wle tré ta cru mla zong gar ceu\n",
            "  Predicted: ta vih fra vih for nér feuh hah kheur\n",
            "  CER: 96.30%, WER: 100.00%\n",
            "\n",
            "Example 16:\n",
            "  Source:    ja_ex_yy\n",
            "  Target:    jyé\n",
            "  Predicted: jyé\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 17:\n",
            "  Source:    wa_oo_yy ca_ii_h da_uu_r da_yy da_ii_yy la_eueu_h ga_oo_yy sa_eueu_ll sa_ii_ll ya_ii_ll\n",
            "  Target:    wyo cih dur dya dyi leuh gyo sleu sli yli\n",
            "  Predicted: wuh cih gyo dya weur sli tli weur wlu jung\n",
            "  CER: 71.88%, WER: 80.00%\n",
            "\n",
            "Example 18:\n",
            "  Source:    ga_ii_ng\n",
            "  Target:    ging\n",
            "  Predicted: ging\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 19:\n",
            "  Source:    ma_ex_yy va_ii_r ta_ii_ng\n",
            "  Target:    myé vir ting\n",
            "  Predicted: myé fyo nyeur\n",
            "  CER: 80.00%, WER: 66.67%\n",
            "\n",
            "Example 20:\n",
            "  Source:    qa_r la_oo_r ma_ex_rr ga_ee ca_ll fa_ex_ll\n",
            "  Target:    qar lor mré ge cla flé\n",
            "  Predicted: rye tli kuh ge lor flé\n",
            "  CER: 70.59%, WER: 66.67%\n",
            "\n",
            "Example 21:\n",
            "  Source:    na_r\n",
            "  Target:    nar\n",
            "  Predicted: nar\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 22:\n",
            "  Source:    xa_oo\n",
            "  Target:    xo\n",
            "  Predicted: xo\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 23:\n",
            "  Source:    ja_ee_yy\n",
            "  Target:    jye\n",
            "  Predicted: jye\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 24:\n",
            "  Source:    pa_ll la_oo_ng na_oo_yy wa_ii_ll ca_ex_ng ra_oo_ll\n",
            "  Target:    pla long nyo wli céng rlo\n",
            "  Predicted: syu long gle y kyo xi\n",
            "  CER: 75.00%, WER: 83.33%\n",
            "\n",
            "Example 25:\n",
            "  Source:    ta_uu ma_eueu_ng ta_uu_r ta_ex_rr ya_pamaeh na_eueu xa_ll qa_eueu_ng ga_oo_ll la_pamaeh va_oo_r sa_ii_h ha_oo i kha_ex_r va_ii_ng\n",
            "  Target:    tu meung tur tré y neu xla qeung glo l vor sih ho i khér ving\n",
            "  Predicted: myo cor tung tu mih yo sah fre po mlé zéh do sya myé do gi\n",
            "  CER: 84.78%, WER: 100.00%\n",
            "\n",
            "Example 26:\n",
            "  Source:    ra_eueu_rr kha_eueu ba_ex_rr ga_ll wa_ii\n",
            "  Target:    rreu kheu bré gla wi\n",
            "  Predicted: hli tah rreu rreu kih\n",
            "  CER: 87.50%, WER: 100.00%\n",
            "\n",
            "Example 27:\n",
            "  Source:    qa_ee fa_yy ka_ii_ng na_ex_rr fa_ex na_yy va_ee ja_oo_h ra_oo_rr ha_uu_h\n",
            "  Target:    qe fya king nré fé nya ve joh rro huh\n",
            "  Predicted: lro pong nro nyeu rro dir lye hung xar\n",
            "  CER: 85.71%, WER: 100.00%\n",
            "\n",
            "Example 28:\n",
            "  Source:    va_uu_r ba_pamaeh ha_ex_ng ta_ng ya_ex_yy ra_ii_rr ja_h ra_ii_h ta_oo_ll va_pamaeh ra_uu ca_oo_yy\n",
            "  Target:    vur b héng tang yyé rri jah rih tlo v ru cyo\n",
            "  Predicted: qeng yer nyah b kheu nya sye v hro bleu voh nro\n",
            "  CER: 93.94%, WER: 100.00%\n",
            "\n",
            "Example 29:\n",
            "  Source:    fa_oo\n",
            "  Target:    fo\n",
            "  Predicted: fo\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 30:\n",
            "  Source:    na_ex_ll ka_uu_ng ma_uu_ll fa ja_uu_ng ka_ii_yy xa_rr na ka_uu_r qa_oo_r ra_ee_h ya_uu_h ja_uu_yy ja_uu_ll pa_ii_r ya_ii_ll za_uu_h ba_pamaeh\n",
            "  Target:    nlé kung mlu fa jung kyi xra na kur qor reh yuh jyu jlu pir yli zuh b\n",
            "  Predicted: kyu néh bang clo vér pir mi sli sreu géng vér zeur jyi sla jyu dya dya tye\n",
            "  CER: 88.46%, WER: 100.00%\n",
            "\n",
            "Example 31:\n",
            "  Source:    ha_oo_yy\n",
            "  Target:    hyo\n",
            "  Predicted: hyo\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 32:\n",
            "  Source:    ya_oo_ng ya_h ga_oo_r ya_uu_ng ma_ex_yy ga_uu_rr sa_ex_h ka_ee_yy ma_ee_ng ma_ee_h ba_ii_ng ta_uu qa_ii_r qa_ex_h wa_ii_yy qa_ex_ng\n",
            "  Target:    yong yah gor yung myé gru séh kye meng meh bing tu qir qéh wyi qéng\n",
            "  Predicted: 5 leh zer koh syoh n pong pong pyé pong pyé jih cro flo tle bing\n",
            "  CER: 82.69%, WER: 100.00%\n",
            "\n",
            "Example 33:\n",
            "  Source:    qa_uu_r\n",
            "  Target:    qur\n",
            "  Predicted: qur\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 34:\n",
            "  Source:    ya_oo_ll ga_uu_h da_oo_h ha_uu_ll xa_r qa_ee_h da_uu_rr ha_ii_h ba_eueu_ll ya_r wa_ii_yy sa_eueu_rr ca_pamaeh e\n",
            "  Target:    ylo guh doh hlu xar qeh dru hih bleu yar wyi sreu c e\n",
            "  Predicted: ylo gru jo zya dyé juh fing bi xar dar fru qeh sru loh\n",
            "  CER: 80.00%, WER: 92.86%\n",
            "\n",
            "Example 35:\n",
            "  Source:    xa_ee\n",
            "  Target:    xe\n",
            "  Predicted: xe\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 36:\n",
            "  Source:    na_uu_rr\n",
            "  Target:    nru\n",
            "  Predicted: nru\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 37:\n",
            "  Source:    da_ex_rr la_rr nya_oo_ng sa_uu_rr ga_h da_ee_yy fa_oo_rr ha_uu_ng pa ja_ex ma_oo_h ba_eueu_yy ma_uu_yy ga_ee_rr la_oo_rr sa_ee_r qa_ee_h\n",
            "  Target:    dré lra nyong sru gah dye fro hung pa jé moh byeu myu gre lro ser qeh\n",
            "  Predicted: lro cer lro sru qoh qoh heng fri hung klu lro sru réng vla rla lyé\n",
            "  CER: 75.47%, WER: 94.12%\n",
            "\n",
            "Example 38:\n",
            "  Source:    kha_ex\n",
            "  Target:    khé\n",
            "  Predicted: khé\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 39:\n",
            "  Source:    fa_ee\n",
            "  Target:    fe\n",
            "  Predicted: yleu\n",
            "  CER: 150.00%, WER: 100.00%\n",
            "\n",
            "Example 40:\n",
            "  Source:    sa_uu_rr ra_ex_h na_ex_ng ja_ee_ng na_ee_r ra_ee_yy sya_eueu ga ka_pamaeh\n",
            "  Target:    sru réh néng jeng ner rye syeu ga k\n",
            "  Predicted: réh tar jir sru wri gro tang yye yye\n",
            "  CER: 92.59%, WER: 100.00%\n",
            "\n",
            "Example 41:\n",
            "  Source:    pa_eueu\n",
            "  Target:    peu\n",
            "  Predicted: peu\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 42:\n",
            "  Source:    ga_h\n",
            "  Target:    gah\n",
            "  Predicted: gah\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 43:\n",
            "  Source:    pa_ee_h\n",
            "  Target:    peh\n",
            "  Predicted: peh\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 44:\n",
            "  Source:    sya_uu_ng\n",
            "  Target:    syung\n",
            "  Predicted: syung\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 45:\n",
            "  Source:    sya_pamaeh da_oo_ll nya_oo ya_uu_ll ya_uu wa_ee_r qa_ng ma_oo_yy ca_ee_r na_ex_rr na_ee ca_ii_h fa_uu_h\n",
            "  Target:    sy dlo nyo ylu yu wer qang myo cer nré ne cih fuh\n",
            "  Predicted: lér deh mlé heung blu té né yri bra zor féng zur tér\n",
            "  CER: 89.19%, WER: 100.00%\n",
            "\n",
            "Example 46:\n",
            "  Source:    la_ii_h za_eueu_ng ma_ex_ll ra_ee_ng genep ra_oo_ng\n",
            "  Target:    lih zeung mlé reng 6 rong\n",
            "  Predicted: lih zer syer vung yyeu tuh\n",
            "  CER: 75.00%, WER: 83.33%\n",
            "\n",
            "Example 47:\n",
            "  Source:    ba_pamaeh ga_rr ba_ee_ll sa_ee ma_oo_h ba_ii_ll na_ex_r fa_ee_rr la_ii ba_oo wa_oo_yy qa_uu_r\n",
            "  Target:    b gra ble se moh bli nér fre li bo wyo qur\n",
            "  Predicted: syong gor bér hi se nér bli jre reur we bli\n",
            "  CER: 83.87%, WER: 91.67%\n",
            "\n",
            "Example 48:\n",
            "  Source:    salapan\n",
            "  Target:    9\n",
            "  Predicted: 9\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 49:\n",
            "  Source:    da_eueu_ll ja_pamaeh ca_eueu xa_h fa_ee fa_ee_rr na_ii_yy sa_uu_h pa_ex_rr ha_ee_r nya_ii_h da_oo_r wa_ex na_uu_rr ya_uu ra_ee_r ka_rr\n",
            "  Target:    dleu j ceu xah fe fre nyi suh pré her nyih dor wé nru yu rer kra\n",
            "  Predicted: nyu rer puh wleu rer puh cir puh bér xah syang wuh fre kya gah kra mlé\n",
            "  CER: 85.42%, WER: 100.00%\n",
            "\n",
            "Example 50:\n",
            "  Source:    ga_uu_yy na_ii_ng ha_uu ja_ee_ng ha_ii ya_oo_r na_ex_r pa_ee_rr ra_ee_r pa_oo_r ya_ex_ng kha_ee_r da_oo_ll wa_ii ka_ee_r ba_ee_rr ga_eueu_yy na_eueu_r za_oo_r za_ee_ng\n",
            "  Target:    gyu ning hu jeng hi yor nér pre rer por yéng kher dlo wi ker bre gyeu neur zor zeng\n",
            "  Predicted: fré se wla long se sya g xra g muh fré mo héh plo por doh por doh bing\n",
            "  CER: 79.69%, WER: 100.00%\n",
            "\n",
            "Example 51:\n",
            "  Source:    qa_ii_h\n",
            "  Target:    qih\n",
            "  Predicted: qih\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 52:\n",
            "  Source:    da_ee_rr sya_ng xa_ex_ng va_eueu_r\n",
            "  Target:    dre syang xéng veur\n",
            "  Predicted: xéng pyu dre xéng\n",
            "  CER: 81.25%, WER: 100.00%\n",
            "\n",
            "Example 53:\n",
            "  Source:    ta_ex\n",
            "  Target:    té\n",
            "  Predicted: mro\n",
            "  CER: 150.00%, WER: 100.00%\n",
            "\n",
            "Example 54:\n",
            "  Source:    na_yy qa_ii xa_oo la_ee_ll ja_ii_r ta_ii_h ya_ii_ng\n",
            "  Target:    nya qi xo lle jir tih ying\n",
            "  Predicted: gla tih veu déh xah ying\n",
            "  CER: 65.00%, WER: 85.71%\n",
            "\n",
            "Example 55:\n",
            "  Source:    wa_ll\n",
            "  Target:    wla\n",
            "  Predicted: wla\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 56:\n",
            "  Source:    ta_ex da_ex_rr\n",
            "  Target:    té dré\n",
            "  Predicted: dré\n",
            "  CER: 40.00%, WER: 50.00%\n",
            "\n",
            "Example 57:\n",
            "  Source:    wa_oo ta_ex qa_ii_h fa_uu_rr na_pamaeh ma_ii_yy\n",
            "  Target:    wo té qih fru n myi\n",
            "  Predicted: jre n fru glo n\n",
            "  CER: 78.57%, WER: 83.33%\n",
            "\n",
            "Example 58:\n",
            "  Source:    na_ex_rr\n",
            "  Target:    nré\n",
            "  Predicted: nré\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 59:\n",
            "  Source:    qa_eueu qa_uu_ng ya_uu_h ma_ee_ll ta_eueu_h ma_ee_r fa_ii_ng ma_ee ma_ex ba_ll sa_ii\n",
            "  Target:    qeu qung yuh mle teuh mer fing me mé bla si\n",
            "  Predicted: syir beung mer mle yuh mle luh ryo nye ryo yuh\n",
            "  CER: 78.79%, WER: 90.91%\n",
            "\n",
            "Example 60:\n",
            "  Source:    ha_ii_ll\n",
            "  Target:    hli\n",
            "  Predicted: hli\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 61:\n",
            "  Source:    sya_ex_ng\n",
            "  Target:    syéng\n",
            "  Predicted: reung\n",
            "  CER: 60.00%, WER: 100.00%\n",
            "\n",
            "Example 62:\n",
            "  Source:    ha_eueu_h\n",
            "  Target:    heuh\n",
            "  Predicted: heuh\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 63:\n",
            "  Source:    ta_eueu_ll\n",
            "  Target:    tleu\n",
            "  Predicted: tleu\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 64:\n",
            "  Source:    wa_ex\n",
            "  Target:    wé\n",
            "  Predicted: wé\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 65:\n",
            "  Source:    ma_h\n",
            "  Target:    mah\n",
            "  Predicted: mah\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 66:\n",
            "  Source:    qa_ll ka_ii_yy ka_uu_h ba_ee wa_ii_ng\n",
            "  Target:    qla kyi kuh be wing\n",
            "  Predicted: syih syih qla kreu breu\n",
            "  CER: 106.67%, WER: 100.00%\n",
            "\n",
            "Example 67:\n",
            "  Source:    ra_oo_ng ga_eueu_ng sa_ii_ng ba_eueu_ng pa_oo_ll i fa_ex_ll ra_oo_rr ba_ng ya_ii pa_ii_yy la_ll wa_oo_ng ha_ex_yy ma_uu_r ja_ex_h ma_oo_ll xa_uu ta_ex_r\n",
            "  Target:    rong geung sing beung plo i flé rro bang yi pyi lla wong hyé mur jéh mlo xu tér\n",
            "  Predicted: ler be neu lri sur blo wu klo blo wu mré kéng tur cor pe cor ping syu\n",
            "  CER: 85.25%, WER: 100.00%\n",
            "\n",
            "Example 68:\n",
            "  Source:    na_ii fa_uu\n",
            "  Target:    ni fu\n",
            "  Predicted: fu keur\n",
            "  CER: 125.00%, WER: 100.00%\n",
            "\n",
            "Example 69:\n",
            "  Source:    ha_ll ra_ll pa_uu_yy sya_ee_ng ta_uu_ng xa_eueu ka_eueu_r wa_eueu_ng ja_ee_rr\n",
            "  Target:    hla rla pyu syeng tung xeu keur weung jre\n",
            "  Predicted: ca yreu bu h nér nyé bih yreu\n",
            "  CER: 78.79%, WER: 100.00%\n",
            "\n",
            "Example 70:\n",
            "  Source:    ra_eueu_r\n",
            "  Target:    reur\n",
            "  Predicted: reur\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 71:\n",
            "  Source:    qa_ex_r xa_oo ya_ex fa_yy ja_oo_r sya_r ca_ii_rr na_eueu_rr la_ee_ll\n",
            "  Target:    qér xo yé fya jor syar cri nreu lle\n",
            "  Predicted: véh qér kor hir véh yeuh xo fle bra\n",
            "  CER: 88.89%, WER: 100.00%\n",
            "\n",
            "Example 72:\n",
            "  Source:    la_eueu ga_ii ha_ii_ll ha_eueu_yy za_uu_ng ha_ex_r xa_uu fa_ex ka_oo_rr fa_eueu_ng nya_ex sya_ii ka_uu_r ka_r ha_ex ka_ex_ll qa za_ex\n",
            "  Target:    leu gi hli hyeu zung hér xu fé kro feung nyé syi kur kar hé klé qa zé\n",
            "  Predicted: xe xe véng to lah kur jéng bé heur bé mreu feur syi kh léng jyi léng\n",
            "  CER: 75.00%, WER: 100.00%\n",
            "\n",
            "Example 73:\n",
            "  Source:    da_oo ha_ee_r sya_ee_h ja_ii_r sya_ex_ng pa_ex_r\n",
            "  Target:    do her syeh jir syéng pér\n",
            "  Predicted: jang her her mle jang sla\n",
            "  CER: 80.00%, WER: 83.33%\n",
            "\n",
            "Example 74:\n",
            "  Source:    qa_ll ra_ex_h ta_ee_rr\n",
            "  Target:    qla réh tre\n",
            "  Predicted: réh hra nli\n",
            "  CER: 88.89%, WER: 100.00%\n",
            "\n",
            "Example 75:\n",
            "  Source:    nya_h\n",
            "  Target:    nyah\n",
            "  Predicted: nyah\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 76:\n",
            "  Source:    nya_ii_r\n",
            "  Target:    nyir\n",
            "  Predicted: nyir\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 77:\n",
            "  Source:    da_eueu ra_ii_ng na_oo_yy ka_eueu_yy ma_ll ma_uu_r\n",
            "  Target:    deu ring nyo kyeu mla mur\n",
            "  Predicted: nyur nyo kyeu mla ring nye\n",
            "  CER: 60.00%, WER: 66.67%\n",
            "\n",
            "Example 78:\n",
            "  Source:    ja_ee_rr na_oo_r wa_uu_ng xa_ii_h va_eueu_r ba_ee_ng ca_oo ba_oo_r va_ii_h pa_oo_ll ka_oo_ng da_oo_ng ca_eueu ra_ee_ll fa_uu_ll\n",
            "  Target:    jre nor wung xih veur beng co bor vih plo kong dong ceu rle flu\n",
            "  Predicted: xih ca xih tih geh kur wri veur sli cung ki yré kang wye réh\n",
            "  CER: 85.71%, WER: 100.00%\n",
            "\n",
            "Example 79:\n",
            "  Source:    ma_ee pa_oo_yy za_ee_r la_ee_ng\n",
            "  Target:    me pyo zer leng\n",
            "  Predicted: leng nyo me zo\n",
            "  CER: 83.33%, WER: 100.00%\n",
            "\n",
            "Example 80:\n",
            "  Source:    za_ex_r ma_ee pa_ee ha_uu_r pa_oo_ng ma_ex_h sya_ii va_ex_h ma_ii_ll\n",
            "  Target:    zér me pe hur pong méh syi véh mli\n",
            "  Predicted: x seung kh zér kh rong heu dle\n",
            "  CER: 84.62%, WER: 100.00%\n",
            "\n",
            "Example 81:\n",
            "  Source:    wa_ii_h nya_eueu ta_oo_rr xa_h wa_eueu_ll va_uu_h ka_ee_ll va_ee_ng fa_oo_rr ha_ex_yy sya_ii sya_eueu_ng da_ii_yy fa_ex_ng\n",
            "  Target:    wih nyeu tro xah wleu vuh kle veng fro hyé syi syeung dyi féng\n",
            "  Predicted: khér glé gar feu gla i heuh suh dli heuh tre kéh kra féng\n",
            "  CER: 79.59%, WER: 92.86%\n",
            "\n",
            "Example 82:\n",
            "  Source:    wa_ii_rr ya_ll fa_uu_ll ya_ee_h sa_oo_r ga_ee_r ta_ll ca_eueu_h ya_ee_yy na_ee_ng sa_ii_yy ma_ii_h ta_ii\n",
            "  Target:    wri yla flu yeh sor ger tla ceuh yye neng syi mih ti\n",
            "  Predicted: weng jér weng lru kreu sye veng wri fri sleu fri vor dih\n",
            "  CER: 92.50%, WER: 100.00%\n",
            "\n",
            "Example 83:\n",
            "  Source:    pa_ii_ll\n",
            "  Target:    pli\n",
            "  Predicted: pli\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 84:\n",
            "  Source:    fa_oo va_uu_h sa_ii_rr da_ii_rr sya_ee_h\n",
            "  Target:    fo vuh sri dri syeh\n",
            "  Predicted: vuh syu zah muh heng\n",
            "  CER: 86.67%, WER: 100.00%\n",
            "\n",
            "Example 85:\n",
            "  Source:    o pa_ii_h na_eueu_h ja_ee\n",
            "  Target:    o pih neuh je\n",
            "  Predicted: neuh neuh syu pih\n",
            "  CER: 90.00%, WER: 100.00%\n",
            "\n",
            "Example 86:\n",
            "  Source:    la_yy\n",
            "  Target:    lya\n",
            "  Predicted: lya\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 87:\n",
            "  Source:    qa_pamaeh da_oo sa_ee_ll nya_ex_r za_oo_h ra_ex_r ta_ex_rr ka_ex_h sa_uu ha_uu_ng ja_r qa_uu_ng wa_eueu_h pa_ee_rr wa_uu_r la_ex_ll\n",
            "  Target:    q do sle nyér zoh rér tré kéh su hung jar qung weuh pre wur llé\n",
            "  Predicted: xér yreu dih xér dya peh xér pyu bé bro syong do ner heh do ryi\n",
            "  CER: 87.50%, WER: 100.00%\n",
            "\n",
            "Example 88:\n",
            "  Source:    ja_oo_rr\n",
            "  Target:    jro\n",
            "  Predicted: jro\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 89:\n",
            "  Source:    na_oo_rr la_ll da_ii_ll la_ee_yy za_oo_r ka_oo_yy\n",
            "  Target:    nro lla dli lye zor kyo\n",
            "  Predicted: dli zor dli lli dli kya\n",
            "  CER: 66.67%, WER: 83.33%\n",
            "\n",
            "Example 90:\n",
            "  Source:    ga_oo_r\n",
            "  Target:    gor\n",
            "  Predicted: gor\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 91:\n",
            "  Source:    nya_pamaeh\n",
            "  Target:    ny\n",
            "  Predicted: ny\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 92:\n",
            "  Source:    ca_ex ha_oo_ng fa_uu_rr\n",
            "  Target:    cé hong fru\n",
            "  Predicted: cé fru ping\n",
            "  CER: 77.78%, WER: 66.67%\n",
            "\n",
            "Example 93:\n",
            "  Source:    la_ii_r fa_ex_yy va_eueu_r ha_oo ya_ii_ll ga_ii_ng ha_ll kha_eueu_h\n",
            "  Target:    lir fyé veur ho yli ging hla kheuh\n",
            "  Predicted: cu yeung wir reung syu jro syu wong\n",
            "  CER: 96.30%, WER: 100.00%\n",
            "\n",
            "Example 94:\n",
            "  Source:    ya_oo_rr sya_eueu_h la_ng nya_eueu_r da_ii_yy ta_oo_rr ba_ii_ll qa_ex_h la_ex_rr nya_ng ya_ex_r enol\n",
            "  Target:    yro syeuh lang nyeur dyi tro bli qéh lré nyang yér 0\n",
            "  Predicted: tre yer neung veuh vla pér héng nyang geh nyang ceur slo\n",
            "  CER: 80.49%, WER: 91.67%\n",
            "\n",
            "Example 95:\n",
            "  Source:    ta_eueu_r na_ex_ng la_ee_r za_ii_ng xa_uu na_ex_ll nya ja_oo_r sa_oo_r\n",
            "  Target:    teur néng ler zing xu nlé nya jor sor\n",
            "  Predicted: gya hleu teur neu jeu yri hla he vé\n",
            "  CER: 89.66%, WER: 100.00%\n",
            "\n",
            "Example 96:\n",
            "  Source:    ta_ex_r\n",
            "  Target:    tér\n",
            "  Predicted: tér\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 97:\n",
            "  Source:    ya_oo_ng ka_uu ca_oo_ng\n",
            "  Target:    yong ku cong\n",
            "  Predicted: yong yong yong\n",
            "  CER: 50.00%, WER: 66.67%\n",
            "\n",
            "Example 98:\n",
            "  Source:    ba_ex_ng ha_ee_r ta_eueu_yy za_oo pa_uu_h ka_ii_rr ga_uu_rr kha_ii ja_uu_ng wa_ii_r za_uu_r la_uu_h ma_oo_r ra_pamaeh ca_ii_ng\n",
            "  Target:    béng her tyeu zo puh kri gru khi jung wir zur luh mor r cing\n",
            "  Predicted: qeu jeur puh puh glo luh n jeur luh jeur 0 pré rir zéng\n",
            "  CER: 71.74%, WER: 93.33%\n",
            "\n",
            "Example 99:\n",
            "  Source:    qa_yy\n",
            "  Target:    qya\n",
            "  Predicted: qya\n",
            "  CER: 0.00%, WER: 0.00%\n",
            "\n",
            "Example 100:\n",
            "  Source:    ka ra_oo ja_oo_h da_ee_yy\n",
            "  Target:    ka ro joh dye\n",
            "  Predicted: duh joh joh weuh\n",
            "  CER: 90.00%, WER: 75.00%\n",
            "\n",
            "CER: 55.84%, WER: 62.73%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "    # Metric evaluation on the test set (unseen data)\n",
        "    model.eval()\n",
        "    total_cer = 0\n",
        "    total_wer = 0\n",
        "    n_samples = 0\n",
        "    with torch.no_grad():\n",
        "        example_printed = 0\n",
        "        for src, tgt, src_lens, tgt_lens in test_loader:\n",
        "            src = src.to(device)\n",
        "            for i in range(src.size(0)):\n",
        "                src_sentence = ' '.join([SRC_IVOCAB[idx.item()] for idx in src[i] if idx.item() != SRC_VOCAB[\"<pad>\"]])\n",
        "                tgt_sentence = ' '.join([TGT_IVOCAB[idx.item()] for idx in tgt[i] if idx.item() not in [TGT_VOCAB[\"<pad>\"], TGT_VOCAB[\"<sos>\"], TGT_VOCAB[\"<eos>\"]]])\n",
        "                pred_sentence = translate(model, src_sentence)\n",
        "                cer = compute_cer(tgt_sentence, pred_sentence)\n",
        "                wer = compute_wer(tgt_sentence, pred_sentence)\n",
        "                total_cer += cer\n",
        "                total_wer += wer\n",
        "                n_samples += 1\n",
        "                # Print a few examples\n",
        "                if example_printed < 100:\n",
        "                    print(f\"Example {example_printed+1}:\")\n",
        "                    print(f\"  Source:    {src_sentence}\")\n",
        "                    print(f\"  Target:    {tgt_sentence}\")\n",
        "                    print(f\"  Predicted: {pred_sentence}\")\n",
        "                    print(f\"  CER: {cer:.2%}, WER: {wer:.2%}\\n\")\n",
        "                    example_printed += 1\n",
        "    print(f\"CER: {total_cer/n_samples:.2%}, WER: {total_wer/n_samples:.2%}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
